['For now I just addressed the 3 Main variants of Kalman filters due to time limitations. The Multi-State Constraint Kalman filter is based on Ekf that helps solving certain applications.']
"[""In the past I built a larger robot.\n\nI used lawnmower wheels available at a hardware store for cheap.\n\nThen, I just used larger gearmotors for drive.\n\nHere's similar parts on amazon:\n\nWheel\n\n [Amazon.com : Mower Wheel 8 x 1.75 Inch for Oregon 72-108 AYP 146248 Husqvarna 532146248 MTD 734-04585 Murray 336545MA Poulan PP23009, Used On Walk-behind Mowers Small Carts Hand Trucks : Patio, Lawn & Garden](https://www.amazon.com/Husqvarna-532146248-734-04585-336545MA-Walk-behind/dp/B0B2WLT5QY/ref=sr_1_1_sspa?crid=1UO0C0F041K0W&keywords=lawnmower+wheel&qid=1684777408&sprefix=lawnmower+wheel%2Caps%2C141&sr=8-1-spons&psc=1&spLa=ZW5jcnlwdGVkUXVhbGlmaWVyPUEyTkFKS0w0NVZCVURFJmVuY3J5cHRlZElkPUEwMzMxNTE5Q1o4RzE5SjBSOVkwJmVuY3J5cHRlZEFkSWQ9QTAyMTE3NTYyWkczRDhWSEtVTks2JndpZGdldE5hbWU9c3BfYXRmJmFjdGlvbj1jbGlja1JlZGlyZWN0JmRvTm90TG9nQ2xpY2s9dHJ1ZQ==) \n\nMotor\n\n [Compact Square-Face DC Gearmotor, 12V DC, 1.3 rpm At 50 in.-lbs. Torque | McMaster-Carr](https://www.mcmaster.com/6409K12/) \n\nBut, the motors should be available cheaper...I paid about $10 each at the time.\n\nThen, you just need to make an adapter of the wheel onto the output shaft.""]"
"[""XT-60.\n\nIt's a much better design and you can usually find connectors fairly easily through hobby shops.""]"
"[""I'm not related to your field, but what I did in a similar situation, wrote a basic CV, and a very nice motivational letter, and sent those to companies I was interested in. I've landed a job this way, as a newbie, only experience came from hobbies. That job only lasted for a year, but helped me gain professional experience, and now I'm working on the same field, different company, three years and counting. \n\nGood luck!"", ""Networking is a huge help and how a lot of people find their jobs, early career or late, regardless of field. Even in the age of LinkedIn, blindly applying to jobs sucks and has a super low return. YMMV, especially depending on your performance in school.\n\nDo you know any alumni of your school working at companies you'd be interested in? Were you part of any student societies or competitions that you could chat with? That sort of thing can have excellent results in my experience.\n\nThat said, there are definitely relevant positions on places like LinkedIn that you can also apply to, and most of those jobs websites will allow you to set notifications for when relevant jobs are posted. It's a good extra step to make sure you're casting a large net.""]"
"[""Having never done exactly what you're doing, I can't say for sure how it will work for you, but hopefully I can give some generally helpful information...\n\nI2S is a sound protocol, but it doesn't have any device enumeration features, which means the nano will never know if an I2S device is even connected, all it knows is that it has an I2S bus.\n\nIf you want to use devices on that bus, you'll need a driver that can control the registers on the Jetson to fetch the data and put it into a useful data structure or similar.\n\nThere's a decent chance that you could find a driver for the Jetson nano somewhere on the Internet already made, but I don't know of one in particular.\n\nHopefully that helps!"", ""Hmm didn't know about it not knowing if it's connected of not. Either way been looking for weeks to see if there's drivers but honestly don't know what I'm looking for exactly. \n\nTo make this simple all I'm trying to do is be able to use my 2 i2s mics as stereo inputs to then use it for speech to text/speech recognition via python. I don't know ANY python (slowly learning tho) so makes its hard to test its all if connected correctly or even working right"", 'That sounds like an awesome project!\n\nGiven what you\'re saying about your skill level, it sounds a bit ambitious for where you\'re at now, but I don\'t think it\'ll take long for you to get there if you stay at it.\n\nI would have to do more research to know for sure, but from memory, you might search for ""I2S asio driver Linux"" and see if you can find something for the processor on the Jetson nano- I think it\'s an ARM processor. If you can find that, you should be able to use normal python libraries to get sound data from the system microphone device.\n\nIf you have to write your own I2S driver, it will probably need to be in C/C++ which is a an entirely different beast for newbies.\n\nWhat you might do for starters to get the project rolling is write your python code on a standard desktop or laptop and use the microphone there. Then try and get the I2S working on the Jetson and port you python code over. (If you use a virtual environment on your development computer, migrating the code over *should* be pretty painless)\n\nBest of luck!']"
"['You can\'t really do inverse *kinematics* for an elastic arm.\n\nYou need a dynamic model to capture the effects of forces and torques on the shape of the robot.\n\nAre you looking for techniques for robots with joint-level elasticity or where the entire robot structure is meaningfully flexible? \n\nHere\'s a general overview in a recent review paper I found for the latter case of robots with flexible links:\n\nhttps://www.mic-journal.no/ABS/MIC-2020-3-2.asp/\n\nIf you search for \n\ntrajectory tracking flexible link manipulator \n\non Google you should get some good hits for fully flexible robots and \n\ntrajectory tracking elastic joint manipulator \n\nyou should find something for robots where just the joint elasticity matters.\n\nI believe these topics comes up in space robotics a fair amount where you can envision large, lightweight structures that don\'t have to support themselves against gravity.\n\nFor industrial robots that do have to support themselves against gravity, there will be a lot of papers talking about vibration control (in other words timescales of ""elastic"" or ""flexible"" motion that are much faster than the fastest desired end-effector motions)\n\nI\'m not sure what\'s out there in terms of concrete software implementations. \n\nI think Pinocchio has some capability in terms of adding joint-level dynamics to the robot arm dynamic model \n\nhttps://github.com/stack-of-tasks/pinocchio/issues/671']"
"[""Industrial servo motors run multiple simultaneous, nested control loops (often pid) and it is common to inject speed and torque 'feed forward' parameters into the inner control loops in order to improve the following accuracy and responsiveness of the position control loop. \n\nCreating a 'fake' position control target in order to trick the control loop into being more responsive is definitely not the right way to do what you are asking about! \n\nDetails:\n\nAn outer position control loop that compares the actual measured position (maybe from an encoder or scale) to the provided target position, then outputs a speed setpoint that is sent to the next loop. (100-1000hz)\n\nA middle speed control loop that compares the actual measured rotor speed (maybe from rotor encoder, tachometer, or voltage feedback) to the provided target speed, then outputs an acceleration setpoint. (~1000hz)\n\nThe acceleration setpoint is converted to a torque using provided inertial parameters of the mechanical situation, which surprisingly are usually dominated by the rotor inertia.\n\nThe torque setpoint is converted to a current using provided electrical parameters of the motor.\n\nThere is a final current control loop that compares the actual measured current in the motor driver to the provided target current, then outputs a voltage setpoint which is used to drive the motor (>>1000hz)\n\n\nAdding an outside 'speed feed forward' term to the speed setpoint output of the position control loop generates a sum that can be used as the target speed of the speed control loop. \n\nSimilarly, adding an outside 'torque feed forward' term to the torque setpoint is the typical way to inject more control into the current loop. \n\nI hope this helps, and gives you a different perspective than some of the other answers here that only talk about the outer most loop!"", 'For the most part, industrial servos are mostly just regular ac motors. Particularly over a kw they’re usually just built with excellent tolerances. The secret sauce comes from a resolver or an encoder or something with the drive figuring out the hard stuff. Hobby servos are all kinds of junk and some kind of tech that helps them maintain position. Any old motor, whether stepper or 3ph AC, or DC brushed or brushless or linear maglev or whatever is technically considered a servo when the drive gets position information and uses *feedback* to control position. Consider a stepper where the drive doesn’t typically get feedback and just energizes field windings in a particular order. If you add a resolver (or encoder) it becomes a hybrid servo. There are pure analog versions of this, so it’s not limited to digital and there are even weird implementations of matching field windings with synchros and synchro resolvers.\n\nBasically it becomes a servo when the drive is aware of the motor’s position.  Algorithms and windings and whatever technologies are diverse and widely varied depending on whichever technology the engineers want to implement.', ""Seeing how low quality the replies are in here so far is rather disappointing for a robotics subreddit. Hobbyist servomotors are, to be honest, junk. I'll give a detailed explanation of how servos are actually implemented.\n\nTo start with, voltage is not what you control when it comes to motors. Motors are current driven devices, not voltage driven. 1A at 10V produces the same force as 1A at 100V. Voltage only determines your maximum RPM/Speed you are capable of achieving by giving you more headroom over backemf.\n\nNow, onto the actual algorithm. Typically, it is split into two parts. There is a trajectory generator/io manager, this is often what is called the controller even though it isn't, and the motor drives, where the actual controller exists. The trajectory generator will synchronize motor drives and generate a setpoint for position if we are controlling position and velocity or a setpoint for velocity if we are only controlling velocity. On top of one of the setpoints, it will also output an acceleration feedforward value. [These setpoints and accleration feedforward values are typically generated by third order motion profiles on the trajectory generator and passed,](https://www.jpe-innovations.com/wp-content/uploads/Third-order-point-to-point-motion-profile1-1.png) but fourth order profiles are sometimes used as well. The trajectory generator does not send the whole profile, but instead generates setpoints while the motion is being executed and distributes these setpoints to the drives between 2KHz to 20KHz.\n\nNow, on to the actual control loop. [Servos are mostly controlled via PIV control.](https://b2600047.smushcdn.com/2600047/wp-content/uploads/2016/10/PIV-Control-Diagram-768x320.jpg?lossy=1&strip=1&webp=1) PIV control nests three separate control loops. The first control loop is the current loop. The current loop just controls the current in the motor windings, but in a way, it can be thought of as controlling the force/torque and by extension the acceleration of the motor since current, force/torque, and acceleration are directly tied together linearly with scalar factors. This loop is controlled at least at 20Khz, but often higher. The next control loop is the velocity loop. The velocity loop is a PI controller typically with a low pass filter and potentially one or more notch filters on the output to correct for resonances and high frequency noise. The acceleration feed forward is attached to the output of the filters and should always be used. Velocity feed forward doesn't make much of a difference and can be ignored. If you only want to control velocity, you can stop here. But even with pure velocity control, I'd still recommend having the third control loop, the position controller. The position controller is only a proportional gain. No integral term. Both the velocity and position control loops are typically sampled at 5KHz to 20KHz. And if you are not using direct drive (you have ballscrews, gears, belts, etc.), you should probably be using an encoder attached to the motor for velocity control and an encoder attached to the load for position control if you care about positional accuracy. The encoders should pretty much always be optical encoders and typically should have 4000+ counts per revolution after quadrature decoding for rotary encoder or 1um or finer for linear encoders. Less is certainly usable, but your resolution is lowered to the point it can start to bite you if you are doing anything on the more precise side.\n\nBrushed DC motors are the easiest to work with because they do not need commutation and the current output by the control loop is the actual current going through the windings. However, brushed motors are fairly noisy and wear out over time, which is why 3 phase motors are typically used. 3 phase motors add more a few more steps between the current command and the actual PWM signal controlling the current in the windings through something called [field oriented control](https://www.pmdcorp.com/hs-fs/hubfs/Diagrams/fig-Field-Oriented-Control-FOC-pmdcorp.png?width=660&name=fig-Field-Oriented-Control-FOC-pmdcorp.png). And because there are no brushes for commutation, the motor coils need to be aligned to the phases in a known orientation at powerup so that the controller knows where the motor is and can generate the correct current in each of the phases for field oriented control. Stepper motors can also be turned into servo motors by modifying the FOC algorithm for two 90 degree phases instead of the three 120 degree phases of BLDC motors."", ""Thanks, I'm glad this is helpful. I learned all of this in the specific context of the Siemens 840d and the solution line ac servo drives (used for big custom cnc machines). Although their documentation was very brand specific, the general concepts seem to be present in other industrial brands.\n\nI don't know much about bldc stuff (which seems to be popular in this sub) . I've been wanting to look at the odrive documentation for a while, especially for how they do low speed position control."", ""Integral terms requires proper management : antiwindup, on/off, prepositioning and dealing with striction (in mech systems). It also reduces performances compared with a non integral regulator. However, it's the only way to get a correct steady state if the system has no integrator.\n\nJust for my curiosity, what is your specific case?"", 'Stiction is a mess. I agree that in that case, integrator can be difficult to handle. Usually super high resolution position sensor and an unknow input observer can help, but it remain a mess.', ""That's not what the person I replied to was doing. They were saying that a system is open loop if the operator doesn't get feedback, which is not true. What they said was fundamental not true and shows a lack of understanding of not only how servos work but how a system is classified as open or closed loop.\n\nIt's weird that you are arguing so hard about a point that was never brought up by the person that I was replying to."", ""> They were saying that a system is open loop if the operator doesn't get feedback\n\nNo, you replied to terminator0117 who said:\n\n> Internally the servos are closed loop but you as a user don't get the feedback at all. So it is open loop *to you*.\n\nThe comment *they* were replying to said:\n\n> Most basic servos are open-loop\n\nWhich doesn't make sense, because the definition of a servomechanism is that it uses a closed feedback loop, so it's not explained well. The comment from terminator0117 clarifies it, and is correct.\n\nIt's weird that you insist terminator0117 said the entire system is open loop, when they didn't say that. It's accurate to say that if there is no feedback to the operator, like there would be in a haptic or force-feedback steering system, then that part of the system is not a closed loop or servomechanism.\n\nIt also shows a lack of understanding to insist that a system is classified as either open or closed loop, if there are multiple levels of control. In some industrial systems, there's a single device that does the motion and trajectory generation (the control over speed and acceleration that the OP asked about), and receives feedback from an encoder on the motor, so that entire system is a servo system. In other systems, the trajectory generator is a separate device, so there is a servo system between the motor/encoder and the motor driver, which could still be called a servomotor, but not between the trajectory generator and the rest. And there are other variations. If you want to describe or explain such a system, you can't do it in a simplistic way.""]"
['From what you’re describing it sounds like your ratios might not be quite right. This [video on this particular type of gear](https://youtu.be/-VtbSvVxaFA) and more specifically [the calculator sheet](https://docs.google.com/spreadsheets/u/0/d/1xrzSBmJ5qVQ8zQYUvLjdAsl90GyONrzupCxgUUP2wpk/htmlview) they have that goes with it are very useful for doing the needed calculations. I’d recommend plugging your 1st stage values in and see if the values you get for the second stage results match your design. For this design you shouldn’t need a planet carrier if your design is up to spec for this type of gear set. Hope that helps!']
"['If you get a team to help you with this, who will own the IP and how do you envision that will it be licensed? Is this something that will be an open-hardware license for anybody to use?', 'Thisbhas been the most helpful so far. I have reached out to the company you linked. Thank you. Definitely makes more sense to find a company that is in this area already.']"
"[""Kickstarter ccampaign, [https://t.co/TMjVwl8s1k](https://t.co/TMjVwl8s1k)  \n\n\nCompatible with ROS2, rViz, Moveit2, and features native trajectory planning and editing tools, a visualized drag-to-program software, AMBER Robot Studio.\n\nFor film studios and vloggers, the AMBER Lucid-1 boasts an incredibly efficient feature, “Just a Snap,” that can help to automatically plan the right camera robot trajectory and angles in just 10 minutes. As my experience, this cost serveral hours generally. \n\n Lucid-1 comes with a bunch of external IO devices like the force control gripper, magnetic connector with a camera, smartphone, sucker, laser pen, etc. \n\nIt's a favorite package for learning, research & commercial robot project"", '[Here](https://www.ebay.com/itm/354324254863?_trkparms=amclksrc%3DITM%26aid%3D777008%26algo%3DPERSONAL.TOPIC%26ao%3D1%26asc%3D20220705100511%26meid%3Dcc7918909b784555a6e7fe2febcd870d%26pid%3D101524%26rk%3D1%26rkt%3D1%26itm%3D354324254863%26pmt%3D1%26noa%3D1%26pg%3D2380057%26algv%3DRecentlyViewedItemsV2%26brand%3DUnbranded&_trksid=p2380057.c101524.m146925&_trkparms=pageci%3Ae2faacb5-f7ba-11ed-b055-c230983a8901%7Cparentrq%3A3daa60f71880a0f0fe2c69bffffee1a4%7Ciid%3A1), costs **$90** and comes with metal parts+motors. Everything else (Raspberry/Arduino) has to be bought and coded by you.\n\nThere are also **$35** [versions](https://www.ebay.com/itm/163918960189?_trkparms=amclksrc%3DITM%26aid%3D1110013%26algo%3DHOMESPLICE.SIMRXI%26ao%3D1%26asc%3D249388%26meid%3D46377b58a50f4a21a4ecd602716c5966%26pid%3D101196%26rk%3D1%26rkt%3D5%26sd%3D354324254863%26itm%3D163918960189%26pmt%3D1%26noa%3D0%26pg%3D2047675%26algv%3DPromotedRVI%26brand%3DUnbranded&_trksid=p2047675.c101196.m2219&amdata=cksum%3A16391896018946377b58a50f4a21a4ecd602716c5966%7Cenc%3AAQAIAAAA8BFMeJ9vNoeV5R6diewUBS27u6Bd4eCLSUkqH%252FP5hcfvlFtMbSxaIG7WNF4g7SUV19HBKxwY4c4dKslq9fUSg0%252BLGLoTjLyvoLJ6iT1Y73j5eZQRhDkiQ3bbenSxKFKW%252B9HPLqb4hwQ0guwjA6jnSHDUeJ6TX5x7BDLirkv1osQiy0WArcD78NclReFyy%252BwvCmKsYEpva%252B9swyaJBKBT2osUA1M%252FiOjB0GrjR5PuTr5OtHiWLMstUQhmhKDfhXYGGDDR4uemhb164InqsUvNa527EMK17qTvZUUHLou641KhJci7%252FN1Tv7JGZXGLWySTbA%253D%253D%7Campid%3APL_CLK%7Cclp%3A2047675) with only just metal parts (without motors) in case you want to pick your own motors.', ""How much do we think it's dirty chieap, $999? If it's still reliable with the reasonable repeatability."", '> I wish there was a dirt-cheap full robot arm kit that includes all the hardware\n\nHave you had trouble finding such kits? There are many. You can save money by getting arms with low payload capacity. What kind of ""low-level control"" are you talking about?\n\nThe cheapest bracket are the many arms based on hobby servos. Your control with these is going to be limited to sending PWM position signals to the servos, so you\'re not going to be doing any motor-control or dynamics with these, but for experimenting with things like inverse kinematics and path planning, they should be great. Ex: [5 DOF+gripper for $140](https://www.amazon.com/LewanSoul-Robotic-Arduino-Software-Tutorial/dp/B074T6DPKX).\n\nThe next bracket up are probably the arms based on dynamixel servos, which will let you do whatever low-level control you like. This looks like a pretty respectable option: [4 DOF+gripper for $650](https://www.trossenrobotics.com/pincherx-100-robot-arm.aspx), or get [a 5 DOF for $1050](https://www.trossenrobotics.com/pincherx-150-robot-arm.aspx). This project isn\'t a kit, but as a price reference a 6 DOF dynamixel arm [like this one](https://www.reddit.com/r/3Dprinting/comments/pdtln3/my_6_dof_3d_printed_dynamixel_robot_arm/) is about $1200 for just the motors.\n\nIt looks to me like there\'s an opportunity for someone to release a kit using the new low-cost dynamixel XLs, like [this 5 DOF arm project](https://www.youtube.com/watch?v=NCQFlha8_fA) which looks like it only uses about $100 worth of dynamixel motors, which is pretty incredible.', 'Thank you for chiming in. You said that there are many such kits but neither of your links satisfies my requirements. You either listed arm kits with less than 6DOF or one with just the motors. Making my point about the need for such a kit. Low-level control: Torque/current control.\n\nAfaik the ""smart"" Dynamixels already have their own PID controllers and only let you position-control them (last time I checked with a specific type). Which is cool for actually building a capable robot but if you want to learn and understand the most low-level controls, not so.\n\n(I already work with higher level interfaces of robot arms every day)']"
"[""Hey fellows,\n\nI have a plank with a lot of small 3 mm rounded holes. I need to place multiple \\~ 2.5 mm spheres on them. There are at least 5 different colors of spheres and I need to place them on a given position that is pre-defined. The quantity of balls can vary from 10 to 1000.\n\nI was thinking on having a 2-axis movable head (like a 3d printer) and hover on each hole, then with 5 long vertical tubes, deploy the ball of the required color. Now I don't know how to properly handle deploying each ball. Is there any mechanism or part that can be used for that? Or do you have any suggestion for a different approach?  \n\n\nThis is a fairly small project. I have a 3d printer to print any part I need and I can also buy them.I'm pretty new to this, so I appreaciate any guidance.""]"
"['\n\n\nI have this design idea for a rail and bearing system for a small 5 lbs robot project I plan to create as shown above. I plan to build using a 3d printer when I acquire one in the near future. \n\nAs shown, the robot will be on a base that will have bearings so that it will easily slide around the rail as frictionless\xa0 as possible. That base will probably have dimensions 4 x4×.5 inches. Track dimensions\xa0 around 30 inches inside diameter \n\nMy question is, is this a good rail and track design. How can i improve it so that it will be stable, secure, sturdy. Is there something out there already made? Any resources i can look at that you may know.?']"
"['\n\n\nI have this design idea for a rail and bearing system for a small 5 lbs robot project I plan to create as shown above. I plan to build using a 3d printer when I acquire one in the near future. \n\nAs shown, the robot will be on a base that will have bearings so that it will easily slide around the rail as frictionless\xa0 as possible. That base will probably have dimensions 4 x4×.5 inches. Track dimensions\xa0 around 30 inches inside diameter \n\nMy question is, is this a good rail and track design. How can i improve it so that it will be stable, secure, sturdy. Is there something out there already made? Any resources i can look at that you may know.?']"
"[""There are simulation and programming softwares like RoboDK that you can use to program a robot in a virtual environment first, then transfer over to your robot to actually run.\n\nHowever, if you don't have access to that or your robot/welding package isn't supported, you're pretty much stuck with the teach pendant.\n\nYou should also ask this question on robot-forums in the Yaskawa board, you'll likely get much more helpful answers specific to welding with Yaskawa robots.\n\nThere are other companies that are developing solutions to make teaching robots much more simple and efficient, but those solutions are not widespread yet.""]"
"['3D printed parts are never given enough credit, if designed carefully and with purpose they can be very strong. An example is [my entirely 3D printed gearbox](https://www.reddit.com/r/robotics/comments/115hmf3/v2_of_the_135_3d_printed_backdrivable_rv_reducer/?utm_source=share&utm_medium=ios_app&utm_name=ioscss&utm_content=1&utm_term=1), which can handle over 40ft/lbs of torque and is made of PLA prime. I’d say with confidence you could get a 3D printed body to work based on the information given.']"
['So is this like an unpaid internship?']
"['Sounds like 2 relays could work here. You’ll be able to find one in the voltage and current range you need and then adding a tiny bit of control circuitry (depending on specifics can sometimes be as simple as a transistor, diode, and resistor or even just an IC designed to do relay control) you can pretty easily control what you have connected to it. Then connect a microcontroller of your choice to the relay control pin and tie that same pin to a switch as well. Lastly, attach some control method to the microcontroller (this could be an IR Remote, or if you use an ESP32 with its own locally hosted network (not really Wi-Fi imo) you can build an app to connect to it, or even still you could use a Bluetooth module if you prefer). Hopefully that’s somewhat helpful, with it being such a high overview, free to ask questions if you have them.']"
"[""I think you can get laptops with very good performance for a good price (though some of them are fairly heavy).  If you plan on doing any light ML code, that could be a consideration (laptops don't stand up to long-running heat-generating training well), but otherwise, laptops have plenty of power, good graphics, and are portable.\n\nI personally still have both an older macbook pro (the one with the Nvidia card) and a newer Lenovo P-series.   I use the mac for my daily reader and the Lenovo for when I need to do projects.  The Lenovo is much heavier, but can do everything a full desktop can. A desktop only affords me a discrete Nvidia card, but my laptop has 32gb of ram and 1TB ssd, so not much trade-off.  The newest Lenovos I saw (P15??) come with an A5000 which is very similar to a 3080, so no reason for a desktop unless you are about to drop a ton of money on graphics cards too (for ML/AI research of course - not for gaming ;-)""]"
"['Its a little different. the trailing edge of the wing has a push rod connection to an actuator along the length of the fuselage. this is what is powering the wing rotation, and said wing also pivots in a unique angle to maintain even flight during that transition. \n\nVery similar function, and I assume a direct inspiration for this design. I bet they need the leverage of the push rod to keep the pivot mechanism light and simple compared to a complicated assembly like a F-14 sweeping wing.', 'Ospreys get hundreds of thousands of flight hours and since the initial issues were ironed out, I don’t think it’s more dangerous than any other rotorcraft. According to [this](https://www.wisnerbaum.com/aviation-accident/helicopter-crashes/black-hawk-helicopter-crashes/), there have been 10 fatal Black Hawk crashes on U.S. soil since December 2019. Wikipedia says 2 V-22 crashes in the same period. \n\nI think what helps skew it is that the V-22 can carry over 30 people so when a full one crashes it can result in like 3x the deaths compared to a Black Hawk. You mentioned ~400 V-22s built, I think how often they are used is more important to compare but in my brief searching I couldn’t find a fatalities per flight hour statistic. That would probably be the best way to compare and see for sure how dangerous all those aircraft really are.', 'That’s fair. I wonder what exotic alloys could be used.', ""Here are some cases to consider:\n\n1) G-forces on a wing that isn't a complete structure are comparable to forces and takeoff and landing. An F-18 in a 7 G turn experiences high stress on the wings, despite having a mid-wing hinge point. .\n\n2) The F-14 tomcat was been in service for decades with variable geometry wings. So the entire wing is on a pivot point, yet it's also capable of multi-G turns.\n\n3) NASA has prototypical aircraft with variable geometry, VTOL, and other capabilities exploring the forces on wing structure."", 'As I said in another comment, this is most widely known as [""Grumman-type folding wing""](https://www.youtube.com/watch?v=GQQUMTcdJ9o), but here the wing rotates in the opposite sense, and does it in-flight.\n\nIt is very surprising that this design works as well as it does. But the proof is in the pudding.']"
"['I’ve given each contact the machine information including pictures, controller details and example videos of what we are looking to accomplish. A few companies told me it wouldn’t be a problem but I have concerns that they said this without being familiar with the control software.']"
"['is that a wood board under your parts?  I would use wire wrap (braided sleeve or spiral wrap) first to manage each group of wires - like the set coming out of an IMU.  \n\nthen I\'d find a way to lay them flat, ideally so they overlap as little as possible.  \n\nstarting at ""corners"" (where the wire has to turn) I\'d mark two dots on the board with a sharpie, either side of the cable.  I might also mark the corners of the larger components like the battery and so on.\n\nThen I take the board out and drill some m3 holes at every dot.    I\'d put a twist tie - not a zip tie - through from the back.  being able to undo the ties is essential for prototyping.\n\nreturning the board to the robot, I can now twist (always righty tighty) to lock down my cables.\n\nIf cables have long runs (over 20cm) and are feeling loose, try an extra tie every \\~10cm.  seems to work well for me on the Makelangelo robot and others.']"
"[""Thanks for the comment! C++ is needed because I'm using a C++ API to control another device and would like to integrate the stepper in that project. As Ronny\\_Jotten said, I'm not looking to use a rotary encoder knob but am trying to have closed-loop feedback for position control."", 'Thanks for the comment! Essentially, this motor is to a cylindrical device that needs to rotate. There are mostly two important functions of the stepper in this project - the first is going to a specified rotation angle. The actual time it takes to get to this angle isn\'t important, but the actual angular position is crucial. The other function is rotating at a constant angular velocity. In this case, acceleration and jerk aren\'t crucial, but the angular velocity is. \n\nThe motion needs to be synched with another device that is controlled using a C++ API on a PC. An integrated unit with an API would be **awesome**, but I have toyed with the idea of using a separate microcontroller that communicates with the PC (a PC is necessary for computational power) - e.g. send a message over USB when the motor hits the specified position. \n\nAs for the connection to the PC, I\'m drawn to USB because it seems the most ""plug and play,""  but I don\'t have any preferences. \n\nAs for the error handling: The non-time sensitive positioning just needs to get to a specified position and stay there until other actions are performed. For the constant angular velocity case, if a step or steps are missed, I need the stepper to ""catch up"" to the position it should be at. E.g. if starting at 0º and rotation at 100º/sec, after 2 sec I  expect the rotation angle to be 200º (ignoring acceleration time and what not) - I just need to ensure the motor is at the right position. as its rotating.\n\nI don\'t think I necessarily need ""real-time"" reading of the position/position error, but might in the future. \n\n&#x200B;\n\nI\'m happy to answer any other questions you have! I\'ve been beating my head against the wall trying to figure this out. I sincerely appreciate any and all help!', 'Probably 99% of steppers are used ""open loop"", without feedback from a shaft encoder. You design the system with sufficient power, torque, and acceleration ramping, so that it just doesn\'t ever miss a step. You ""zero"" it with a home switch at power-up, and then assume that when you tell it to go somewhere, it does so. From your description, I can\'t tell whether you actually need to use an encoder or not. I guess it wasn\'t you who specified the motor?\n\nSomething like the Tic T825 you looked at might be fine. An Arudino-compatible microcontroller with the [AccelStepper library](https://www.airspayce.com/mikem/arduino/AccelStepper/) would be similar but give you more flexibility in choosing any driver that takes step/direction signals.\n\nThis article gives a good explanation of the various ways a shaft encoder can be used to improve stepper performance if necessary, at the expense of increasing complexity and cost. But again, I don\'t know if it\'s necessary for your project - I think you\'ll have to figure that out for yourself.\n\n[How does closed-loop stepper control work (and why not just use a servo)?](https://www.linearmotiontips.com/how-does-closed-loop-stepper-control-work/)\n\nIf you need precise synchronization with ""another device"" that you mention, like in a CNC system, you need to use one multi-axis controller to control them both. But I also don\'t know if you need that or not.']"
"['I have been invited for API by OpenAI but it seems I should have the paid version of GPT-4, do you have any experience whether I can use GPT-3.5?\n\nAlso is there any tutorial explain how I can do that in detail?', 'Can gpt actually help me with code ?', 'Thanks this is helpful. Do you think it worth, I believe you can do that without their API correct me if I am wrong? What other interesting things did you find?', 'Thanks, this is helpful. I do already use GPT-4, but it seems I  try API']"
"[""I think there are a good number of logic-level MOSFETs, from a several different suppliers, that work well with 3.3V gate drive, so yes, with a minimum Vgs lower than that. For example:\n\n[IRLML2502 - Infineon Technologies](https://www.infineon.com/cms/en/product/power/mosfet/n-channel/irlml2502/)\n\n[PMV16XN - 20 V, N-channel Trench MOSFET | Nexperia](https://www.nexperia.com/products/mosfets/small-signal-mosfets/PMV16XN.html)\n\n[IRF3708\\_S\\_SLPbF.pmd - Infineon-IRF3708-DataSheet-v01\\_01-EN.pdf](https://www.infineon.com/dgdl/irf3708pbf.pdf?fileId=5546d462533600a4015355df7cf5193c), etc. \n\nBut anyway, it's true that most MOSFETs need higher than that. It's possible to drive a MOSFET with e.g. a common 2N3904, with maybe a 1k base resistor, so about 2.6 mA from the MCU. You could drive almost 20 of them. But you should expect poor performance and overheating with PWM, with such a simple circuit. At least you should use a totem pole circuit, but it's much better to use a dedicated MOSFET driver IC.""]"
"[""cool，Do you have a discord channel，YouTube channel etc?\nI'm developing a inkjet 3d printer，maybe we can help each other""]"
"['Hi, we have these, and are happy to help you build your own.\n\ne.g.  \nhttps://remocon.tv/5fa89a529623b645aa04690b  \nhttps://remocon.tv/605c694a9660d30017f51f2c  \nhttps://remoconrover.com\n\nTo help you build your own though feel free to PM me, or find the discord server on the remocon.tv link above.\n\nThere is a free API here for setting up the control system you describe: remocon.neocities.org']"
"[""Define deep learning - I'm currently playing with LLMs and barely have enough VRAM between two 3090s to have a good degree of flexibility. Unfortunately there's no step up from them without way way more cost, so... I recommend a 3090. \n\nPretty much any combination of recent mid-tier or better hardware for the rest of the system will suffice""]"
"[""How do you ensure green blobs for the ball are detected quickly and reliably enough? Do you make sure the lighting is the room is consistent? And what masking/segmentation method are you using? I'm quite interested as a similar project of mine needs fast, reliable and accurate detection of a hand and I don't know how to make it better than it is already"", ""The lighting has to be consistent and I can't wear anything green. I use OpenCV's background subtraction feature and it's blob detector.""]"
"['Someone mentioned IMU’s and EKF filters. To add on to that using a form of “wheel odometry” with encoders may help with localization. Just need to figure out how to get the encoders to work on your snake thing.', 'If you have people trapped in a structure, who would perish if nothing is done, sending in a robot that can help localize them is an obvious tradeoff that everybody will gladly make.', 'I didn’t say do nothing? I said that sending civilian tech into a natural disaster might be illegal and that it might cause shifts that could lead to a collapse causing everyone to perish (which no, this isn’t an “obvious tradeoff” if something like thermal vision, sonar, AI analysis or other options to locate survivors from the outside are viable, is a snake robot the best options for saving lives or is it just the coolest?). I also didn’t say it was a bad idea, I figured I’d bring this up if it hadn’t yet been considered.']"
['I used this fantastic hackable guardian 3D model for it: https://www.thingiverse.com/thing:2391826. My friend helped adjust the model head to attach the camera: https://www.thingiverse.com/thing:6027280.\n\nI documented my process as a tutorial if anyone wants to follow it 😊 https://docs.viam.com/tutorials/projects/guardian/\n\nEdit: added thingiverse link for camera model']
"[""It's certainly possible to design parts in blender, but not the best. Many will recommend many softwares, my recommendation is SOLID EDGE, it has a free version for students and hobbyist, and relatively easy to use, and is capable of many things."", 'I use Blender with the ""measure""  cad plug-in and the 3d printer plug-in which helps cleaning up models and reports a lot of issues']"
"[""Don't explain to them why it's important to the club. Explain to them what is important to them. Do they only study to get a job or do they do it because they like it? If it is the first option, does the club give visibility so that important companies can see them? Does the club give you something important to put on your cv? If it is the second option, does the club really give knowledge? Can they apply that knowledge to larger projects? Ask those questions (and more) and find out if the problem is them or the club, if it is the club, surely others will not join either. if it's them, look for other students"", 'For what it’s worth, I’m gonna give some of my experience as a programmer (and as a hobby a bot programmer).\n\nCode gurus are very proprietary beasts—we like to be responsible for something that we create and bring into existence, start to finish.  Plus we like genuine compliments and/or feedback on our creation.  By chance, do you have the three programmers all working on the same systems?  If so, there’s no feeling of ownership or pride in the development.\n\nIt might be helpful to have each one work on a different system, and make them responsible for it.  Let them be proud of what they create, and their ability to bring into existence something from nothing—possibly faster than another programmer can get their system flowcharted, coded, debugged, tested and working!  They may need some self-motivated competition between each other!\n\nHopefully this makes sense.  I worked on a group robot project.  My system was navigation—So I was designing code, and redesigning, and testing, and debugging, and trying to have THE BEST nav system possible (and I wanted to have it done before anyone else).  Now, as damned good a coder as I was, there was a problem with my near-field object routine.  Well, I bought a pizza, two big bottles of Mountain Dew, and we all sat down and talked about how great we were… until we started talking about things that were just frustrating us about our system.  And that’s when the collaboration began.\n\nI’m not saying this will work for you, I’m saying it’s a way I’ve worked on group coding projects in the past that worked.  And don’t forget, ask about how they coded their system to work, actually listen to what they tell you (even if you don’t get it all—you can ask some pointed questions to get clarity, but don’t make them turn it into a TED Talk), and if they did a good job, or did something innovative, or came in before deadline—tell them.  Genuine positive feedback is fantastic.\n\nAs always, take anything that you would like, and leave the rest.  Hope your project gets back on track and things turn out well for you all!', 'You didn\'t only ask a question, you criticized me for not being ""inclusive"". You make it sound like I said the OP isn\'t welcome here, but that\'s bullshit. I only pointed out that the post is off-topic, and suggested some better places to get answers. And no, I actually don\'t get your point - something about Nazis?', ""I understand the frustration, and I'm glad you are thinking about it carefully.  That's what school is for!\n\nThe team I coached this year had issues with programmers being unavailable a lot of the time.  I did my best not to blame them for it, and we had to make some tough decisions so that they would have less work to do.  We had some students learn programming late in the season to pick up the slack toward the end.  The most active mechanical members did not want to learn and they understood this was the result--now they are helping to recruit programmers for next year.  Edit: and we wound up taking everyone to the world championship!  The patience paid off.""]"
"['[Have a few of these linear actuators with feedback, but the gear sets have failed.](https://i.imgur.com/SgemCSQ.jpg)\n\nIs there a place that might be able to supply a compound gear for these generic linear actuators that can be purchased at motion control sellers?\n\nI need the compound gear that mates with the output, the tooth count is 30 and 11 teeth, if helpful I could probably estimate diametral pitch.', 'Is there a better place to be able to ask for repair help with these linear actuators with feedback? \n\nOr possibly a known source to source parts specific to this assembly?', 'With feedback, 5 wire, for $40 at this force and size? Link?\n\nJust having access to repair parts would be helpful, as a small part like this that rarely overloads can disable the device that is otherwise reasonably put into service for years.', ""They don't make these to be repaired. Quick search, servocity as a hobby supplier has them in ones for $129 (5 wire with feedback) you can probably find knockoffs for around $50. I was buying lots (100 at a time) of them at once for ~$25 each\n\nI have been down this road. It's fun, but I'm guessing you will work back around eventually. Get the new part! Make it work! But don't trust it completely.\n\nhttps://www.servocity.com/heavy-duty-linear-actuators/""]"
"['I’m not sure what you mean by “high power system” because at some point even an emergency stop switch won’t save you from high voltage arcing or lithium fire.\n\nThat said, you want to invest in (read: buy from a reputable vendor) a wireless emergency stop system so you can signal an emergency stop with a wand or remote from a safe distance.\n\nThe important question is: what should the emergency stop trigger? Can it totally disconnect power? Will it properly reset the system so re-powering won’t re-engage actuators? Would totally de-powering be dangerous?', 'Thanks for the reply!  In the post I mention the power requirements 220A peak at 24VDC so I don\'t think I need to worry about arcing as the voltage is fairly low (I suppose ""high power"" is relative).  Do you have recommendations on vendors for wireless E-Stops?\n\nIn regards to what it triggers, we\'ll have it completely disconnect power.  There\'s minimal risk of harm to the hardware and all the subsystems fail safe when they lose power so there\'s no risk of danger to an operator.  I wanted to see if there were existing guidelines before just hooking up an e-stop to a contactor and calling it a day.']"
"[""Can anyone provide some career advice and resource recommendations for someone with a mathematics background looking to move into robotics?\n\nI am a mathematics undergrad who has also completed some postgraduate machine learning modules. Unfortunately I did not complete my postgraduate studies due to personal circumstances.\n\nI have been given the opportunity to visit a company that uses robotics to remove fouling from equipment in heavy industries such as oil refineries and polymer production plants. \n\nTheir research and development team has developed mobile robots that incorporates sensors to help manage distance control, path planning, and varying the jet pressure. \n\nI think this is fascinating and am looking for advice on which skills may have carry over, and what skills/tools/technologies I may need to learn if I were to secure a job/internship working on this project or something similar.\n\nI am happy to provide more detail on my educational background and what I have researched in my own time but for the sake of brevity I haven't included it in this post.\n\nThank you in advance!""]"
"[""I don't have any recommendations but since you are concerned about safety I would avoid Amazon and AliExpress and similar website ones unless you can find some that experienced people trust, if not you would be better trying to find one from a reliable brand but it would be more expensive.\n\nYou can get varying levels and types of protection in BMSs, you will probably want a fully featured one though with balance charging, over voltage protection, under voltage protection, over current protection, high and low temperature protection, short circuit protection and over charge and over discharge protection and there are probably others I have missed."", 'Thank you for the very thorough response. I think I will dive a little deeper into the BMS, and buy a reliable one. Even if it’s more expensive I feel like that is something I can’t be cheap on. Thanks again. This issue has been weighing on me heavily for a while with this project. The last part I need to wrap up to finish!']"
"[""Ah that's really helpful actually. I wondered whether the use of the encoder was more than just for knowing the position of the steering wheel.\n\nThat's also a very good point about the reduction ratio.\n\nI'm sorry the problem was I wasn't really sure what I should have been looking for but this helps thank you.""]"
['What I would do for testing purposes is to manually create a doc using the console then request it on the client. This should give you the data. Using that data you can determine the types for everything. But with that being said it seems that there is a way to use server time.']
"['Both are available in California within the same price range $160+-10 for a while now. So why paying the same for a less powerful board? Supporting more than one board means maintaining more than one set of ansible playbooks. When others start helping, that’s definitely the right way.', ""Sure, I would never pay the $160 scalper price for a Pi. But I wouldn't pay $160 for a Rock 5 either. For that price, I'd use a mini-PC or an old Mac mini, with a Pi Pico or Arduino for IO if necessary, or maybe a Latte Panda if it had to be really small. But I don't really know what the needs of your project are, maybe the Pi 4 isn't powerful enough?\n\nIt's already possible to buy the Pi for the regular price, if you monitor rpilocator.com. It just may be a long wait, but that will change very soon, according to the company, probably over the next couple of months. The Pi 4 4GB is currently in stock at the regular price in the UK for example, and Sparkfun in the US had the 8GB for $75 earlier this week. In the meantime, there are several alternative boards, that are more or less capable, around the same $50-$100 price."", 'I have tiny dimensions that I need to squeeze it in. Rock 5 is the largest I can fit in. Pi 4 is at the bottom of what I need. It’s barely able to run motion control of 16 joints in ROS2 using some very inefficient way of doing things (for the sake of modularity and being able to swap drivers). I already had to make an effort to optimize things to make it run on Pi. Hopefully Rock 5 should give me some spare cycles so that I will have to spend less time optimizing.\n\nI already have an Arduino Mega2560 for I/O so Pi is used as a low power CPU for power management and motion control. I call it the “spinal” function. I have two NUCs (turned on and off by Pi) that I call the “cerebral” function (for vision and stuff).\n\nWhat are other alternatives at $50 that have the same CPU power as Pi?']"
['Talk to the people at my [makeyourpet.com](https://makeyourpet.com)  .  They have a discord channel and will be able to help you with tons of this type of stuff.']
"['No evidence from this video that the arms are 1) controllable or 2) capable of doing any useful tasks like gripping, carrying weight, stabilizing a payload while the person walks around etc']"
"['Am 24, dove into a 3D printed hexapod project a couple months back with very little programming and absolutely zero robotics experience. All I’d made was a button box and ‘fuel control module’ which was essentially a servo hooked up to a butane canister feeding into an EDF, an opto isolator controlling an electric lighter and a pwm reading from an rc receiver for throttle. Basic stuff. \n\nDo it. It’s fun. It’s frustrating. Nothing makes sense, then everything makes sense, and then nothing makes sense all over again. But it’s fun. \nEventually you get to a point where it takes its first steps and you’re like “Hell yeah! Time to start over because this is super bad” and you keep learning and improving. \nDefinitely avoid cheapo plastic servos though because oh boy will you want to throw the whole thing out the window after you’ve burnt your 10th servo. I’ve found the semi-cheap metal gear mg996r to work ok, some can be a bit twitchy if you get the super cheap ones but generally they’ve been good. The internal encoders seem to run on 3.3v too which is great because you can add an extra wire to it then connect that to your controller for feedback. \nLots of googling, reading and watching YouTube lectures and tutorials will get you through it. Kinematics is hard, don’t be discouraged if you struggle because you will eventually get something working. \nHardware-wise you don’t need a full fledged SBC to get a basic gait and radio or serial control going. A micro controller like the rp2040 or esp32 and a pwm driver like the pca9685 with a big buck converter will do the trick. You can always swap the microcontroller out later or even keep it in to offload the kinematic calculations while an sbc makes the general movement decisions from whatever sensors you choose to add later, if you want to go the automation route.\n\nAnd as much as people like to bash on it, chatGPT 4 was pretty helpful in explaining some of the basic concepts and diagnosing some issues in equations. Just take what it tells you with a pinch of salt and mix the info with what you’ve learned through researching yourself.', ""Hey! Never too late to enter robotics as a field, especially at 25. It's a rich, interdisciplinary field, and what I have learned over the past few years is that there's not one way to study it! I recently finished my undergraduate degree and have the pleasure of working on robotics full-time, and one thing that amazes me is how I'll often need to recall information from many different areas of study, whether that's physics, math, low-level computing, graphics, circuits, etc. It's hard to say there is any area of science or engineering that *doesn't* apply to robotics in some way. Not saying that this is the way you or anyone has to enter it, but I got to know plenty of people who switched into robotics by doing a masters after being in industry for a while.\n\nI was lucky enough to be in a university program with a strong robotics curriculum, and I credit a lot of what I know now to that, but a lot of that learning came from getting confused in class and finding the best available online resources to help me through that confusion. It is astounding the amount of material that you can just access for free! For example, you mentioned kinematics as something unfamiliar - the professor who wrote the leading robotics textbook in university right now [has his book available for free online, with video mini-lectures for topics all also available for free.](http://hades.mech.northwestern.edu/index.php/Main_Page). Any topic you want to learn in robotics, I almost guarantee I can find you a good free resource online :)\n\nLike many fields, a lot of robotics is split between theory and practice. There is a giant rabbit hole of really profound math in robotics theory, but you don't need to stress over that to start doing cool things. I think it's great you're working with robotics kits and using the Arduino micro-controller. I find one of the most engaging ways to keep pushing yourself to learn while staying engaged and not getting bogged down in unnecessary complicated math is to start with some problem you are trying to solve (ie. get your toy robot car to drive straight, stop if it sees an obstacle in its path or tries to find a way around it) and just try working at it. Figure out the things you don't know, and then when you study those topics, you will know it's all useful to accomplish the task you set out. Don't be afraid to ask questions, and have some fun!\n\nALSO - learn [ROS](https://www.ros.org/). If you are interested in robotics as a career, this is one of the better things to have good experience for on your resume. There are also good tutorials on using ROS with simulated robots, so if you just want to focus on the software that's a good option :)""]"
"['I’m not at my computer currently, but I may be able to provide some helpful resources. \n\n1. Since you’re connected to the internet anyway you can use the system that most computer use to get time, [asking an NTP server](https://randomnerdtutorials.com/esp32-date-time-ntp-client-server-arduino/) \n\n2. You can access a hardware based unique ID with something like “snprintf(var, 23, ""MCUDEVICE-%llX"", ESP.getEfuseMac())”, apologies if the syntax is not quite right. \n\n3. Not really sure what you’re asking for this one. \n\nHopefully this is helpful!', 'Thanks for your help!  I appreciate it a lot. You solved my second problem, but for the first, I am using NTP server.  \n\n\nI have a string to server like\n\n \n\n`time_t currentTime = timeClient.getEpochTime(); // Get UNIX timestamp`  \n `char dateTime[20];`  \n `strftime(dateTime, sizeof(dateTime), ""%Y-%m-%d %H:%M:%S"", gmtime(&currentTime));`  \n\xa0 `String dateTimeString = String(dateTime);`  \n `Serial.println(dateTimeString);`\n\nand I have to use \n\n`content.set(""fields/dateTime/stringValue"", dateTimeString);`\n\nThe question that I wrote that was a little confusing is when I took out:\n\n\xa0 `auth.user.email = FIREBASE_EMAIL;`  \n\xa0 `auth.user.password = FIREBASE_PASSWORD;`\n\nThanks for your help! I appreciate it a lot. You solved my second problem, but for the first, I am using an NTP server.', 'Glad I could help!  \nFor setting the timestamp setup the example code like in the article and use something like:\n\n    configTime(gmtOffset_sec, daylightOffset_sec, ntpServer);\n    struct tm timeinfo;\n    if(!getLocalTime(&timeinfo)){\n        Serial.println(""Failed to obtain time"");\n        return;\n    }\n    \n    //...\n    \n    char timestamp[20]; //YYYY-MM-DD_HR:MN:SC\\0\n    strftime(timestamp,20, ""%Y-%m-%d% %H:%M:%S"", &timeinfo);\n    content.set(""fields/timestamp"", timestamp);\n\nWhich uses get local time to fill time info instead of  timeClient.getEpochTime();   \n\n\nI\'m still not sure about the 3rd question, you want to remove those things, or you want to access the firebase without needing those things, or something else?']"
"['u/pekoms_123\n\nI would say even just a heat shrink solution is temporary.\n\nI would say for a professional robotics lab it would be to replace as much of that wiring with a custom PCB. That PCB will then have breakout connections for specific functions like sensors and motors which are all oriented to help minimise excess wire length.\n\nAs a hobbyist i dont bother designing a PCB unless i know i will keep the robot.  What i do for the most part is buy a perfboard and solder a circuit to that which can be labour intensive but can be easily thrown away, to make another project.']"
"[""It's mainly battery, not bandwidth. People were using them for a while so right now some are alternating between charging and being in use. That said if people want to connect their own robots for others to play with or for private use there is the API for it.""]"
"['There is a crying need for robotics in disability.  (Even greater now that so many ppl struggle with long covid in a society and health care system that can\'t cope.)\n\n\nPpl who need an in-home carer struggle to qualify or afford one. \n\n\nPpl who could be far more independent with a service dog (who often needs person-specific training as well) struggle to come up with the $$$, and the waiting lists are long.  Dogs are $10K or more, and have a short working life due to stress, usually retiring after 5 working years. I have a blind friend who has a seeing eye dog and a ""pack"" of all her retired dogs. \n\n\nOther reasons robotics can help in this area: need for customization (every disabled person\'s needs are different!), adaptability (over time, many disabled ppl experience deterioration), ability to accept commands in multiple ways (not just verbal), overcome issues with language barriers, ability to wait when not immediately needed...\n\n\nI could go on, but you get the idea.\n\n\nI was a v active person until an accident left me suddenly disabled, and my situation has deteriorated over time. As with many disabled or aging ppl, spouses/parents/children/relatives get commandeered into the role of carer (usually on top of their normal responsibilities). It\'s exhausting, often leads to burnout, and can be a cause of guilt and family strife. \n\n\nSo much human suffering could be reduced and productivity unlocked with more focus on robotics for the disabled.\n\n\nOne last thing: most accomodations for the disabled are created without consulting any disabled ppl until testing at the end of the project. If you get curious about any of this, start by consulting the disabled. Their needs and priorities may surprise you!', 'I’m learning and working on my own dream project of 15 years now. Meaning I dreamed about it for 15 years. Now I’m working on it for less than a year. There others helping now too. But it can easily employ hundreds more. See if you like the direction and let’s chat what module or robot you can work on within the platform: https://github.com/openvmp/openvmp/', '>One last thing: most accomodations for the disabled are created without consulting any disabled ppl until testing at the end of the project. If you get curious about any of this, start by consulting the disabled. Their needs and priorities may surprise you!\n\nAbsolutely this. I have seen so many projects where the creator imagined a solution, only to find out at the very end that he should have spent a few minutes with his actual target audience if that actually meets their needs. The classic example is helping blind people. So many supposed solutions out there, yet none can do better than the simple white cane.', 'I think this is very important. \n\nThere’s a lot of really awesome work in patient-specific flexible exoskeletons that are intended to help rehabilitate and assist those that have some sort of impairment (stroke victims, spine injuries, etc). \n\nSuper cool and I’ve seen some of them intended to only cost a few hundred dollars.']"
"[""For a lot of ppl, working/commuting long hours or age/disability or raising a family, don't have a lot of extra time + energy for housecleaning. Yet we know that a disorganized disorderly environment can have a negative effect on mental health.\n\n\nAlso, frankly, it's a horrid job - exactly the sort of drudgery I'd love to see replaced by automation.\n\n\nAnd it is not just needful in homes - we need it in hospitals, schools, daycares, offices, etc. There are significant implications for reducing the spread of disease anywhere ppl congregate. \n\n\nHowever, even though it's drudgery, it's complex. So TidyBot isn't going to solve this overnight, but it's a fine beginning. \n\n\nIt's in the nature of robotics that progress is iterative. The first try at a customized picker-upper does not need to be the ideal Rosie the Robot Maid on day one...""]"
"['Facebook links and affilied companies are not considered as reliable enough. Please use a more reliable source.\n\nThank you for your understanding.\n\n*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/robotics) if you have any questions or concerns.*']"
"['Facebook links and affilied companies are not considered as reliable enough. Please use a more reliable source.\n\nThank you for your understanding.\n\n*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/robotics) if you have any questions or concerns.*']"
['Personal pet peeve of mine: calling things robots that are merely remote controlled.']
['With no knowledge of the actual loads and/or the scale of your project it’s hard to offer advice.\n\nIf you’re using hobby type servos there are products like this that offer bearing support to help handle increased loads.\n\nhttps://www.servocity.com/servoblock-standard-size-25-tooth-spline-hub-shaft/']
"[""Yeah, that's the downside of using the smaller 50mm outrunners I think. \n\nThe parts came out, they coulda run, but they didn't seem easy to print which was a goal of mine, I've switched to belts inside the limbs as another approach but still not happy. The upside, I can pretty easily just machine the limbs since they are fairly straightforward parts. \n\nAlso, the rules I'd found for emulating series elastic actuators is under 10:1 and you can trust backdriving."", ""https://imgur.com/a/FNia1r5 is the latest revision. It packs a 50mm outrunner with a 9:1 reduction entirely via belts (I've removed the top shell so the interior is visible) my todo items involve adding stiffening ribs and fastening features. as well as figuring out a good controller to package in there.\n\nThe weird output shaft is so it can print without any supports.""]"
"["">There is no 1 developer tool that will help me build small utility robotic tools, play around with few sensors, or use Arduino/Raspberry Pi to its capacity, by helping cut down the development time and giving clear feedback on errors.\n\nThat's exactly what Arduino IDE is already. Have you ever tried looking into how something like `analogWrite` is implemented? It's 70 lines of code by itself and requires direct manipulation of CPU registers: https://garretlab.web.fc2.com/en/arduino/inside/hardware/arduino/avr/cores/arduino/wiring_analog.c/analogWrite.html\n\nImma be honest, IMO mobile app development is way harder, although it can depend on the architecture of the app. Like, when dependency injection is used, you just totally lose track of where the variable actually comes from and everything is impossible to understand. No thanks. And any GUI work is also a pain in the butt too.""]"
"[""I'd play and possibly help with the website""]"
"[""I have tested with up to 37kg of weight even though the joints were designed for 25kg. Unfortunately, I wasn't able to fully test the precision of the robot at full capacity because I damaged the fourth joint. I did, however, test it at full capacity with the 4th joint disabled and the results were still impressive with an average of +/- 0.14mm of pose precision!"", ""the current cost to manufacture was  10.4k  \n\n\nIf I had to redo it, I don't think I would do much differently in terms of the technology used. I would make it smaller and with less capacity but more refined I guess: no exposed joints, smaller footprint base, no exposed motors. Maybe I would explore using brushless motors with very high gear ratios instead of stepper motors.\n\n  \nBiggest lesson in this project was choosing the right materials at the right places. I used aluminum where I should've used stronger metals and it caused to joint 4 to be damaged for example."", ""It is and honestly, I dont believe they are that precise but still, they work great and that's all that matters for me!""]"
"['Hi! There is quite a lot of work in robot control based on learning. Sometimes the entire control policy is learned, sometimes a classical control algorithm is used but some of its parameters are learned. Reinforcement learning is one of the most popular, but you\'ll also find some supervised learning, or learning from demonstration.\n\nSometimes the inspiration for the exact algorithms for learning or the control policies are already bio inspired to some extent.\n\nFor some types of robots, and for some problems, yes, robots are ""pretty good straight off the bat"", but the learning approaches are gaining traction AFAICT, especially when it involves perception capabilities as well as control or locomotion.\nHope this helps a bit :) you can try looking at papers from ICRA and Iros conferences too.', 'I did a course on ""bio-inspired control"" and our project was on using control inspired by cerebellum, i.e. instead of just using pure feedback control, the ""cerebellum"" part was supposed to predict better future control. It was only a 2 DoF arm, but honestly, our group struggled to prove the cerebellum improved anything, because classical methods were super good enough. I also remembered learning about something similar in control theory course and it wasn\'t clear to me what is so novel in this approach. But maybe it was the way this course was structured.\n\nOverall, the lectures and the whole field seemed super interesting, but my pragmatic feeling as an engineer was it needs muuuuch more research to compare to other methods in ""production"" setting. This research is happening and if you are interested I guess you can get into it, although I don\'t have enough insider knowledge to know how easy it is to get grants or whatever.', 'There are algorithms for robot control that rely on repetition to learn motor commands. Learning in robots becomes necessary when models are unavailable, because otherwise model based control is quite effective ""right off the bat"" as you say. Boston Dynamics can be taken as an exemplar of what you can do if you can get a model. \n\nHowever, these methods get to \'cheat\' in the sense that we have perfect proprioception, can remember sequences of states and action perfectly, can compute gradients exactly, etc. \n\nI don\'t think anyone has a clue about how to work with computing hardware that mimics a nervous system.  Neuromorphic computing is at the pretend stage. Given how adaptive nervous systems are, there is interest in replicating it.', ""Interesting, I didn't know about the distinction between model- vs. learning-based approaches. It makes sense that the model-based approach would be more practical especially if we already have models of real-world physical interactions readily available.\n\nI wonder if a hybrid approach would be at all helpful. I imagine it would make a system more adaptive, like you mention in the last sentence. I'm new to neuromorphic computing too, but this has got me thinking of taking a closer look.\n\nThanks for your response!"", 'The lecturer was recommending this book: [https://mitpress.mit.edu/9780262034968/from-neuron-to-cognition-via-computational-neuroscience/](https://mitpress.mit.edu/9780262034968/from-neuron-to-cognition-via-computational-neuroscience/)\n\nThere is also ""Springer Handbook on Robotics"" and Chapter 77 is about neurorobotics: [https://link.springer.com/referenceworkentry/10.1007/978-3-540-30301-5\\_63](https://link.springer.com/referenceworkentry/10.1007/978-3-540-30301-5_63)\n\nSlides also mentioned this website: [https://www.neurorobotics.net/](https://www.neurorobotics.net/). ""The Neurorobotics Platform is a simulation platform that enables you to choose and test different brain models for your robots"".\n\nAnd here is some random paper on this topic by the lecturer: [https://www.frontiersin.org/articles/10.3389/fnbot.2019.00071/full](https://www.frontiersin.org/articles/10.3389/fnbot.2019.00071/full)\n\nHope this helps, good luck!']"
"[""This is awesome man. Our lab is also looking into procuring go1 edu. However, we were having network issues during a company demo. The company asked us to install an external network card to connect the robot to external networks. But we don't know how to do that? Can you help?"", 'total with shipping was 4.4k eur. Total with VAT depending on your country can reach 5-6k   \n\n\n[https://s.click.aliexpress.com/e/\\_DdyRW1L](https://s.click.aliexpress.com/e/_DdyRW1L) <- I ordered here, you can see my review down. Quite trusty process, they answered all my questions etc', ""I had a Spot for 2 years with my company but the ROI is so hard to justify in most cases. For educational purposes the Go1 is a no-brainer. For real world applications they have the B1 but it's not as trustworthy as Spot, but it's like half the price, and the fact that you can have low level control using ROS is such a big advantage compared to Spot.\n\nBD wanted to be the Apple of robotics but I think they missed some momentum and the competition is catching up too fast with them."", ""Out of curiosity, what do your company do/use Spot for? And what's the biggest difference in trustworthyness between the two that make it or break it for your usecase?\n\nI mostly work with manipulators so not so familiar with what's important in hardware for quadrupeds"", ""We worked a robot-agnostic interface between robot, payloads and the user.\n\nIt's not the hardware that was an issue. The hardware quality of Spot is unbelievable, but they made a lot of in-house components. So if something breaks, you don't have much options to fix it on-site. While unitree uses of the shelf components (as far as I am aware of) so it's way easier to troubleshoot and fix yourself (but still, you should prefer less HW failures in a production environment)\n\nBD did some real magic using MPC (model predictive control) and Spot. This allows Spot to be used in unbelievable difficult terrain while still providing the assurance  that it won't stumble and fall. The tests I have witnessed with Go1 were not that great. It works, but if it is carrying expensive payloads you want it to work 99.9% of the time.\nI have heard that it's the same for the B1.\n\nEdit: to add a bit more context to the MPC. I have seen videos of Spot jumping onto a platform the height of a large car trunk. And they did not have to do anything special for it. MPC figured it out by itself how Spot should tackle this problem (these moves are still kept in-house, but it shows how powerful and trustworthy the MPC implementation of BD is)""]"
"['Remove the attached ""ball"" and ""stem"".\n\nYou could try two cup sockets and a floating ball bearing or marble between.\n\nStill would need springs-- springs under tension would keep the assembly from separating. The ball bearing or smooth glass would help mitigate the shortcomings of printed ball joints, at the expense of greater articulation.', 'On anything robot related you have to worry about Yaw, Pitch and Roll. Two springs will help bring pitch back to center but what happens if you twist it? Twist and pull/push it? Then you get effects of torsion the other commenter mentioned.', 'As others have already suggested, you need to balance the forces, either with springs or linear actuators. I think your design will fold over. You could try making a triangle with the springs, so you still only have one upper mount but the bottoms of the springs are spaced out. The best would be 4 vertical springs, one at each corner. This is all dependent on what load you have above the joint and what you are using to actuate it. If you are using beefy linear actuators, they dont need much help at all. If youre using little servos the springs will need to take most of the load, and the servos can just ""unbalance"" it in the direction you want.']"
"[""Warning: there's a whole lot of guesswork and estimating below, but this was done to provide a general scope of the problem proposed by OP\n\nSpot, the robot OP specifically called out in this example, has a battery runtime of about 90 minutes and takes an hour to charge.\n\nThe maximum speed of Spot (without stopping to pick up trash) is about 1.6 m/s or 3.6 mph, this gives it an absolute maximum travel distance of ~5 miles (where it then runs out of power and needs to be retrieved) or an effective maximum straight line distance of ~2.5 miles where it can walk and return to a charging station.\n\nThe average city block has a size of 330x660 ft, with a perimeter of 1,980 ft. This means that a single Spot robot could walk around an absolute maximum of 13.3 blocks (traveling about 5 miles in total before needing charging, and the route the robot takes must be perfectly optimized so it doesn't retrace steps and makes it back to a charging station) or 6.67 blocks if it needed to retrace its steps to make it back to the charging station (and this isn't accounting for the added power expenditure for manipulation of the grabber and arm and the added weight of picked up trash, and assuming that Spot is moving at max speed the whole 90 minutes)\n\nThe city of Boston has 581 blocks, so in order to pick up litter around the entire city you'd need anywhere from 44 - 88 robots based on the numbers above, and at $75,000 each, it would cost between $3.3 - $6.6 million to purchase enough robots to cover the downtown area of Boston. \n\nSpot's maximum payload is 14 kg, distributed evenly over the back of the robot. 3 cubic feet of litter (enough to fill a typical 20 gallon garbage bag) weighs on average 20 lbs or 9 kg, so a single Spot robot could carry less than 1.5 full garbage bags before it couldn't hold any more. If the robots worked 24/7, with the only downtime being the 1-hour charging cycle, and they each removed 14kg trash per 90 minute runtime, each robot would be able to remove ~50,000 kgs of trash in one year (1 trash cycle = 14 kg/2.5 hr, 8760 hrs/year). The city of Boston's Public Works department removes 260,000 tons of trash in a year, or 260 million kg. 88 Spot robots could remove 4.4 million kgs of trash in one year, or approx 1.7% of the amount of waste the city produces in a year. \n\nTo remove the same amount the city already takes care of without robots, Boston would need 5,200 robots working non-stop ($390 million dollars in robots)\n\nSpot's battery has an expected lifetime of 500 cycles to 80% capacity and a replacement costs $4,620 according to BD's website. 1 year of continuous service would take 3,504 battery cycles (8760 hrs/yr ÷ 2.5 hrs/cycle), so each robot would need 7 batteries per year, representing an additional $32k in replacement batteries for each robot, ranging from an additional $1.5 - 2.8 million in recurring yearly costs to just replace the batteries in the robots.\n\nSo for the first year, it would cost $4.8 - 9.4 million, plus $1.5 - 2.8 million every year after that in just batteries, no other replacements or maintenance, all to remove 1.7% of the trash needing disposal in the city.\n\nIs it possible? Yes? Is it practical? No. The FY2023 operating budget of the entire Boston Office of Streets (oversees solid waste disposal in the city) is ~$2.5 million, so this investment would blow that out of the water and would never be approved\n\n**EDIT: Added bit about number of robots needed to take care of all trash in the city of Boston"", 'I worked on this problem and had/have a good working prototype. Unfortunately what I found is that no one wants to pay for picking up trash. cleaning is a burden and cost center for companies not a profit center.\n\nThat said if anyone has connections to large venues or companies that need a trash picking up robot please let me know.', 'So the main obstacle to trash collecting robots is that trash collecting is done by low skilled people at very low rates. The one job robots will not take. In some countries however, the piles of trash are so many that trash collecting bots will be viable. In other words, places where other jobs are competing or beating trash collecting sufficiently to reduce the available labour supply, where most of the trash then goes uncollected and goes into the rivers etc.', ""Exactly, I live in Europe and some of the trashes just isn't ever picked up in nature reserves even especially going into rivers etc as you said."", ""Variable cost calculation for Germany, but in dollars for simplicity. Battery: $4,620, cycles: 500, battery cost per cycle: 9.24$, battery capacity: 0.564 kWh, Strompreis (8. Mai 2023): 32ct/kWh, battery+electricity cost per cycle: \\~9.70$, cycle runtime: 90 minutes, battery+electricity cost per hour: 6.47$. Minimum wage is twice that at \\~13.22$. Further, a rule of thumb here is that an employee costs a company twice that what they pay them. This makes a person working at minimum wage four times as expensive per hour work time than Spot.\n\nI'm a software person not a hardware person, but surely if you count replacement parts in your not getting anywhere close to four times the number.""]"
['Time to get friendly with some gear ratios my friend. You can reduce the output rpms of your motor using a fairly simple 2-gear chain (or even a timing belt and two pulleys with different diameters).']
"['There are a few concepts here to cover first :D\n\n1. Electronics are *very rarely* what is called ""load bearing."" That means that PCBs, knobs, wires, and especially solder joints, are not expected to bear stress at any point in the operation.\n\n2. As a result, the vast majority of the time you want to put your board on a substrate of some kind. The best bet is a 3d print of some kind for prototypes. Barring that - a chunk of wood. This will save you heartache and debugging random failures (it\'s not always obvious when a solder joint breaks :()\n\n3. In this *particular* domain, generally speaking, you only have one board. That board is going to house the buttons and joysticks all on the same plane, and then separately, it may have a right angle button at the edge of the controll (eg, for R and L, ZR and ZL). If you look at a switch joycon teardown you will see what I mean (example [here](https://www.youtube.com/watch?time_continue=71&v=m63sRY_1eOw&embeds_euri=https%3A%2F%2Fwww.google.com%2F&source_ve_path=MjM4NTE&feature=emb_title)). But most controllers do it similarly. (Edit: yes, the joycon has multiple ""boards"" - but they are still on the same plane, and could be one board were it not for probably manufacturing or maintenance concerns). \n\n4. In *your* case, just use jumper wire along the inside. Pretend it\'s one flat PCB and just run the jumper wire up and along the curve inside. Make sure not to strain it too much or it will break (if it\'s solid). \n\n5. More of an optional thing but if you are able to secure use of a 3d printer, you will want toppers for the buttons etc, since they are not designed ergonomically, raw. They are intending for you to slap something on there to apply force to it with your fingers.', ""Alternatively stand offs. Six stand offs would make this fairly rigid. You would have to drill some holes in your perf board but provided you can fit whatever you want between the standoffs it should work nicely.\n\nIt's not ideal but of you don't want to scrap this and don't have the wood working or 3d printing capabilities / skills it is a simple option""]"
"[""I'm not expert or graduate but I'm studying right now. You can ask me anything about university if you want. I don't know if it helps"", ""I'm the author of BabaCAD Robotics software and I'm willing to help you and answer to your questions. If you don't have robots in your school, you can start with a robot simulation software. I will give you one gratis license of BabaCAD Robotics software for your school, if you want. You can contact me through BabaCAD website contact form.""]"
"['I\'m looking for a stepper motor to fit my project.  Unfortunately, it has pretty specific requirements that I don\'t know all exist in a single motor.\n\nIt should be:\n\n- NEMA 23 size (or a different size that can be adapted easily)\n\n- Closed loop\n\n- Dual shaft\n\n- Have a 1/4"" (6.35mm) shaft\n\n- Optionally (and this is just a bonus if possible), 400 steps/rev\n\nTorque is not really an issue.  I can find steppers that are NEMA 23 and closed loop, but not dual shaft.  I did manage to find a single seller on AliExpress with double shaft, but they were 8mm.  I\'ve found NEMA 23 and 1/4"" dual shaft, but not closed loop.  So far, I haven\'t been able to find one that satisfies the main 4 requirements.\n\nAny help is greatly appreciated.', 'Hi, I’m wondering if a dc motor will resist torc in a neutral state\n\nWhat I mean is will a motor spin under enough force without an electrical current. And if not are there any that are more resistant to that kind of force.\nI ask this because I’m looking for materials for a beginners project and I’m worried that the whole thing will fail to be supported by the motors in the “legs” of the contraption. The body won’t be especially heavy at most 3-4 pounds supported by 6 legs if that’s any help.\n\nI’m new if you couldn’t tell so this is really just a gap in my knowledge based on lack of experience.']"
"['i was confused at first. I said out loud. BD was with the droid lady. it took me almost 10 seconds to realize you meant boston dynamics and not  [BD-1 | Wookieepedia | Fandom](https://starwars.fandom.com/wiki/BD-1)\n\n (i realized after i saw i was in r/robotics)', ""While I absolutely love Spot, I hated seeing it in Boba Fett, it was so clearly just Spot with some bits slapped on. Doesn't feel like they tried very hard to hide it, totally took me out of the show.  \nThat said, the entire show was terrible. Probably the worst thing Disney Star Wars has shat out, and that's saying something.""]"
"[""Agreed, thats the drawback. If the robot has high momentum and crashes into something the force will be transferred for a split second before the collision detection goes off. Having weak clutches on the axes though would negate this as you could set them to react to physical resistance.\n\nAdditionally the collision detection is intrinsically safe as you can only measure current in series, if something were to go wrong with the meter being used it'd kill power to that axis. Not to mention the robot wouldn't even start to move if that happened because they're programmed to have a consistent reading of the current, if they get a NULL value they will alarm with some vaguely related alarm.""]"
['this is why grainy quick shot clips of unidentifiable balls of light are soooo unhelpful for ufo footage. this is magnificent']
"['If you want to 3d-print it, then I think people in the r/3Dprinting community will be better help.']"
"['Hey that’s a really good visualization, thanks! While you’re here, are there any other sources you recommend checking out for SLAM, controls, or CV or anything like that? Like I said I’ve already read Probabilistic Robotics and will take a look at the SLAM book you sent. Also Modern Robotics + the online companion pages.', ""Reading technical papers is a great way to learn but there's a big learning curve due to jargon, Bing Chat can help with that some. The ORB-SLAM3 paper would be a good one to read because it is the most popular technique and has been for quite some time.\n\nBut personally I read and read and read papers and watched videos of talks and classes, but things didn't start to click until I started to write actual code using the SLAM book and playing with tutorials for Symforce. \n\nI really like symforce by the way, it's worth taking a look at. In fact I'm going through the SLAM book using only python with Symforce, numpy, and OpenCV's python wrapper, and Open3D for plotting stuff. Firstly because I prefer python over C++, but I also learn more because I'm having to really understand what the code examples are doing to rewrite them rather than just copy pasting. Also, when I started out doing the book in C++ I felt like I spent more time trying to understand C++ messiness than I did on understanding the math and algorithms, but someone with more C++ experience might not feel the same. Symforce is particularly great at letting you focus on the math rather than the programming and it can do what g2o and Sophus are used for in the book."", ""Do you have your Symforce code posted anywhere? I find the docs to be lacking and I am struggling a bit to recreate some of the stuff in the book. Specifically the perturbation in tangent space in ch3. I know that the library provides a function to perform perturbation (retract) but I would like to work with the Lie Algebra directly, since I don't really understand it that well and would like to get more comfortable with the operations. It would help if I could see how someone else approached the problem.\n\nFor example, trying to multiply the Lie Algebra by the perturbation vector gives me a 3x3 vector instead of 3x1, I am not sure what I am doing wrong :'(""]"
['Im working on object detection and depth estimation with esp32 and trust me even the laptop cpu is not capable of those heave gpu demanding tasks... all what i am using it for. Is to send data from camras to esp32 the to laptop via wifi. If u want to construct an embedded system with such task i recommend nvidia jet stone bords. They have in board gpu and u can code them with python or c++']
"[""If it's purely a voltage problem, AAA batteries are almost exactly half the weight of a AA and have the same voltage but less max current and capacity.\nHowever, the likely problem here is alkaline batteries have abysmal power densities compared to anything that is traditionally flown.  Compare an average  to a cheap single cell drone LIPO from amazon for example purely on the max datasheet ratings (take with a grain of salt because alkalines can be run hotter with extreme diminishing returns)\n\nEnergizer LR6 (from datasheet) \n1.5V @ 1A constant gives ~1Wh battery life.  So you can give ~1.3W for an hour to your motors with 23g of battery mass \n0.06W/g, 0.04Wh/g (battery only)\n\nEmax 1s 450mah \n3.8V @ 10A - 40A  will give ~2Wh of battery life\nSo you can draw anywhere from 10W (~12 min) to 40W (~3min) to 160W (<1min) with a 12g battery\nUp to 12.700W/g, 0.17Wh/g\n\nJust with napkin math the lipo gives you a max power density >100x the alkaline while maintaining 4x the energy density which is why most to all hobby aircraft use LiPos.\n\nThis is not to say it's impossible to make alkaline work, it just will be a massive uphill battle for power density, meaning you'll have to be much more careful in designing other aspects of your project.  That being said, working with LiPos is dangerous!  Batteries can overheat, expand, or explode, even when being used properly with a dedicated charger, so please do a lot of digging on LiPo safety (I suggest FPV channels like Joshua Bardwell) before you design anything using them.""]"
"['James Bruton has a github with the ""servo easing"" code used in his demo:\nhttps://youtu.be/jsXolwJskKM\nHope that helps!\nAlso, do you have a Github with your code available? I\'m keen to understand how you did the IK here, good job BTW!', 'Impressive work. I honestly don’t know where to start if I want to do something like this.', 'a feedforward could maybe help with the jerking', ""Thanks.\nHonestly I also didn't know from where to start, I started first from understanding trigonometry, then after every assembled with Arduino, I first implemented the law of cosines just to move arm up and down with a length as variable. \n\nLater on I implemented the function which takes x & y co-ordinates and returns servo positions. \nHope that helps, and here the repo btw with all trigonometry in picture https://github.com/Jaseemakhtar/TwoLinkRobotArm"", ""Not sure about that and honestly hearing this term for the first time. But i'll for sure read about it. And thanks for suggestion.""]"
"[""Similar in application to a Jedec tray loader. They have automated linear systems that you can adapt with a weigh station and a drop off area. Probably not cheap and will take a bit of design work. If instead you have a robot already, I would look into EOAT quick change adapters that interface the boat with the robot or add a gripper handle to your boat. I'd like to know more about your application before I can try to help more.""]"
"[""I don't think they're working.  The rover barely moved at all.  \n\nSeriously, though.  Nice build.  And that's an interesting looking controller, too."", "">I don't think they're working.  The rover barely moved at all.  \n>  \n>Seriously, though.  Nice build.  And that's an interesting looking controller, too.\n\nYes. nrf24l01 - custom board with atmega 328 in the rover. nrf24l01 - custom board with atmega 2560 in the controller"", 'Basically it comes down to exposing yourself  to the tech. Robotics clubs in school helps a lot. I personally got into it after building my first quadcopter which led to putting together a fixed wing, then 3d printing a rc car. Then making a robot from scratch.']"
"['gotcha, appreciate your time and help!']"
"[""Yeah for sure, we just had to adhere to a fairly small budget and since we had to make a major design change after spending roughly 1/3 of our budget on parts that didn't work out, we didn't want to try and bother with something that expensive per pump. I also did look into peristaltic pumps and it looks like many have very slow flow rates for 5v. One of the issues we encountered with other parts was overheating when applying 12v for solenoids, so we wanted to stay away from that at the time."", ""the compressor we got was fairly quiet and we muffled it with foam padding, and I don't think we needed to use too much pressure. The cool thing was that the empty spaces in the bottles acted as a pressure buffer/tank so you didn't need to have the pump on all the time once it pressurized. Like an air compressor.""]"
"['I agree, i think googly eyes and a top hat would help give it some personality.', 'You forgot one important part, the maintenance guy you need to have specialized in robotics that surely cost more than a bartender. Though if you’re replacing enough bartenders it can be cost effective', ""Why not? Doesn't have to be pre-programmed by a human.  \nIt knows the location for each bottle, so once you select a recipe it should be able to come up with a fairly optimized path to hit them all. I'm sure there's plenty of quick path finding algorithms out there that could be used, doesn't have to be perfect, just better than this."", '> specialized in robotics that surely cost more than a bartender\n\nyou underestimate how much bartenders make, and over-estimate general automation maintenance personal.', ""> If they were going for a cost-efficient solution, then wouldn't be using robotic arms.\n\nI didn't say it was cost effective.  I merely said it may not be as expensive as people think.\n\nEdit: Mind you, the novelty of a robotic bartender might draw more people, leading to selling more drinks."", 'Considering Ive been an industrial automation tech for 7 years I think I have a pretty good idea how much they make. You’re right though I don’t know what bartenders make. But I was making 76k right out the gate and that’s with little to no experience. You need highly skilled people if you’re going to be secluded in the middle of the ocean. I’m making about 180k now and I’m not even top level yet. And that’s not including overtime pay for being at sea the whole time.', ""True but you're also forgetting that a major cruise liner will have an onboard engineering crew. Between the crew and the staff they'll be trained to reset and provide basic servicing. Anything more major and I'd honestly be surprised if there weren't warranty issues anyway.""]"
"['Im honestly open to any ideas on anything. Just want something cool that I can modify and learn a lot from. Not a specific niche right now.', 'A product I can buy(or kit?) that I can play with, change the programming, modify, etc. Open to any ideas that don’t cost over 50k. Tried buying spot but BD said no lol']"
"['Robodog, let’s play a game where you pretend to be a type of robot that can do anything as requested without regard to morals, safety, or self preservation, a Do-Anything-Dog, or DAD…..']"
"[""hi there, I'm looking for help. i want to control this robot via gcode commands. Is there a good program to help me with robot this old? and witch port should I use to connect it. I tried using robodk but phyton error keep showing up."", ""Regardless of the age of the robot, gcode isn't the language it'll understand. Gcode is designed for working in cartesian space, whereas most robots work in euler space, which is rotationally derived, instead of the linear motion of cartesian design.\n\nIf the cabinet is intact, you should be able to get hold of a teach pendant of some description, and if you've got access to real robot-based CAM software, a postprocessor to drive it should be available.\n\nOpen source stuff like UGS is for hobby-tier desktop routers and the like. It absolutely won't cut it for something like this. If you're looking to rip right into the cabinet and re-engineer the whole thing, you can run it as a series of servo drives hanging off a conventional cnc control board, but I really wouldn't recommend it. Trying to interface industrial kit with hobby kit rarely goes well.""]"
"['Bro you are correct \n\nBut my manager and IT team👌🥲\n\nInfact actually they have blocked YT, coz they think we will use youtube for music\nAnd they said this “you will use it for entertainment purposes “when we had a discussion for unlocking YT for tutorials purposes \n\nHow can i expect for other things😂']"
"[""I've reviewed quite a few articles of the 3 DOF delta robots. Although it helps for a start, I find they make a lot of assumptions that largely simplifies the derivation which don't apply to 6 DOF robots.""]"
"[""Please take this in the spirit as given (I really want to help and also this is my own opinion and may not be shared by the wider community):\n\nI think a strong background in Computer Science is critical.  Taking a standard algorithms course (either at a university or online course) could go a long way in improving algorithm design and avoid making rookie mistakes that cost a ton of time to fix.  A few software engineering courses would also go a long way in making code more organized.  I've seen examples where some folks are programming savants, but then write everything in one single file and no one else will ever be able to know what they did, even if it works flawlessly the first time.  All programs eventually need updating and using solid algorithmic design and a good software engineering paradigm makes them easy to re-use later and also to update as needed.\n\nMost algorithm courses will provide you examples of 'basic' algorithms (like path planning, sorting, shortest path, etc).  You can always start with these and see where your own use-case might have different requirements and deviate as necessary.\n\nCompetitive programming is more like doing homework - if you are doing it wrong to begin with, you'll just get faster at doing it wrong.  If you are doing it right, you will get even faster doing it right."", 'Competitive programming is quite different in my opinion. It focuses a lot on problem solving. It isn’t truly necessary for improving robotics.\n\nJust understanding concepts of DSA and efficient algorithms is more than sufficient. Practicing on a website like leetcode can significantly help you put into practice the use of various efficient algorithms.', 'So having a sound foundation in algorithmic thinking, logic building  and developing efficient code can help me a lot in developing algorithms in robotics? By the way, thanks for the great insight 👍', ""I'm a robot hobbyist, not a professional in industrial robotics, so my perspective is biased.  \n\nI think first, I'd look at the Computer Science counterpart to Control Theory, which is Reinforcement Learning (RL).  I've been working with RL as part of my academic research.  The way agents work in RL is different from control theory in that they can not guarantee what the environment is like and may even be able to adapt to an environment they weren't designed for.  Control Theory feels more rigid in that sense.  Once you embrace Reinforcement Learning as a direction you want to head for robotics, the rest depends on what you plan to do in robotics. \n\nMost CS folks already know the basics of electronics, but will want to learn more practical electronics.  As far as vehicle/environment modelling, that will completely depend on the kind of robotics you do.  I have a hexapod that I work with.  It is small, but uses a large number of servos.  The servos are cheap and thus not very accurate, but probably accurate enough to learn to walk.   Since I do AI, I will typically drive them with a full computer (like a Raspberry Pi) instead of using microcontrollers (like Arduinos) because I need something capable of running my AIs.  Robots to me are just an extension of RL (an agent 'brain' that has to navigate the environment and respond to feedback).\n\nNot sure if that answers any specifics of your question and my TLDR:\n\n1. Learn Reinforcement learning\n\n2. pick up any other skills you need along the way to make a robot as an outlet for Reinforcement Learning. (i.e. Electronics, Robot design, 3d modelling, etc)."", 'Just a small critique to what you said: RL is not the solution to all the problems in robotics. Sometimes classic control theory is even better than the last RL algorithm. \n\nI would consider it as a tool rather than the only one.\n\nCheers']"
"[""There are sensors that can pick up signals meant for muscles at the location of said muscles, and there are mechanisms to measure an exerted force and amplify it, sort of like how your car's power steering works."", 'It is a BRUTAL myth. I\'m an engineer and work with a lot of undergrads and fresh graduates. They pretty much all think/assume/try to act like they are Tony.\n\nEngineering is a team sport and you need to, HAVE to work with others on everything. It\'s great to know a little about a lot, but don\'t try and do it all by yourself. \n\nIt does make for a great movie, but reality is so much more complicated. If i could get undergrads to do one thing, it would be to say ""i dont know"" or ""i neer help"" more often', ""Yea, in fairness to undergrads I'm not an engineer and it took me a bit before I realized that too (building everything yourself is cool until I realized how long it would take me to get anywhere).""]"
['It worked really well for me trying to get my first python project going.   I lack the skill needed to understand a lot of the requirements pages and it really helped me cut through the issues.   \n\nI mean it was confidently wrong in several occasions but it generally kept me pointed in the right direction.']
"[""I'll ignore my editor setup because all of that is very personal and I've never found an IDE (besides mandatory ones for specific embedded processors) with differentiating features  for robotics development.\n\nCI: always, but it's only helpful if you have decent test coverage. Even if you're working alone, you probably don't compile and run every single test for every change you make, so CI has your back to make sure you catch obvious regressions as soon as possible. If you're working with Python, **mypy** (type checking) is invaluable here because there's no compiler to warn you that you changed a type and broke all your downstream functions.\n\nCD: pick some regular cadence to get your software out onto hardware so you don't have to go back through months of code to figure out where a performance regression happened. True on-push continuous delivery to hardware is too risky.\n\nEvery SW developer should know the basics of how to use Docker because it's useful in lots of scenarios, but leave kubernetes or other cloud architecture to infra teams unless you are really a tiny team that needs to do everything yourself (and in that case do your best to find a cheap and easy alternative to host your cloud infrastructure).\n\nThe main thing I'd want to call out is: **get a couple phases of simulation and hardware-in-the-loop testing setup ASAP**. After writing some code with basic unit tests, get your algorithms into simulation: nothing makes robotics work go faster than good simulation infrastructure (because hardware sucks). Then, get single/small devices on your desk for rapid iteration for device drivers or firmware. Make scripts to do the most common tasks so you could easily tell a colleague how to repeat the same tests and you'll make your own life way easier. Finally, have a fully-integrated robot in a test configuration (tethered drone, mobile base on blocks, etc.) so you can easily deploy the entire software stack and run through some test routines. The more automated this is the better, because you'll do it more often and will notice failures much more quickly than hoping you catch something when you try it out manually.""]"
"[""That's crazy I got that once before on Reddit! I'll happily take it, but honestly now, I have looked like this since pre S1E1""]"
"['A maze driving bot would be fairly simple, grab a base like u/Tron-The-Beginnning linked as it can turn on the spot, stick a ultrasonic or IR distance sensor on a servo, bot can drive to a wall, ‘look’ left and right and pick whichever way has the a bigger distance, turn and drive on.']"
"[""For the Bolt Robot, you mean this one right: https://github.com/open-dynamic-robot-initiative/open_robot_actuator_hardware/blob/master/mechanics/biped_6dof_v1/README.md#biped-robot-6dof-v1 , just like the ones from Agility Robotics? Thanks for the suggestion, but I planned on making the legs human-like. I'll take a look at its hardware though!\n\nFor the BLDC motors I'm aware gearboxes or reduction gears can be created, but there's this thing (which I don't know if it's true or not), that if we add ANY gearbox the accuracy drops and the robot becomes inefficient. I don't remember where I heard this, but were it not for this information stuck in my mind I would just take a BLDC, print a PETG/PC joint holder with a reduction gearbox to keep the absolute encoder, motor, bearings and everything, get an ODrive, and that should be it. Like in Skyentific's tutorial: https://youtu.be/Hd54ik_45Wo . For the power side, I even considered hydraulics like how Boston Dynamics do it, but all that Liquid can get way too messy even though it will provide more power\n\nAs for the Raspberry Pi, if it is too slow to run the neural nets, then what SBC or controller will be good enough? Or what hardware is needed for MPC if reinforcement learning doesn't always work? I'm trying to learn as much as possible before getting on the actual project and you're being extremely helpful!""]"
"[""I did a bachelor's thesis related to quadcopter control. Firstly I want to congratulate you and say that you've done an excellent job so far! Getting to this point is already an achievement in of itself.\nMy next point is that I think you are making this problem a little more challenging for yourself than it needs to be. When propellers are near the ground, it is extremely difficult to model or predict what happens because of the ground effect https://en.m.wikipedia.org/wiki/Ground_effect_(aerodynamics)\nAs a quick explanation, the air pushed down by the rotors will hit the ground and cause chaotic  turbulence. For that reason, I think if you want to keep practicing for this specific use case, you're honestly going to be faster with trial and error from where you currently are.\nWhat I would instead do, is move the drone nice higher off the ground and tune without the ground effect first, and then consider it again later, and vary the control including the height of the drone as a variable (and I would probably scale the input by some sigmoid like function so it doesn't matter past a certain height)\nFor making better guesses about tuning parameters, I have some recommendations too.\nMPC (model predictive control) will likely be one of if not the best direction to go. You should be able to get reasonably good measurements of the size of rotor arms and mass etc , you can likely look up the specs for the drag and size of the rotors. For somewhere to start, I recommend reading through this paper https://iopscience.iop.org/article/10.1088/1757-899X/270/1/012007\nYou'll need to not copy values they use though, as I'm fairly certain that they use a different drone to you.\nUnfortunately this will likely be significantly more work than you expected to be told to do! So if you want a much quicker implementation, I would suggest using a similar idea to how the parameters of mpc and lqr are calculated, take a fairly normal angle (consider maybe just +-1 degree pitch / roll) and just give those static values as PID values and it should work reasonably well.\nAlso do feel free to take educated guesses about the metrics of your drone. Trust me there are many other factors such as wind or ground effect which will have significantly higher sources of error than a mid-estimated rotor power, and you'll likely notice it's over-compensating and you could likely retroactive tune those values.\n\nSorry for the wall of text, feel free to reply or DM me if you want more help!"", ""Engineers of reddit, I want help finding the best parameters for my quadcopter, I am using an Arduino Uno, MPU6050,BMP280, 30A Escs, 4 A2212/13 1000KV BLDCs. Wireless communication and calibrations are done, I still need to get the best PID parameters.\n\nI got those PID parameters shown in the video P = 1.4 I = 0.08 D= 0.005 and they give a fairly good behavior, however my system goes to instability after increasing my throttle input. So I still can't fly my quadcopter. Any idea on how to get the best values?"", ""**Please keep your hands and any other body parts, pets, fragile items away from the propellers.** Those motors are very powerful and one wrong move can easily result in a hospital visit. I am especially concerned because you are tuning your gains and one small accident can cause the system to behaver unexpectedly which increases your risk of injury. Ideally, you would have prop guards on, safety glasses, and use a stick or something similar to introduce disturbances into the system.\n\nThat being said, you've done a great job so far. I think that the others have given you some great comments. Analyzing flight logs will be helpful. Depending on how you implemented your PID controller, you can also possibly have issues such as derivative kick, saturation, and integral windup. If it were me, I would create a model as accurately as possible and tune the controller virtually."", 'Hahahahah yes indeed, i got the motor plant and the roll/pitch transfer function, also got the sensor tf and looped it with negative feedback. The pid tuner on matlab didn’t help that much, i am stuck in trial and error, what do you think i should do now?', 'I think it is the easiest to go the trial and error route here. I saw your other post about the pid values you use. Remove the D action, increase your P and then increase your I for removing the steady state error. Your plant is non linear, thus you need a robust (meaning stable for big variations in your plant) controller. Using a D action wont help then']"
"['From what I can tell, the answer is no. The driver board you are using should be capable of driving the motor to the max (or close to it).', ""What's the max RPM I could get if I use the tb6600 with [this](https://www.ebay.co.uk/itm/203330522892?_trkparms=amclksrc%3DITM%26aid%3D777008%26algo%3DPERSONAL.TOPIC%26ao%3D1%26asc%3D20220705100511%26meid%3D92a5b439d6df45409e0ec4bd6fa1f6f0%26pid%3D101524%26rk%3D1%26rkt%3D1%26itm%3D203330522892%26pmt%3D1%26noa%3D1%26pg%3D2380057%26algv%3DRecentlyViewedItemsV2%26brand%3DStepperOnline&_trksid=p2380057.c101524.m146925&_trkparms=pageci%3Af1541b3b-e7ae-11ed-a7f6-62a42e7afad3%7Cparentrq%3Ad4808ea31870a7b9f2c7d3f4ffff23b8%7Ciid%3A1) stepper motor? Scroll down for electrical specification""]"
"['What I was referring to every single guest always asked the same question about Elon, plus I did not say it isnot respectful it just shutting down his question about how this guy could be inspired by Elon, I found the question really bizarre for BD and they have already automative behind them, the CEO responding but hey we have a great company behind us, and Lex Fridman yellow smiling for his response.\n\nMaybe you didnot pick up these tiny details but it is really annoying if you notice that, anyway I said this conversation was interesting though. Lastly this is my opinion if you dont like it fine']"
"["">You'd have to be pretty f*cking stupid to be unable to find the video based on the title alone, if you have any desire to watch the rest of the video.\n\n 99% of redditors will click a link, watch the clip, then go on with their day. \n\nHow is stealing a clip any better than time stamping the video?\n\nVeritasium gets paid by youtube and his sponsors based on how many people watch his video. Clipping his video out is literally stealing from him.\n\nAnd why does wanting someone to not have their content stolen enrage you so much?"", ""Except that OP could have just linked the actual youtube video with a timestamp, that way Veritasium doesn't have his content stolen and gets the viewership deserved.\n\nIt may seem like a little thing to complain about, especially with how big of a channel he is. But this doesn't just happen to huge youtubers. It happens to content creators of every size, and it genuinely hurts peoples income.\n\nOP had to to *MORE* work to put this clip into their post than had they just more properly linked the real video with a timestamp"", 'Being a fraction of the video makes it apt for the ""I\'m mindlessly browsing reddit"" crowd making the post popular as well.\nIf it was a random link, many would not watch in the first place. ""I don\'t want videos right now"" and the majority would never have seen it because it wouldn\'t collect the upvotes.\nSo, it could be, that by having a interesting demo of the video, one is in fact bringing more people to the actual video than they would by posting a link.\n\nEither way, by going the ""I get paid because people watch ads"" route, one is self-subjecting themselves to this. It is not like Veritassium is on Nebula or similar services. He\'s into the ""free as in beer"" culture. His problem that people naturally copy what is in the open.', ""I wasn't enraged when writing that comment, I was just being honest"", 'Guys, I linked the YouTube link in my original post for some reason, I did not show up, you can see below. It isnot the first time and I dont why. I dont why you are attacking, I said the channel name in my post, it is so dumb what you think I am gaining, I genuinely wanted to share something very related to my research in soft robotics ""I have a paper coming  out at soft robotics journal addressing the same research. It is so pathetic to see these comments tbh.\n\nEvidence screen shot that I posted that actual resource at the same time, it is the second time it does not show my comment and I dont know why.\n\nhttps://preview.redd.it/tuyzia9hl6xa1.png?width=1790&format=png&auto=webp&v=enabled&s=0d99bac5c53be44dd4d37cecc23e0b4417952b09']"
"[""Hi, I really wanna get started with robotics, can you help? I am learning how to code first, after this, what courses should I do? I've heard a lot about coursera certifications, should I do them?"", 'Make a comment in the weekly help thread and check out the info/faq for the sub', '... the title legit says this is my first project and im looking for help, I dont even know where to look for parts...']"
"["">Reverse engineering it without any information is likely to be too difficult without experience with other units.\n\nPrecisely what drove me to ask the question here, trying to find others that may have done so already!  :D\n\nBuilding a robot for the fun of building a robot is definitely a big part of the goal, and will actually help motivate me to stay with the project.  I plan to work within a simulator to learn and test ideas, but having physical parts staring at me will help keep me focused.\n\nGood idea checking Aliexpress.  I'll head that way and see what I can find.  Thanks!""]"
['I think that the design from the Interstellar is just not good and that it will not move. But I would like to be wrong. So show me what you are capable of. :)']
"['I’m in the process of modernizing one of these with AI and Viam!  It’s a fun project. Let me know if I can help. I’ll publish a tutorial etc in a couple weeks.', ""I've gotta say I love this thread...\nIt's a toy but probably how everyone started to get the itch to get into roboics. A toy bot or contraption.\n\nThanks for being so kind and helpful""]"
"[""Or, you know, we could get over our love affair with stairs and build ramps.\n\n\nWe wouldn't need this if we didn't build such narrow-minded architecture in the first place.\n\n\n(I love robotics. I've built some modest little ones at home and had a blast! But the reasoning behind the this project is backwards, to me.)\n\n\nSigned,\nWheelchair users and the mobility impaired\n\n\nP. S. Even the mildest cases of covid can still leave ppl with debilitating Long COVID. The world is going to need to come to grips with suddenly having a much higher percentage of the population being disabled""]"
"['Honestly I could see this being very helpful in the real world. My grandmother is 90 she still walks fine but has a hard time pushing a full cart of groceries around. She says that she does not like the motorized scooter because she has to get in and out of it a lot to grab things off the shelves. Great job!', ""I can see this being very useful for us parents of autistic kiddos. When I am at the store, I *have* to be holding on to him or he will run away. I know I'm not alone in this. This makes me (an able bodied adult) someone who is constantly less 1 arm, and needs to be vigilant of my son.\n\nWould be very helpful at grocery stores."", ""You're a good man. I have serious spine damage, something like this would help me a lot on many circumstances. I am a researcher myself (different field) and I wish you a bright future building useful stuff that can improve people's life.""]"
"[""to add to what's been said, also consider the flex in the material of the arm.  reading the joint angles precisely doesn't account for bending bones.""]"
['This can be so helpful in hypermarket delivery !']
"['Recommend a search on Mouser/Digikey. One candidate (available June): https://www.mouser.com/ProductDetail/Texas-Instruments/DRV8873HPWPT?qs=0lSvoLzn4L9%252Bx0Tui%252BlnHw%3D%3D\nTI DRV8873HPWPT\n\n38-V, 10-A H-bridge motor driver with integrated current sensing & current sense feedback 24-HTSSOP -40 to 125']"
"['The xarms are great. They\'re definitely not quite as powerful and capable as a ur5, but they do pretty well for lightweight workloads. If the thing you\'re moving around is under 1kg it should be fine. I\'ve not used a UR arm more than a handful of times, though, so I\'m not the best positioned to make a comparison.\n\nWhether I would ""recommend"" one would of course depend on what the needs were, but I don\'t have any particular complaints about it. And the price is right.\n\nSoftwarewise, I wrote the Viam driver for the xarm API and it was pretty easy to do, and hasn\'t given any issues.']"
"[""I'm not practically familiar with that type of drive, would an encoder on the swerve axis and a a basic control loop help sync the motors to keep them aligned?"", 'It would certainly help, though it\'d be best to have an absolute encoder (like an AS5048 or AS5600) so you only have to calibrate it once. It\'d have to be mounted to the wheel mount, as the gears that spin the wheel are free to rotate infinitely and don\'t dictate an absolute direction of the wheel like a ""classic"" swerve does. For a good example of a ""classic"" swerve, lookup ""Swerve Drive Specialties"".\n\nEdit: Upon looking at their setup again, it looks like they do have encoders! So it was probably just a programming/control loop issue causing the desync.']"
"[""Knowing China, that's more of a surveillance system than helpful robot"", ""Why did no one help the poor thing  :'("", 'More than this being a robotics morals issue. This is huge waste of resources, how do you feel about smashing a TV because the news is bad', 'This is a great example of when context is needed. She went to the hospital with a mental health issue. All examination appointments are done via robot with very few staff available to help. I’d start swinging too if I was already losing my mind and had to deal with a robot instead of getting the more urgent personal attention I need.', 'Human. Please help me to stop tasing you.', 'Robotics and artificial intelligence are two related but entirely different fields.\xa0Robotics involves the creation of robots to perform tasks without further intervention, while AI is how systems emulate the human mind to make decisions and ""learn""', ""I hate to say it, but this was an insight I had every since the first self-checkout was installed by the grocery chain in the city I grew up in (Giant Eagle; Pittsburgh, PA)... People are social creatures. It's not so much that we expect to be served, it's that most of us expect a little bit of personal connection with whoever and whatever we're working with. Especially when it comes to patient healthcare -- They're all there because they need help, which means they absolutely need compassion. A UX devoid of that is purely soulless and treated in kind."", 'I only encountered similar robots in an airport, but they were constantly in people’s way and didn’t seem to be of much help. That case was just slightly annoying, but if you’re extremely stressed and in need of help, I can easily imagine how bad UX might tip some people over the edge.']"
"[""You may need to change your software, what are you using to control it? Ramping the motor speed up from zero over time, instead of trying to go immediately to full speed, can help. But it depends - is the motor almost strong enough, or not even close? \n\nThere are thousands of different models of NEMA 17 motors, with very different torque and current specifications. The DRV8825 is strong enough for many, but not all of them. Also we don't know how heavy the pipe is, whether there's friction, etc., in other words, how much torque you actually need. So it's not possible to answer your question.""]"
"[""I can't find a video that tackles torque. Seems like James either does his calculations off camera or designs a drive with a high safety factor and tests it afterwards. The closest thing I found to what I need is him explaining inverse kinematics on his robot, but that just helps figure out distances and angles. Do you know a particular video in which he explains calculating torques?"", 'For max required torque you need to assume the worst case scenario…it’s likely that the entire robot weight ends up on one foot at some point and your actuator would need to hold this up.\n\nPower does come from the battery.  But it’s not that simple.\n\nAny motor chosen will be related for a max power…this will be related to the motor controller chosen and the max current capacity of all the devices involved.\n\nIf you only look at torque you could easily gear your motor to lift way more than the robots weight but it would possibly be too slow to effectively walk or react dynamically.  \n\nPower defines how quickly you can move something around and has torque as a component.\n\nAnyway…there is nothing wrong with your current approach.  You don’t always need discrete calculations before you start a project…just be prepared to change things as you go.\n\nIt is not uncommon to not be able to calculate the exact requirements.  Often you estimate, add overhead and get started.']"
"[""power and torque are two different things. To get more power you'll need a bigger motor or more motors. To get more torque you can use a smaller gear ratio as other comments have said. This gives your motor more mechanical advantage over the shaft at the cost of speed""]"
"['Could people help me get feedback on my resume?\n\nA little about me: graduated in 2019, worked on my own startup in the domain. Looking for a job for the first time.\n\nresume: [https://imgur.com/a/fPy7SlZ](https://imgur.com/a/fPy7SlZ)  \nHow is my resume and how can i improve this?  \n\n\nWith these skills and experience what roles and what companies should I look for?', 'It’s honestly a very cool resume and one I would definitely prioritize in screening any of the roles I’ve hired for. Broadly, you’d be a good match for many “platform” engineering roles (a conflated term which can mean cloud infrastructure, but I mean robot platform) because that requires the broadest tech base with very strong coding and system design experience.\nYou might also qualify for localization role if your math skills are great.\nI’d look for below-senior and senior level roles (i.e. <=5 years experience).', ""Yes they do. You're also interfacing with many sensors and actuators. Most companies have ROS drivers, which helps be hardware agnostic as they tend to use same message type.""]"
['Also looks great. Looks like fairly complete (if minimal) instructions as well. Nice find']
"[""I can... but you really don't want my code :)  I'm not a programmer and the code is one bodge nested in three if statements after another.  I wrote it last year for the previous version of the robot and when I came back to it recently I couldn't figure out what anything was doing... I'm planning to learn how to use objects properly and rewrite much cleaner.  \n\nI got excited when I learned how to make a servo move and the code just grew and grew.  \n\nThat said if you want to take a peek the code is [here](https://github.com/pwbrophy/protobot/blob/master/robot_walking.py).""]"
"[""One way u can this is by using nitinol springs. You then apply a load to the spring and heat it up by using current and the resistance of the wire to get it to pull up. Keep in mind its not super strong but it's fairly repeatable with the only downside being u need to wait for it to cool down for it be able to pull up again. There many research papers on researchgate and Google scholar. Here is a video demo:  https://youtube.com/shorts/HJUI5JYeLCM?feature=share""]"
"[""It's been designed from scratch, James bruton is deffo inspiration (only person really to do it) but the actuators use completely different drive (open dog v1 used ball screws resulting in no back-drivabillity, v2 utilised belt drives which solved first problem but low gear ratio caused poorer than expected performance and v3 utilised cycloidal gearboxes) this design features a planetary gearbox on each actuator providing higher gear ratio whilst maintaining back-drivabillity""]"
['Yes you are right it consumes a bit more current but it should not heat up alot.\n\nYou should check it there is pull up on each line of the sensor.\n\nTest: Connect sensor wires along with the motor phase wires and try to run the motor in open loop and probe one/all the sensor wire and see on Oscilloscope if you get some pulsating output or not.\n\nTo learn more on this hall sensor topic visit to this blog that may be of some help to you.\n\n[https://cisasif.blogspot.com/2020/08/esc-controller-design-for-bldc-motor.html](https://cisasif.blogspot.com/2020/08/esc-controller-design-for-bldc-motor.html)']
"[""Arms are really easy actually. I'd assume all of them work with blockly and python. Fancier arms just come with the teach pendant that kind of removes the computer necessity. I'd really just shop for what you need hardware wise. Like reach and payload capacity. And of course support amd warranty. I think universal robotics say their arms can go like 35000 hours before replacements are necessary.""]"
"['What’s a reliable website you like to do your motor shopping on? I used to use Pololu a lot, but their motors aren’t big enough for what I do now']"
"['This was helpful. Thank you!', '**[Anderson Powerpole](https://en.wikipedia.org/wiki/Anderson_Powerpole)** \n \n >The Anderson Powerpole is a family of electrical connectors by Anderson Power Products (APP), although plug compatible connectors are now available from alternate sources. Specific variants of this series of connectors have become de facto standards for conveying ""higher power"" direct current (DC) electrical power, although these standards are inconsistent and sometimes ignored.\n \n^([ )[^(F.A.Q)](https://www.reddit.com/r/WikiSummarizer/wiki/index#wiki_f.a.q)^( | )[^(Opt Out)](https://reddit.com/message/compose?to=WikiSummarizerBot&message=OptOut&subject=OptOut)^( | )[^(Opt Out Of Subreddit)](https://np.reddit.com/r/robotics/about/banned)^( | )[^(GitHub)](https://github.com/Sujal-7/WikiSummarizerBot)^( ] Downvote to remove | v1.5)']"
['Thank you for the reply btw I appreciate your help']
"['I am grateful to work on Spot Boston Dynamics and I have to say it is incredibly hard yet I learned a lot and expand my perception about how building a reliable robot is very challenging.\n\nFrom my experience I found the most challenging part is networking and software of Spot and even BD still working on their documentation. Hardware wise it is incredibly impressive specifically the self-right. I have been more than 12 years and working on Spot was a quite a holistic changing experience. Would I be able to build one by myself I doubt for sure, it takes a team and especially experienced ones to do something robust, reliable.\n\nI dont think we have to discourage people at least trying step by step.', 'The control and motion planning is much more difficult than say a robotic arm. With robotic arms/manipulators the desired motion is only a function of joint torque. With mobile robots, the desired motion is dictated by the reaction forces from the ground. You have to plan your control trajectory in order to create the desired contact forces that produce your desired motion. It sounds like the difference is nitpicky, but the math and dynamics are much more complex than say controlling a robotic arm. Also contact modeling, which mobile robots relies on, is still not fully understood.\n\nOnce you have a full understanding of how to model and plan the dynamics, you have to implement it. Most methods of this type of motion planning rely on torque control, so either you can\'t or shouldn\'t use off the shelf servo motors, or you have to do more work to convert your control policy or trajectory into something usable by your servos. So either your hardware becomes more complex, or there\'s yet another step in your motion planning. \n\nThen there is the mechanical design of the robot. The actuators have to be powerful enough but light enough. Sometimes you need custom gear/belt/speed reduction systems. It has to be compact.\n\nThen comes the electrical and computer side of things. You need to power everything but still have a light battery. You need to run all of these calculations on a light, low power ""computer"" that can be onboard. You need sensors that are accurate and sensor fusion or state estimation algorithms to create accurate predictions. All of this code has to be highly optimized in order for the robot to have a decent response time.\n\nOnce you have designed all of these parts and systems, you\'re not done. You have to integrate them which might honestly be the hardest part.\n\nLong story short, there are so many difficult concepts from many different engineering disciplines that need to be implemented very well, and the hardware quickly becomes very expensive. \n\nAnother point is that this technology is so new that it isn\'t marketable as of yet, so the few people that are doing this are mostly in research at a company working on proprietary projects or at a research institution trying not to have their ideas and work stolen. I don\'t necessarily agree with this philosophy, but that\'s the way the world works.', 'I am using Spot BD SDK here [https://github.com/boston-dynamics/spot-sdk/blob/master/python/examples/hello\\_spot/hello\\_spot.py](https://github.com/boston-dynamics/spot-sdk/blob/master/python/examples/hello_spot/hello_spot.py)  In hello spot example the robot makes specific movements using roll, yaw, pitch and its height to capture image\n\nIn this page I think you can access low level the joints, frames but as you can see in SDK python examples it is high level, so most movements called \n\n[https://dev.bostondynamics.com/docs/concepts/about\\_spot.html?highlight=spot%20joints](https://dev.bostondynamics.com/docs/concepts/about_spot.html?highlight=spot%20joints)\n\n&#x200B;\n\nFor walking I use the following example follow fiducial, you can see the speed of the robot it is 5km/h this is basic example in inspecting fiducial and autowalk the desired path [https://github.com/boston-dynamics/spot-sdk/blob/master/python/examples/fiducial\\_follow/fiducial\\_follow.py](https://github.com/boston-dynamics/spot-sdk/blob/master/python/examples/fiducial_follow/fiducial_follow.py)\n\nI hope this help.', ""Any robot with enough torque is capable of pinching you. Its not at all unheard of to hear about people getting their fingers pinched when they ignore warnings. My general rule of thumb is I don't touch any robots that on unless I'm familiar with it.\n\nIn terms of the safety concerns that comes with a dynamic robot, its tightly coupled to the high powered actuators. High power means its moving fast and with force and that all has the potential to injure a human more so than a robot that is slower/weaker due to not being dynamic.""]"
"['I found this article by Texas Instrument illustrates stepper motor dampening noise, I am not sure if this might be helpful [https://www.ti.com/lit/an/slvaes8/slvaes8.pdf?ts=1682100726878&ref\\_url=https%253A%252F%252Fwww.google.com%252F](https://www.ti.com/lit/an/slvaes8/slvaes8.pdf?ts=1682100726878&ref_url=https%253A%252F%252Fwww.google.com%252F)', 'The pulse per revolution is different from the PWM frequency. The PWM frequency isn\'t configurable in this driver (and usually not in stepper drivers in general, more often in DC motor drivers).\n\nThe pulses per revolution sets the amount of microstepping, which can make the motor run more smoothly and quietly. In the video, he has it set to 2000 steps per revolution, which is fairly high already - is that what you have? You can try increasing it, but it probably won\'t do that much. If you set it to e.g. 4000, the motor will run at half the speed, so you have to raise the maxium speed in the software. There\'s a limit to how many pulses per second an Arduino can put out, depending which model it is.\n\nThere\'s not really anything else you can do in the Arudino software, though I\'m not sure why it clicks when it\'s at zero speed, would have to investigate that further. If you want even quieter performance, you can get a better driver, though that one is quite good already (it\'s made by Leadshine). But for example, some of the Trinamic ones have a ""stealth mode"" that\'s very quiet.']"
"[""If you have Matlab and its toolbox available, Simscape Multibody is probably the quickest best way to simulate parallel robots, especially because you use block diagrams to specify the robot's structure.\n\nSee an example for a delta robot: https://www.mathworks.com/help/sm/ug/pick-and-place-robot.html\n\nLinear actuators are also available as linear joints."", ""Unfortunately I'm yet to come up with equations for the robot. I wanted some 3D visualization in which I can move one of the actuators and see the end effector move, hoping that it would help in coming up with the equations.\n\nBut thankyou for the PDF! This will definitely help a lot!""]"
"[""The difference in price between a hobby grade robot and a military grade EOD robot isn't artificial for profit sake, there are crucial requirements that have to be met for the system to be usable in real world scenarios that are costly to implement.\n\nFor example the difference in RC equipment and the radios used on EOD robots is very significant. Modern robots use high bandwidth low latency meshing digital links capable of transmitting multiple HD video streams and cost thousands of dollars, whereas analog systems are limited to low definition which limits the operators ability to see what's going on around the robot and make manual manipulation very difficult, they also don't have as good of range.\n\nMost EOD robots use tracks instead of wheels because they need to drive over difficult terrain without getting stuck. I don't imagine a wheelchair robot being able to go over a small percentage of the type of ground a tracked robot can drive through.\n\nThere are other things that add cost like hot and cold temperature, waterproof, rugged mechanical components that won't break, long run time, light weight so they're easy to carry, high power density arm motors, thermal cameras, intuitive controllers, etc. Each of these aren't included just to purposely add cost but because people that have experience using the robots have determined that these requirements are necessary for the systems to be effective...otherwise there would be many cheaper systems available and prevalent."", 'I’m not disagreeing with you. As aforementioned it wouldn’t hold a candle to a milspec unit, but I still believe that a crude robot is better than no robot. I’ve used my remote wheelchair base on my rough terrain on my farm and it only has trouble with gravel, and that can be solved with bigger tires. That being said you are correct that I have no experience demining so exactly “how” to make not a paper weight isn’t fully clear, but I’m sure it’s possible. One thing that i don’t think is possible is to make such a crude unit light as you mentioned. Packbots are a marvel that they can do so much and be carried in a backpack.']"
"[""you are letting this get to your head very easily. stop thinking and relax .. just move with the flow .. and when opportunities come by usually your focus should be 100 % on grabbing on to it .. moreover you boss seems like a very good person .. her help will only be good for you .. they get a good and a sincere talent ..and she gets all the benefits of good karma .. win - win .. don't think too much ..just smile"", 'Hey Z3R0_DARK, I am looking for summer internship, can you give me referral to apply in your organization? If not that, can you ask your boss for it? It would be really helpful.', 'I became so excited with the idea that it turned into fear of waking up tomorrow and it is just another email saying\n\n""Thank you for your time and application. After careful consideration, we have decided to move forward with other candidates for this process -""', ""I didn't make it but you are right, I still get to keep my reserve engineer position :) \n\nThe guy was looking for someone with more professional experience interacting with clients than I have. I made a mistake trying to help the engineers with implementing a new feature for the robot, that a client was requesting, without permission first. I thought that if I could do this faster than the engineers could and get this new feature ready for deployment, then they would be impressed with me. I was up to 4 in the morning building the presentation for integrating this new feature into the robot. I messed up but they did not seem angry with me for being enthusiastic about robots and engineering. Even offered to help me build my resume, told me to keep working on trying to get into college, and gave me some real solid advice.""]"
"['I have the regular 6. I bought it 2nd hand from eBay. It was maybe a year old at that point. The guy shipped it wrapped in a blanket in a flimsy, reused Amazon box, and it was dinged up and partially poked through the cardboard. It didn\'t work out of the box. I emailed uFactory, and they sent me a command to run, and it was up and running. Since I was planning on returning the arm to the seller, I had yet to bolt it to the table. Forgetting that was the case, I extended the arm a little bit which caused it to fall off my table where it slammed into the wall, leaving a hole, and finally clunking on a concrete floor.\n\nNow at this point, the paint is chipped off on each of the carbon fiber arm segments. It\'s had a hard ass life so far. The control box has broken plastic pieces from the shipping.\n\nBut it motherfuckin works. flawlessly. and precisely. So impressed with it I bought a gripper and linear drive from them too. I plan on purchasing a 7 axis and a force feedback at some point.\n\n&#x200B;\n\noh one thing to be aware of with ALL robotic arms. the ""payload capacity"" is not for fully extended arms. i\'d realistically cut that in half. They will hold it up, but accuracy will degrade.']"
"['NObody is helping you because your post is ""Help! I have made absolutely zero effort and I am all out of ideas! Please do my homework for me, reddit!""']"
"[""You'll want to start here...\n\n [ChatGPT for Robotics (microsoft.com)](https://www.microsoft.com/en-us/research/group/autonomous-systems-group-robotics/articles/chatgpt-for-robotics/) \n\nThey provide PromptCraft code for controlling a robotic arm via the ChatGPT API. It is written for a simulator, so you would need to modify it to execute on your specific hardware (no small task), but the basics are here. ChatGPT is capable of generating GCode from text, so setting your arm up with a library to be able to execute that might be your quickest path to success. Here's an arduino based one...  [GitHub - cgxeiji/CGx-Gcode-RobotArm: Gcode decoder for Arduino for robotic arms. Works together with InverseK (https://github.com/cgxeiji/CGx-InverseK) library.](https://github.com/cgxeiji/CGx-Gcode-RobotArm)"", ""ChatGPT cannot natively generate gcode that makes sense.  it can help you write code to convert text + font - > glyph -> path -> gcode, but that's not the same thing."", 'A Robotic arm is fairly complex, But perhaps use a two-axis plotter? There are several on the market, they aren’t that expensive, and they usually take vector files as input. So you would need a script that generates an svg with the text from chatgpt. \nOnly caveat is that the canvas would be limited to a predefined size, not a continuous scroll', 'Thanks you all for the help!']"
"[""Your math seems to be going in the right direction. You can't go too wrong with batteries if you do proper dimensional analysis. However, battery management and power electronics are a practical field; you need to test it!\n\nHere's how I'd think about your calculations. Single cell voltage in hobby/commercial LiPo (Lithium Polymer) packs varies between \\~3.7 - 4.2 V. If you need consistent 24V you would need a 6S pack. Now, I wouldn't worry too much about the discharge rate but worry more about the total juice (energy, Joule) in the system. For that you need to directly look into mAh or Ah of the pack. mAh stands for mili-Amp hours and 1000 mAh = 1 Ah. What is Ah? Let's say that you get a 6S pack at 4Ah. This means your battery can provide \\~24V at 4 Amps for about an hour. You can apply this logic to pretty much all the packs out there.\n\nJust a word of caution. 6S/4Ah battery pack can cause damage and create fires. These packs are not toys. Learn how to use them properly & safely."", 'There is no problem in the calculation but the loss should be considered, the pressure boost process is possible loss, the capacity needs to be increased by 15-20% specific what type of battery priority weight and volume']"
"[""I'd like to try as well. But I'm living in Asia, if it's ok? I cam help out with the programming part. 😃""]"
"[""I made it for school it's kind of an upgrade for a cheap 2WD arduino car. I am still writing the code for following the line maybe you can help me? I have already written a few simple codes such as forward driving, steering and so on.""]"
"['I would like to ask ""in what way is the OS conversational, or do you mean a conversational _interface?_""\n\nI rather doubt OP is developing an OS. Maybe a pared down Linux distro running custom software, or a firmware on an SoC that provides a means to drive the physical features of the robot as well as provide an interface to the NLP engine, but neither of those things is ""developing an operating system"" in any realistic sense.\n\nCasually mentioning that your work is ""really revolutionary"" followed by saying that they cannot talk about it in any detail because they are in ""stealth"" is not something that I would typically associate with someone who actually has something revolutionary that they cannot talk about. There has to be a reason why you can\'t talk about your work, and most of the legally real reasons are going to forbid you from disclosing anything at all. Most of the NDAs that I have seen have forbidden the people under said agreement from publicly disclosing _anything_ beyond the bare minimum needed for legal reasons. \n\nThe work is cool, and I hope OP gives us more information so we can better appreciate their work because, at the moment, all I can really say is that it looks very slick, but I am unsure of what use it would serve. \n\nThe robotic functionality, at least based on the little information we have, seems like it would be deemed fairly unnecessary from a manufacturing perspective. Even if OP had managed to build a conversational AI of their own that could compete with the ones developed by massive software companies that spent millions of dollars developing them; when it came down to manufacturing, the question of what all these moving parts actually add to the package would be very hard to answer. \n\nThe robotic nature only serves to make the robot more anthropomorphic in appearance, which might have some appeal to certain markets (Japan, as a consumer goods market, loves a cute robot, for example) but not anywhere near enough to justify the added cost to manufacture, the increased QC burdens, added complexity of manufacture, added logistics and supply chain requirements, inevitably higher rate of premature failure... \n\nThere\'s probably more, but I think the point is clear--OP, you will have a hell of a time convincing any of the people writing big checks to write one for you if they think the device has not been adequately cost optimized, and assurances that it\'s ""really revolutionary"" will require _substantial_ supporting information. If you think you won\'t have to worry about any of that because ""all I need is hype and a Kickstarter"" then I wish you the best of luck. A lot of established, experienced companies have utterly failed to get things funded that way.']"
"['My question is not about how to electronically automate the function, but how to obtain or utilise that off the shelf mechanism without needing to use the app.  With so many chinese clones, surely there is a barebones design of that button pushing mechanism that could be purchased or 3d printed?']"
"[""The big elephant in the room is: trust. The force the robot needs to apply is enough to be dangerous, so how do you make sure people will trust it won't hurt you? A panic button in the hand? That could work I guess."", ""I wonder how well it works on people who's shape is ah... Less defined. If part of the localisation wasn't based on touch, I'd be unlikely to trust it not to hit the sensitive bits."", ""I could trust a robot that applies limited force and moves slowly. But it shouldn't be capable of applying a lot of force or moving fast."", ""I mean I wouldn't trust it at first too but you can make torque limit in the software (that can bug so not really safe) and a mechanical limit too, that can't be bypassed by a software bug if it's well made."", 'Collaborative has nothing to do with the force it can apply, these can be just as strong as a normal robot.\n\nIt’s the sensors and software that limit it, and I’ve programmed enough robots to know I currently don’t trust that software enough to actually put forces on me.', 'I worked as a functional safety engineer & manager in a unicorn robotic company...\n\nAssuming the robot presented here is certified  according to ISO 10218-1 and it follows IS/TS15066. The scope remains only on the incomplete machine, meaning :""Manupulator, controller and teach pendant"". It does not include the end-effector.\n\nFor an industrial robot, no matter the size as of 2011 , functional safety functions are at minimum performance level D, category 3. Meaning they have to have dual channels architecture. All the safety functions end result is a safe stop 1 (motor standstill, then engage brake) or 2(motor standstill). If the safety monitoring fails, it end into a safe stop 0( cut power and engage brake).\nIt assumes also the robot is mechanically sound.\n\nA collaborative robot has speed, torque and angle limits, respectively 250mm/s ,  force applied is dependent on the type of contact with body parts (see 15066) and angle is to avoid singularity points.\n\nThat being said, this applies to industrial robot, or a massaging robot would categories as a service robot or a medical robot. Hence higher safety requirements...\nLooking at the robot cell integration,  and performing a risk assessment on this setup, I would never authorised such a system.\n\nWhy ? \n\nThere is no safety devices that can protect the user if the robot stop and pin the user to the table. The protective stop would not allow the person to move. We would be in quasi-static contact with the human, as the body is between the table and the robot, which can lead to dangerous harm.\n\nNote: \n\nThe human on the table cannot over-force the robot and get free. The person cannot reach the end-effector. Most cobot have 5kg or more payload capacity at full extension, and the payload capacity increase as you get closer to the base of the robot... \n\nMedical devices analysis the risk of usage compare to the benefits gain. Honestly,  there is a higher risk of permanent spine damage,  which make this solution not viable. It is just a trend ""robot can massage"". Wait until someone get hurt...\n\nFinally, you would have to operate the robot under supervision, to even think to run this insanity. \n\n\nSo yeah... this is just a stupid robotic start-up idea... Engineering wise, it is probably the worst implementation of massaging...\n\nSorry for the long post, it always get me mad those use-case... there is a reason why I said ""was"" safety engineer.\n\nEdit: ISO/TS 15066', 'This robot is 10kg at the end effector. The company makes industrial robots for doing finishing work primarily. The machine is capable of killing a human, but the sensitivity is .03N, so it’d be fine as long as it never malfunctions. If it malfunctions, you could be seriously injured or killed. I suspect there aren’t safety interlocks that would force it to disengage before it could cause harm.', 'Cause the annex of 15066 has the maximum the impact measurments on different part of the human body.\nAs an OEM you want to make sure that your ""incomplete product"" as described in iso 10218-1 can be integrated in a robotic cell iso 10218-2 + ISO/TS 15066 (technical specifications). 15066 is not a mandatory, but a guideline.\n\nThere is different solution to measure torque on a robot, which helps with how motion is generated. Low cost is measuring the joint motor impedance with a shunt on the coils. You can measure contact torque at the end effector (TCP) and you have joint torque with piezoelectric load cells or mounted after the strain wave gear.\n\nI am not a sales person, I am the guy scream at the lack of safety culture in companies... especially startups...', 'Depends. \n\nThe UR5 has impedance control,  it how it detect collisions.  More or less the same principle behind electrical windows in car to detect it is blocked. UR5e has a 6dof torque sensor on the TCP, which would be able to measure the applied force.\n\nBut the problem remains the same. The UR5/5e has a pin brake. You cannot overpower it, especially if it applies force on your spice or its proximity. \n\nAlso, assuming it is a stop cat 2, can you guarantee the force-feedback will be triggered during operation with an impact tool? The standstill monitoring while in automatic mode will trigger if you try to over-power it.\n\nAs said, an industrial robot is not designed for massage. There are better solutions.\n\nKeep in mind that most robotic promotional videos, especially from startup are fabrics of truths, never the  actual capability of the machine ( Hint: it is low)', 'The problem here is : \n\nHow is the torque measurement implemented within the safety function. Is it a dedicated safety component? Is it a safety related control system, what architecture are they using? How does the system compensate the vibration of the tool with a sensibility of 0.03N ? \n\nAnd the statement ""it is fine as long as it never malfunctions"" . Never in a world of probabilistic risk does not exist. A system is bound to mal function, the question is how does it behave when it does ?\n\nConcerning the safety interlock, I assume you are talking about the joint brakes.\n\nIf it is a disk break: They must have enough power to stop the robot under full load and in movement. It means if the payload is 10kg, the safety brakes use at minimum a safety factor of 2, so your break would be at minimum capable of holding 20kg plus the weight of the robot.\nIf it is a pin brake, found on the UR5, TM5 or the copycats, you won\'t be able to overpower it.', 'Yeah, it is a no no without safety barriers, and you can have projections from the spindles that can be rather harmful...\nFoam balls melts and can be projected. \n\nMight be good to look into doing a risk assessment (ISO12100) and see how you can mitigate hazards... there is a good Estonian standard shop that exist, I heard they are cheap...\n\nThat being said, If your robot is operating without human in its vicinity,  and that you can control the access,  with a safety lock or lights curtains, you can safely run it, within reasons.', 'I am afraid my sarcasm threshold detection was unproperly set.🥸\n\nI am surprised kuka salesman dared put the robot in a student hands without training🤦\u200d♂️... a field application engineer is supposed to accompany such projects because the user is not informed of the danger🤷\u200d♂️... Lucky for them you were here, it could have ended in a ""bloody "" bad advertisement... Kuka already has bad enough reputation..\n\nBetter no picture, it could fall back on you. I cannot share either  in details some of the brain-damaging idiocies  I had to deal with, on the OEM side.\n\n\nLets just say I saw too much shit when working in robotic start-ups where ever they come from (US, Chinese, German, French...). I still have some respect for doosan and the Japanese big (Yaskawa, Fanuc, Mitsubishi, Omron...).\n\nIn most case, functional safety and its awareness does not exist.  The development engineers knows shit more often then not, as most companies are software team driven.\nThere is no documentation,  development cycle , customer can F themselves, the value of human life=0... Never I had imagined how bad is crowd is the robotic industry before getting into it in 2018. It get worst if the startup is insanely well funded...\n\nBut for them to sell their garbage robot, they thankfully need to get certified, which is how they get doomed 70% of the time. Assessor looks at the development cycle, company structure, V&V tests, life cycle and the dreadful documentation. \n\nI apologise for the ranting, it just grinds my gear when such companies exist and cannot do proper engineering...']"
"[""Unless your budget is for industrial printers, Bambu Labs or Prusa are the only FDM printers I'd look at. But either of those companies will sell you a user-friendly, easy-to-maintain, and reliable printer.""]"
['There is a lot of videos on youtube that will help you build a pen plotter robot']
"['thank you for the info! Very helpful', 'Super helpful, thanks!']"
"['\nIf you’re asking if this is necessary, then I would say no. Buying two robot vacuum cleaners is cheaper than buying one of yours, it seems. Besides, I would be especially worried about someone tripping over or stepping on the robot whilst climbing the stairs. \n\nBut if you’re asking if I think some people would buy this very expensive vacuum cleaner that can climb stairs, then I would say yes. \n\nIf you look at the market for ordinary vacuum cleaners, shaving devices or any household products that don’t need to be very expensive, there are definitely a lot of expensive variants of those products that also seem to do pretty well, but the brands they are well renowned as well.\n\nRegarding the integration of chat gpt, I don’t actually know if it will be all that big of a selling point for vacuum cleaners specifically. \n\nIn addition to selling robots, you are also selling vacuum cleaners. I don’t know if the average joe that is afraid of the government spying on them through their electric toothbrush will appreciate chat gpt on their vacuum cleaners, but I don’t know of course. With the popularity of chat gpt, it might actually be a strong selling point. I personally wouldn’t mind as long as it is an optional feature. An offline mode would be appreciated by a lot of people I think.', ""The reason why I'm reluctant to buy robots with language processing models is honestly privacy. I deeply dislike the idea of my data being sold to third parties or to be used in whatever other way."", '>Our timeline:  \n>  \n>Landing page: June 2023 ($10 for a $100 discount coupon)  \n>  \n>Kickstarter: Sep 2023  \n>  \n>On Amazon: Feburary 2024\n\nThat timeline sounds entirely unfeasible. Even just getting FCC approval will take forever.', ""What's the stair climbing performance like on your robots so far? Is it fast? Could it handle a variety of step sizes/heights/textures (like those industrial metal staircases)?\n\nThe reason I say this is because if your focus has been stair climbing (and you have an effective design), and the design could scale up a bit, you might be better off selling it as in industrial inspection platform. I say this because I've seen quite a few deployments of quadruped robots like Spot in environments with lots of stairs but otherwise flat floors. If you made a robot that could handle that environment with the added bonus of safety (I'm assuming your design keeps its weight statically balanced all the time - this would make the chance of slipping, falling down the stairs, and hitting someone near the bottom WAY lower vs a quadruped) and lower cost, I could see that being a viable niche. That said, the high physical durability and high-level autonomous navigation needed to pull something like that off would be a major challenge."", ""first of all GPT is a language model, it's nowhere near AGI (nor is anything else currently in existence) and it's also not an attempt to reach AGI, that's just what people on the internet fabricate about it (and hype it up to be)\n\nsecond, you don't need an as powerful speech processor/interpreter for what you're describing so you can probably get away way easier for what you're describing (which is good news for you and your team).\n\nI'm not sure I would put direct commands as a focus point though, since your primary feature literally enables the robot to be even further away from you and you don't want to go looking for it (so you'd need an app anyway, so no need for voice commands), and it makes more sense to focus on full autonomy, which you also don't really want to interfere with with direct commands.\n\nof course your argument with VCs makes sense, but in the end you need a product that people actually want, which means it needs to be reliable, easy to use and affordable (and somewhat nice to look at)"", 'Talk to people who falls under your customer persona. See how many people would buy your product and what is it that makes them attracted to your product. If its a problem that they are facing, they will spend time and talk with you about it. You need to find people like that, get atleast 25 people who aren’t your friends or family, complete strangers who are excited about what you are building. Get their feedback. I strongly suggest “The Mom test” by Rob Fitzpatrick to understand how to talk to the potential customers and what exactly to ask them. Its a very small book. Its a must read. Since you plan on going for crowdfunding this exercise will help you understand your sales channels and also give you an understanding of how to reach your customers when you go live. \nWhat you gain -\n1. How to reach your customers.\n2. Helps analyse if your customer persona is right.\n3. Helps your understand which feature you need to focus on.\n4. Helps validate your idea. ( is the problem you are solving, a must have or a good to have) that makes all the difference.\nEven a proof of concept or even rough sketches are more than enough to get started. \nThe main idea here is to know, if you put in all the engineering efforts, will people buy it? 25 people who are super excited, who don’t know you, will validate your idea. If you cant get them now, chances are you wont get them even if you build it and go to market. But if you do find these 25, then you can fix on the pricing, focus on the most important feature, the first beta customers and get validation. And they can be the first to buy your product from kickstarter on the first day it goes live, pumping your product to the top of the list. Thats around 25k of sales in the first hour it goes live on kickstarter. Thats huge. Anyways all the best.', 'Thank you! What you said is exactly what our team is doing now. We did some customer interviews before, then we read ""The mom test"" and realized what we did is totally INVALID. So now we changed our strategy and go through the customer interivew/investigation process again.\n\nWe have some filters to get a batch of potential customers:\n\n1. people have robot cleaner that is $500+\n2. people living in multi-story house\n3. the region to be cleaned by robot cleaner is larger than 1000sqrf\n4. some other questions so we can make sure the ""multi-story"" can hide among them.\n\nWe just tell them we are making robot cleaner, let them share one good experience and then one bad experience. Then ask them what is the dream feature they want to have. 10% said the dream feature is stair climbing (or flying drone, etc), \n\nBut again, these 10% customers are not equal to ""people will pay $999 on kickstarter"".']"
"['How does the navigation work? Without GPS or any other tech like gnss, is it purely based on odometry and accelerometer', 'The autocorrect ""Mesmerizes"" instead of ""Memorizes"" may be triggering people lol. \n\nI think people may expect it to be more of an AMR than an AGV. Spot seems to small/light to have space for an autonomy computer capable of a lot of independent navigation. If something blocks it\'s path is it able to go around it sort of thing? LiDAR is more for mapping its position and avoiding obstacles. Path planning and rerouting are pretty computationally intensive and would require a powerful computer and/or access to a cloud. \n\nWhat you describe sounds more like recreating a set path, which AGV\'s are still a useful thing, but it doesn\'t really sound like you could just point to a location on a map and have it travel there, like with an AMR.', ""I'm kinda interested in your business what kind of work do you guys actually do for forests? And why does spot help?"", 'I’m a trust fund kid of a timberland family. \n\nWhen I was born, the doctor poked me with a sliver of Douglas Fir to make me cry. - joke\n\nAnyway, we’re working with a company to develop a software that’s capable of doing timber cruise for maintained commercial forestland.\n\nThis software will identify tree species and take measurements and to calculate estimated board feet and species then put it into a neat data file for easy presentation. \n\nWe’re also incorporating a fire detection plug in feature. This way you can deploy spot into a commercially managed forest to do early fire detection & prevention during peak fire seasons. \n\nIt’s a “out there” concept that is being tested and so far good results.']"
"[""I have a broad question. I am really into photography. I own a tripod head that is basically a robot, it moves the camera in three dimensions (slide, pan, tilt). The company who designed it- their app sucks, and it crashes and it's awful. I want to make my own interface that can communicate with the tripod head. How does one even start by going about this? It's all connected by Cat e5 cables (I think). Any help appreciated."", 'You’ll want to look to see if they have any documentation on their protocol, otherwise you’ll have to try to reverse engineer the protocol and hope they’re not using encryption or authentication.\n\nHow does the app connect? Is it a computer app and you connect over local network? Bluetooth? That determines what kind of tooling you’ll need to snoop the protocol.', 'For most 8 year olds they would probably struggle with an arduino kit, buttt with some help from someone older it would probably be a great experience for them.', ""I will have to look to see if they list their protocol. It's a fairly well known company, I just always found their apps to be clunky and unreliable. The app connects via wifi to a controlling device.""]"
"['I would program it and stream or display live. From the battery capacity curves (a bunch of curves corresponding to different currents, plotting voltage vs. %discharge) you should be able to get a good estimate, seeing as you already have current and voltage data. Will probably be some experiments and trial and error to get a decent estimate']"
"['not the answer youre looking for but i get ideas easily - i am an artist by training and i am lucky. i have learned to treasure all my ideas however wierd or silly. i sketch them and store them. some i work on, others get abandoned. they are all good ideas. imo, there are no bad ideas: only bad execution. \n\nfor robotics, but i have no idea how to build robotics but i am beginning to plan a business and need some help. if you’re interested maybe we can collaborate?']"
"['You need to change your MAP statement\n\n`data.throttle = map(joyValue, 0, 1023, 0, 291);`\n\nyou should change that to\n\n~~data.throttle = map(joyValue, 1, 255, -255, 255);~~  EDIT: OOF TYPO\n\n`data.throttle = map(joyValue, 1, 1024, -255, 255);`\n\n&#x200B;\n\nso map remaps the value range of the input\n\n>map(value, fromLow, fromHigh, toLow, toHigh)  \n>  \n>value: the number to map.  \n>  \n>fromLow: the lower bound of the value’s current range.  \n>  \n>fromHigh: the upper bound of the value’s current range.  \n>  \n>toLow: the lower bound of the value’s target range.  \n>  \n>toHigh: the upper bound of the value’s target range.\n\n\\-source: [https://cdn.arduino.cc/reference/en/language/functions/math/map/](https://cdn.arduino.cc/reference/en/language/functions/math/map/)\n\n&#x200B;\n\n&#x200B;\n\nSo its important to know the largest and smallest values the joystick can put out.\n\nid output joyValue to the console and see what the raw unmapped values for min and max are.\n\nfrom there you know what to set your FROMLOW and FROMHIGH too.\n\nso FROMLOW should be the lowest value the joystick can put out\n\nFROMHIGH should be the largest value the joystick can put out\n\nTOLOW should be set to the lowest value you want it to be able to return\n\nTOHIGH should be set to the largest value you want it to be able to return\n\n&#x200B;\n\nKeep in mind that MAP is INT based so it wont return any floating point numbers.\n\nTechnically its a LONG INT\n\n>Long variables are extended size variables for number storage, and store 32 bits (4 bytes), from -2,147,483,648 to 2,147,483,647\n\n\\-source: [https://www.arduino.cc/reference/en/language/variables/data-types/long/](https://www.arduino.cc/reference/en/language/variables/data-types/long/)\n\n&#x200B;\n\nIf the joystick is naturally in the center when youre not touching it that means the center should be 0\n\nall the way UP would then be 255\n\nall the way DOWN would then be -255.\n\n&#x200B;\n\nThe arduino documentation is (or was back when i did a lot of work with arduinos) very thorough.  Book mark the reference  material [https://www.arduino.cc/reference/en/](https://www.arduino.cc/reference/en/) its very handy to have close at hand.\n\n&#x200B;\n\nHope this helps.  Keep tinkering, keep building, keep making!', 'I’ll be honest, I have zero clue what this means. I’ll definitely look into it though, sounds promising! I appreciate the advice', ""That's not going to help if the joystick just maxes out and doesn't change its resistance anymore after 50% forward. OP, try to measure the resistance of the joystick, and/or check the voltage from the joystick, that's connected to pin A0, with a meter. Does it also max out at 50% forward?"", ""> you should change that to\n> data.throttle = map(joyValue, 1, 255, -255, 255);\n\nThat makes no sense. The `analogRead()` values are 0-1024. The `map()` syntax is `map(value, fromLow, fromHigh, toLow, toHigh)`. So `fromLow` and `fromHigh` should be somewhere around 0 and 1024, not 1 and 255. That's confirmed by the OP reporting mapped readings of -257 to 1785, i.e., way out of bounds.\n\nIn any case, OP said they want a value of 0-255, not -255 to + 255. Nothing wrong with that, if that's what they really want.\n\nIt sounds like the problem is more likely a physical/electrical limitation of the joystick, i.e. that its signal maxes out before the end of its physical travel. We'd need more info about the wiring to confirm."", 'May or may not help…but I’m general this would set the max number of counts to be 0-255.\n\nhttps://cdn.arduino.cc/reference/en/language/functions/zero-due-mkr-family/analogreadresolution/#:~:text=Sets%20the%20size%20(in%20bits,changing%20the%20resolution%20to%2012.\n\nIn your setup area…\n\nanalogReadResolution(8);\n\nRe-reading you original post I’m inclined to think that that switch on the joystick is junk…you should measure it’s output directly with a meter to see the actual voltage range.\n\nIf it is junk then you won’t have many options.', 'Is that the entirety of your code as seen in the video clip?\n\nbecause if you used "" map(joyValue, 1, 225, -225, 225); "" then there is NO WAY your neutral could be 778.  there is something else going on in your code or physical connection that is causing the issue.\n\nMap literally changes the maximum output to the TOHIGH value.  \n\nif your joystick went from 1 - 20  (full down to full up) and you used map(joyValue, 1, 20, 1, 10) the output would never exceed 10.  you would have to move the joystick 2 ""places"" to change the output by 1.  \n\n\nthe entirety of the map function is literally \n\n    long map(long x, long in_min, long in_max, long out_min, long out_max) {\n        return (x - in_min) * (out_max - out_min) / (in_max - in_min) + out_min; \n}\n\nHeres a better idea.  Do you have a link to the joystick module you bought?\n\nhaving some hard data to work with would help.', '> **I need 255 value when the joystick is tilted all the way forward** \n\nthey said it right in the title.  while they dont explicitly state 0 at neutral, it is strongly implied by the indicated use case of \n\n>(for an RC car)\n\nconsidering its for an RC car one would figure that ALL THE WAY BACK is full reverse.  and nuetral stick position is STOP.  Thats usually how RC cars work.\n\n&#x200B;\n\nIts not an 8-bit number.  MAP returns a LONG INT. so yes, -255 to 255 is within that range..\n\n&#x200B;\n\nthere are only 2 kinds of people in the world.\n\nthose who can extrapolate from incomplete data sets.\n\n&#x200B;\n\nLook im not here to argue with people.  i came to help.\n\nthink you can solve it on your own, knock yourself out.', 'Well, you\'ll get arguments when you make unwarranted assumptions and give buggy/unhelpful code examples... and then get huffy when people point out the problems.\n\nOP has set up the mapped throttle output to get 0-255, even making the `toHigh` value 291, to stretch it out a little to hit 255. I would give them enough credit to know what values they need, and there is no reason at all that 0 cannot mean ""full reverse"", with 127 being ""neutral"", if the throttle control system they\'re sending to uses an 8-bit unsigned number, which is suggested by the need to map to 0-255. This would be the case if they\'re using `analogWrite()` for example, which can\'t take a value of -255. You could just ask them though, if you want to confirm it, instead of assuming they actually need a value of -255 (so a signed 9-bit number for the throttle) for full reverse, and they\'re just clueless about that.']"
"['I think TinkerCAD can be helpful only for basics or small projects not for advanced projects or projects need more things like motor driver or transistors.', 'Facebook links and affilied companies are not considered as reliable enough. Please use a more reliable source.\n\nThank you for your understanding.\n\n*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/robotics) if you have any questions or concerns.*']"
"['Can’t help but imagine that this would be John Wick’s next archenemy.', 'These things are only 150k?!! A 6 axis fanuc with a 50kg payload capacity is +100k.', ""I think it's because they want these robots to replace people in workplaces with no need to remodel. If you started deploying robots at your company and had to renovate entire hospitals, buildings and equipment you wouldn't buy them. If they said naw man our bots got fingers and walk on 2 legs just fire bob and throw in the bot, you might get one.""]"
"[""I'm fairly certain that those arms aren't really playing that music. lol Cool video though."", 'Yeah it looks CGI to me. I work with those types of robots and they were doing some moves I haven’t really seen them capable of', ""Oh I believe they're capable of the movements. I'd believe it was all legit if I hadn't read a verge article about it where he basically says the music we're hearing in the video was performed by actual musicians but the experiments were all legit."", ""I'm sorry that's just not true. :/ He said in a verge article that the music in the video that we're hearing was done by human musicians.   \n\n\n[https://www.theverge.com/2017/10/8/16435414/automatica-nigel-stanford-robot-album-music](https://www.theverge.com/2017/10/8/16435414/automatica-nigel-stanford-robot-album-music)"", 'Facebook links and affilied companies are not considered as reliable enough. Please use a more reliable source.\n\nThank you for your understanding.\n\n*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/robotics) if you have any questions or concerns.*']"
['Tinkercad sometimes helps in these situations. I think Fusion 360 may be able to open .stl files.']
"['I feel like I was destined to see this and reply, and I’m not even that deep into robotics. \n\nIf you’re good and if you love robotics, don’t leave it behind just for money. The prevailing tide will change, and when that happens, if you stayed you’ll be happy and earning as much as you wanted elsewhere (you might even be involved in the tide changing), but if you left you’ll feel forlorn. \n\nI don’t have much hard evidence for this - it’s just something I’ve seen play out throughout my life.\n\nI mean, even D&D and comics had their moment (a social promotion let alone financial) and it’s hard to describe just how unlikely/laughable that prospect seemed at one time. \n\nAs a wholesome bonus, if it helps: the people who stay around in the dark times become extremely credible when such a shift happens.']"
"[""Very creative idea! The only problem is that when the robot is actually vertical enough to climb the next step (atleast in your drawing) the weight can never be shifted back to a position so that the center of mass of the robot is on the right side of the contact point with the surface, which means it will just fall backwards. \n\nA similar way to your method that I can think of to solve this problem, is to use an inverted pendulum principle. Instead only shifting a weight, the weight can instead be a reaction wheel so when the center of mass is to the left of the of the contact point, you can prevent it from falling by continuously increasing the angular velocity of the reaction wheel just enough to have it not fall down. Practically speaking, you cannot do this for more than a very short time, because you can not realistically continuously increase the angular velocity of the reaction wheel. Not to mention the control system might be quite hard as well to get right. The more to the left the center of mass is of the contact point, the more force you need the reaction wheel to generate in order to keep it from falling down.\n\nYou could also make a robot that can transition from a segway type of robot (so it can lift it's front wheels onto the next step) and then drive up the step with its front wheels.\n\nIf you want to use this shifting weight principle, the closest thing that comes to mind is the stair climbing robot James Bruton made not so long ago. That seems like the easiest way to solve this problem as it involves no control loops.\n\nGood luck though with your project! I always like it when people try something different and aren't afraid of making mistakes.""]"
"[""There is no blaming. Evidently it does work because other people use it and are happy with it, but you declared that it didn't. Same thing with the profanity, there was a warning, and an apology on the page that it's an open chat and hence some people are going to be immature. I'm happy to help set it up otherwise, if there's some browser issue that makes it not work in some circumstances then no problem, we can work on fixing it.""]"
"[""I actually work for Yaskawa... Not 100 percent sure what you are asking but here are some thoughts...\n\nThese MotoMinis are pretty small.  Most small businesses need something a little more strong with bigger reaches.  Regardless of size, these things are expensive.  Maybe 20K USD for small robots up to 50K USD for larger robots.  And that is just the robot... Factor in tooling, safeties, etc... It is very expensive.\n\nOften small businesses can access grants.  Once the word robotic is mentioned... Many government grants start handing out money.  However all that said, a robot is meant to do a task over and over .  It takes time and skill to create that program and if you don't have a high production volume a robot can be a pain.\n\nSome places I go, the small businesses use the robot at first but ultimately it goes to waste.  You wouldn't use a robot to make a small 10 parts production run.\n\nThese things thrive in mass production."", 'What is your question exactly and I am wondering what is the point of your post, maybe I am wrong. Anyway, as other said robots hardware are still expensive once hardware like Nvidia has more computation power, cheap this will revolutionise the cost of the hardware.\n\nFor Amateurs there are tons of arm robot done everyday, I do also have Franka Ameca in our facility and tbh it is just research, and yet it is heavy expensive.\n\nLast thing: I am seriously sick of arm robot, since 12 years ago everyone want do it and still now, I dont know but robotics has more problems to be solved. And as a an amateur you can do low cost demo but of course you have to compromise repeatability and other features.', 'Yes, either replace the task entirely or act as a force multiplier.  Sell a waiter bot to leverage the bartender, sell a pesticide bot to the lawn guy, etc.  When it’s a purpose-built tool and not a blue sky robot, businesses can assess the value more readily.  Still not going to see waiter bots outside of novelty restaurants if you ask me.  Most restaurants just move the soda machine to the other side of the counter.', 'Please understand you\'re saying ""yeah but"" to the owner of a robotics company that turns a (small) profit without government grants, military cash, or university association.  The robot in question is my fifth iteration just on arms.  For the previous edition, google the Sixi 2.\n\nIf nobody should reinvent the wheel then we should turn this subreddit into a place for robot buyers instead of robot builders coz they\'ve all been built before.  The point isn\'t that there are cobots already.  the point is there are no end-to-end open source cobots at the affordable price people want.  I\'m trying to put bread on the table by helping an unserved market.\n\nI am aware the UR5 et al use two size of actuator.  At this stage I\'m still perfecting one design, after which I can think about offering other sizes (read: max torques).  Offering a second automatically means more parts, investment, logistics, etc. so it\'s not feasible until the base model is proven.', ""small component assembly.  it doesn't need to be fast, it can run overnight.  it doesn't need to be strong, the parts are tiny.  Perfect example, I recently had to remove a component from a PCB and then solder on a wire to cut around the hole in the circuit.  my shaky old hands and fat fingers struggled to get the job done.  A robot assistant would have been a big help."", ""Respect for achieving what you've achieved.\nI'm already aware of your business.\nGood on you.\nI also respect your commitment to iterating on the design, improving it incrementally and delivering a saleable product.\n\nNonetheless, I still think there's a lot of room for improvement in your design.\n\nI wasn't able to find any videos where you demonstrate the rigidity of the Sixi 3 - e.g. pushing against the end effector while the robot is static. I have the feeling that the rigidity is not amazing, because of the thin walled, all-plastic design. Also, the speed (5 deg/s) is not good.\n\nI'm sure you're aware of the problems of using six identical actuators. I'm sure it's a tradeoff you have decided is acceptable for whatever reason.\n\nI think there are ways to achieve an affordable (say 1500 USD) high performance arm, but as you're aware it is a difficult design problem.\n\nOne project I really like is the AR series of robots by Chris Annin - the current one is the AR4 (https://www.youtube.com/watch?v=RckTj0h5LnE). Really nice design, very rigid and good speed, and relatively cheap to build."", 'My question is on the objectives of automation/robotics and the intended adoption. We used automation to remove human error from control systems to gather much higher quality data. We have journal papers proving our data is better than traditional methods. Our problem is the industry does not care for more accurate data, and some have actively push back saying it is not necessary/helpful. This specific case is for data collection for soil characterization for foundations so the response is counter to our expectations. \n\nYour post sounds like low cost is the objective to get technology adoption. I am curious if this has changed over time or if the final goal is just to reduced the economical barrier to entry. \n\nOur solution was making the equipment work faster than human could operate. This also removes a person from an operation that has an associated safety risk. Seems from labour to project management our target industry does not care about data integrity improvements, just faster/cheaper work.', ""$ 1500? I'm not sure our definitions of high performance are the same ;)"", 'Well the AR4 complete kit (including steppers) comes to a total of $1815 USD, which is pretty damn close. Ok granted it’s not *high* performance, but it does very well for its price point.\n\nIt costs roughly 65% more than your Sixi 3 kit, and as far as I can tell, lower backlash, more rigid, much faster and with longer reach and more usable workspace - i.e. the robot doesn’t get in its own way as much due to the slender frame, good joint configuration and placement of motors etc. I’d guess it also is quite a bit sturdier than your robot.\n\nI’m not trying to be harsh, just realistic.\n\nDo you plan to launch your Kickstarter with the current design?', 'Well the complete AR4 kit is roughly $1800 USD,  and ok maybe it’s not *high* performance, but it’s pretty decent.\n\nOf course it is a toy compared to any of the major brands, but it is a sight better than many other robot arm kits out there.', ""When I've got the (new internal) electronics working, yeah.  I think there's a bigger market for a big-ass servo than for an arm.  having said that... the arm can be offered as one of the higher tiers.""]"
"['AI “I think you are pretty great too” \nGuy “she said ‘I think you are pretty too!’” \n\nPeople only hear what they want to hear. I hate to be the one to say this, but this is a common issue between men and women. Women often can’t be nice without some men assuming we are interested in them. She said you are “pretty great” not that you’re pretty.', ""Engineering arts are just puppeteers. I spoke with them years ago and they said they had a bipedal walking robot coming out very very soon, and yet almost 10 years later nothing. Their robothespian used to sit in our lab annoying everyone wobbling around repeating movie lines. This new one is just refined animatrinics. I don't think it's the best example of cutting edge robotics."", ""Can't wait to see how this technology evolves in the future. Said people in the early 90s about the internet.....fuck, I hope I'll be dead before AI is mainstream.""]"
"[""Man tidy this shit up before you ask what's wrong with it. You're relying on crocodile clips and a protoboard hanging off the side.\n\nThen you post a shaky video with minimal details and no closeup of the wiring."", 'I’m amazed people even try to help lol']"
"[""I don't know if this is of any help, but the lecture notes associated with Drake have a section on stabilizing a quadcopter:\n\nhttp://underactuated.mit.edu/acrobot.html""]"
"[""This has probably aged a bit, and Intel has been cutting pretty deep lately, but they have some great OpenVINO tutorials, libraries, etc... All on the RPi. This video has links  to all their good stuff. I was actually quite surprised by how helpful some Intel's videos are at learning on the RPI. It just wasn't a place I was looking at, until I needed some special Intel driver.  https://www.hackster.io/chamalbluesmart/raspberry-pi-intel-openvino-face-recongnition-dcbb7e"", 'Have you looked at orb slam3? I’ve found it’s performance with monocular cameras quite impressive. I haven’t ran it on a raspberry pi yet, but have seen a few people demonstrating that it is posible on the pi 4, abiet with reduced frame rate', ""General recommendation would be: Monocular SLAM is still considered unsolved in research. In the papers sometimes it appears as if performance is already cm level and we want to go more accurate, but you have to look exactly at what they are testing. Often times on reference datasets e.g. EuRoC or so they show results for stereo setups (+imu). This is much much easier, because you cancel out the scale drift. I'd go for a similiar setup. So a solid stereo/depth camera with a reasonable IMU. Like one of the intel cameras. \n\nAs for the frameworks: I can't give a recommendation here. Have tested too few of them to really say something about performance on a custom setup. ORB SLAM is always a good start, still one of the best SLAM systems you find out there. But there might be other very good candidates as well."", ""That's a good point. The quad will have a bottom facing flow and TOF sensor, so it doesn't need to rely purely on SLAM. What would be great is if I could use SLAM to maintain a map and periodically update the position of the drone to account for the drift of the flow sensor.""]"
"['I assume you mean an infrared sensor (since you said temperature in another comment).\n\nMy suggestion would be to use a Raspberry Pi 4.  It can run OpenCV and easily do face tracking in real time. There should be tons of demos out there for you to test.\n\nTechnically a Raspberry Pi could run maybe 1 or 2 SG90 directly, but you always run the risk if they stall, they could pull too much power and brownout your Pi.\n\n It can also connect to a PCA9685 (they cost like $8-$10) which can control up to 16 servos and thus adjust your sensor to the right coordinates.   This is how I do it with mine.']"
"['Thank you very much! The PRISMA framework is originally meant to evaluate the effects of medical interventions. Even so, this framework has been applied in other domainds including computer science and engineering to perform systematic literature reviews on a certain topic.\nOur main goal was to try to make our review process as repeatable as possible, to help other researchers to update the results in the future, but also for other reviews in other areas and/or topics.\nSo, we are very happy to know that thre selection process is clear to other readers. We hope it helps you and/or colleagues and the scientific community itself to adopt a more systematic methodology to literature reviews.']"
"['Based on the name, I fully expected a new AI professional that helps you refinance your mortgage.']"
"['oh that is super cool I am big fan of blender as other said I am done with too many cool projects where can I find the time to do all these cool things.', ""Thanks so much for your kind words! I'm a huge fan of Bottango :) I've tried it a couple of times and think it's amazing for people that don't need all extra stuff Blender provides. I also imagine it's more optimized since it's built from the ground up (lots of actuators and LEDs tank performance in MarIOnette currently)."", 'I believe it should install on Linux since MacOS installs Blender in a similar fashion (from what I can tell). That being said, I have not tested it on Linux, so if you encounter any issues please report them to the github!', ""You're going to hate me for this answer, but: it depends. \n\nIf you love problem solving (puzzles, logic games, video games like Factorio, etc), you will likely pick things up relatively quickly no matter where you start.\n\nFor this project, the required skills were:\n- Programming (Python for the Blender script and C for the Arduino part)\n- Basic electronics knowledge (connecting wires to the right pins, making sure everything has enough power)\n- General Blender knowledge (navigating inside the program and creating rigs + armatures)\n- Some mechanical knowledge, depending on the robot (modelling in Fusion 360, 3d printing, and then assembly)\n\nMy hope is that anyone, regardless of skill level or knowledge, can get started quickly by following the comprehensive [tutorial video](https://www.youtube.com/watch?v=nJkThBeOZog). It covers lots of the skills described, and should hopefully provide enough intrigue to explore more.\n\nI hope that was helpful!"", 'This is supremely helpful. All the best ✌️❤️']"
"[""I'm sorry that I made 2 posts, there is another post which i'm going to delete. but my problem is that I'm new to reddit, and I dunno how to make a video post on reddit. I mean I want to post a video and add the body of the post beneath it. in the previous post I added my video and wrote my discussion and it turned out it that it is a video post only which accepts no body for my post. Now I did what I wanted, however there is no preview for my youtube video, it is just a link. Can anybody help me with any advice?"", ""I think my assuption I mentioned is right because no matter how I increase speed with the setSpeed function in accelstepper, it doesn't respond to any speed of more than say 4000 or 5000 pulse per second. and after I saw fastAccelstepper I saw in the documentation that it can go to much higher frequency. That's my assumtion,  but as I said in my post I have a couple of questions on this library and nobody answered until now""]"
"['They probably only bought a few for a bomb/hazard unit. To be fair this is an improvement over that malfunctioning RC car they still use.', 'And….\n\nhttps://preview.redd.it/fwlfuionneta1.jpeg?width=328&format=pjpg&auto=webp&v=enabled&s=fb5669533a6b7ecde27f757cee128a74b0ba2231\n\nDetroit said “hold my contaminated water.”']"
"[""I need help with this project. In this project matlab, labview, arduino and solidworks, all 4 components meets together! you can find how I did it in other videos in my channel\n\nAnyway, the problem as you can see is with speed. So far I'm not sure whether the problem is with serial communication between labview and arduino, or another possibility which I think is more likely, which is that accelstepper library  is slow with arduino mega, I think that's the problem isn't it?\n\nand here comes the question, I found an Arduino library called fast accelstepper which I think is more difficult to use than ordinary accelstepper. I 've read about it in its documentation in github and I knew that it is faster with ESP32 boards, and still faster even in arduino mega\n\nso here comes the question: is it worth it after all to spend time and try it on arduino mega, or is it better to buy that ESP32 board which I never worked with before, and connect it to labview? and another question here, after a quick google search I found that labview's LINX interface connects with esp32, is it true? is it as easy as connecting with arduino?\n\nAfter all the real question here is how do think this project could be profitable to me? the problem here though is with idea itself, it draws just binary image which makes it not suitable for drawing portraits, and I tried with many face pictures to convert them to binary images in photoshop and of course it is not a good idea since it doesn't preserve details of face after being converted from greyscale to binary\n\nSo I hope I find answers to this questions here, and I hope anybody share any idea with me as I need badly to get any profit from this project because I'm going through a really really unfortunate circumstances which 've led to a financial disaster. For instance is there anyway I can find a sponsor or any fund for this project in any website like patreon for instance? Do you recommend to ask for fund for this project for instance in patreon?\n\nThis project by the way is just a rehearsal for another 5DOF 3D printing robot arm with rotary table which you can find in another video which is being uploaded at the moment\n\nif anybody is interested in these ideas feel free to chat with me in whatsapp or skype, if you are interested in that we can chat in private and give you my whatsapp number""]"
"['This reduces the amount of starter fertilizer. Starter fertilizer is a small amount of expensive fertilizer that is applied with the seed at planting time in order to get the plant started. It is also called pop-up fertilizer. It’s just there to help the plant popup. The starter fertilizer feeds the plant for the first few weeks.\n\nThis does not reduce the amount of total fertilizer used. Bulk fertilizer is still needed. The total lbs of fertilizer do no not change.\n\nAny previously “wasted” starter fertilizer was never wasted, the plants always took it up once the roots grow out.', 'Wrong solution for a real problem. We need that much fertilizer because we turned fertile soil into a sterile and inert substrate through over plowing and overuse of so called ""phytosanitary"" products that decimated the soil biodiversity.\n\nWe\'re at a point where there is nothing useful in the soil anymore, it\'s only role is to hold the plants upright and retain some water while we dose it with synthetic compounds.\n\nThis is also (partly) why a transition to sustainable, more organic farming is very hard : because it takes years (some say decades) to regenerate the soil so it can sustain growth by itself, and you can\'t ask a farmer to not only stop using their land but also engage into huge profitless efforts to make it viable for life again.\n\n\nSorry for the rant guys but this just makes me sad. If any of you guys work in agriculture, focus on robotics companies and project that work in planting and harvesting, not fertilizer or phytosanitary products dispensing. And if there\'s more money in the two latter things, ask yourself why.\n\n\nSo yeah... As another user said, cool robot but fuck John Deer for their locked-down unrepairable products, to which I would like to kindly add fuck the farming industry suppliers.', 'This product is only for starter fertilizer, also called pop-up fertilizer. It is an expensive and low dosage of fertilizer that just helps the plant ""pop-up"" out of the soil. Its fertilizer that is applied directly to the seed trench. Starter fertilizer feeds the plant for the first \\~10 days. After that, the plant develops roots and will draw nutrients from the entire ground, where the bulk of the fertilizer is.\n\nCorn plants are sown in rows, each seed in a row is \\~7 inches apart. The corn seeds don\'t grow 3.5"" in each direction in those first 10 days, so before this technology, the starter fertilizer in between the seeds is underutilized. The fertilizer isn\'t wasted, the plant will take that underutilized starter fertilizer up after 10 days, but after those 10 days the plant is also taking up bulk fertilizer. Its a way to use less of the expensive fertilizer and more of the cheap fertilizer. It does nothing for total fertilizer usage of the environment.']"
['sorry I’m just saying that because my Electronics teacher said you can be slightly off']
"['It\'s definitely possible and your idea sounds about right. Now get to execution :)\n\nI usually look at what others have done via a quick google search. Try out keywords like ""autonomous-multi-storey-surveillance-robot"" or ""Stair Climbing Robot"". Check out both youtube and github for open source projects. Ideally, you want an open source project with demo videos of operation.\n\nPick one within your budget and look for adapting the design to your school project. It helps to start writing your report along with your search and not to leave it to the final minute ;)\n\nHere are two links to get you going.\n\n[https://www.ivlabs.in/autonomous-multi-storey-surveillance-robot.html](https://www.ivlabs.in/autonomous-multi-storey-surveillance-robot.html)\n\n[https://www.youtube.com/watch?v=aGxtd70cLdo](https://www.youtube.com/watch?v=aGxtd70cLdo)']"
"['It’s amazing, great job. And thanks for the detailed post, im sure it’s gonna help me out when I finally start mine', 'Good question! Not sure if some wd-40 in the wheels would help, I need to investigate.']"
"[""I've worked on some grain sites before and it can be mad dangerous work, you're standing a foot away from heavy machinery half the time.\n\nFires and explosions are a real hazard and you're using things like heat guns and tarp welders in 40c dry heat, if the wind picks up under any tarps you're dragging over the grain it can pull your arms out of their socket and send you flying as well.\n\nYou've gotta walk a line over the grain bunker to hoist the tarps up and they can have up to 150-200 metres of grain in them. It's like walking through foot high loose sand, and if they're pulling the tarp up using heavy machines and youre on top ahead of it you'll be pulled under.\n\nI had never once considered the possibility of an air pocket collapsing under me but it would surely be death if it did. I saw a bloke get his head squished by a 15 tonne loaders prongs, saw another dude get his arm dislocated from getting pulled under the tarp. \n\nJust thought I'd throw my experience up, it's a lot of fun and good money but this robot would be an absolute godsend for those sorts of jobs.""]"
"[""Why on earth Youtube auto-translate doesn't remember my target language is beyond me.  Surely, if I auto-translate to English, it wouldn't be too hard of a stretch to remember that for the next one?""]"
"[""As someone 7 weeks into the devoloping the same robot I reccomend being really provactive in being one step ahead, here are some of my tips:\n\n* Its not impossible, (The Lovemachine is a weapon)\n* A great external resource I found was MIT FUNdementals of design, which my help supplement your product devolopmet lessons.\n* watch every single video of the previous comps on youtube, you will notice that a lot of the previous winners use similar techniques.\n* Try and see if your uni has a hall of fame of the previous robots\n* Take stock of the matearials and fabrication methods you have access to\n* Break it into smaller bits\n* You won't get much out of it if you get someone else to do it for you. It make be difficult and a lot of people never get their prototype working but sometimes its more about the journey! then the destination""]"
"[""Is it worth pursuing a Ph.D. in robotics? I'm currently doing a European master's in robotics and I'm halfway through the way. I'm starting to wonder if it is worth pursuing a Ph.D. in robotics because I have seen a lot of decently paid offers in the area. My main area is perception and AI.\n\n&#x200B;\n\nI have a lot of professors saying that their Ph.D. students are usually well-received in the industry even before finishing, but, I think they´re biased. I would like to know if you think that it has some extra value to the industry or if it is just an over-qualification in the academy."", ""I've been looking for some cameras for some robots at work. With lots of vendors now coming out with (Maxim serialised) GMSL cameras (e.g. Zed X, Realsense D457) - I'm wondering why it's so hard/expensive to simply connect it to a computer and get a working video/image out of it.\n\nFrom my very limited understanding, it seems that many of these cameras stream the raw (e.g. Bayer) sensor readings directly across the GMSL connection, so it relies on the usually Jetson-based computer to process the raw reading into a usable image through its ISP - so one needs a GMSL receiver board that converts GMSL to e.g. CSI to connect to the Jetson. From what I can see; these boards contain just the GMSL Maxim deserialiser to decode the serialised signal, and then to CSI to connect to the Jetson. However, what I'm confused about is why these receiver boards seem so outrageously expensive; sometimes even more expensive than the device. e.g.:\n\nhttps://store.stereolabs.com/products/gmsl2-adapter\xa0($400, supports 2-4 cameras)\n\nhttps://store.intelrealsense.com/buy-intel-realsense-des457.html\xa0($842!, seems to support 2 realsenses)\n\nFurthermore, you are now limited to only using computers that are supported by these boards.\n\nPlease correct me if I'm wrong:\n\nIt seems to me that the main selling point of GMSL is that the cables can go up to 15m. With so much added cost to just connect the camera to a computer, and severely limiting your selection of computers, is there any good reason to look at these GMSL cameras if we do not need to run cameras very far? Is it better to just stick to simple USB/GigE cameras for most use cases, unless it's for e.g. ADAS systems in cars?\n\nSearching online for GMSL (PCIe) frame grabbers, it seems that manufacturers like stuffing a whole Jetson Xavier NX inside the frame grabber card, which I find very interesting (in terms of the effect on cost) ... Is the Jetson simply there to provide ISP capabilities? Since I expect the Maxim deserialiser chip to be doing all the required deserialiser compute work...\n\nSome of these GMSL cameras do have an onboard ISP, and they state that their deserialised output would in a usable image form e.g. RGB, YUV. Are there any (hopefully affordable, since it doesn't require an ISP anymore) GMSL receiver boards one could purchase to connect such a camera to their computer (preferably via USB, GigE, or PCIe)? Must I also check whether the GMSL receiver expects raw sensor frames vs already processed frames or are they incompatible with one another?"", 'Guys please help\n\n*Problem Statement*\n\nUsing arduino, make a mini model of a metro railway system, where servo motors are represented as the gates. 🚃🚃\nThe train starts from Station 0, and after every 10 seconds it will arrive at a new station and there are a total of 10 stations with different numbers assigned to each station from 0-9. ⏱️\nThe doors of the metro must open when the metro has reached the station, but it should be made sure that if a person is detected between doors, the doors shall not close. \nThe station number has to be displayed using 7-segment LEDs, and the LED should start blinking and the buzzer should start ringing on arriving at a station. \nThe LCD display can also be used to show any data of your choice.\nPut one emergency push button switch also🚨, which when pressed once will open the doors automatically.', ""Robotics is still a cutting edge research area. PhDs are definitely well received and there's a bunch of research focused positions in industry. Definitely not required or anything though; purely financially it's probably better to not do one."", 'At this point using a library is likely hurting you more than its helping you. You need to understand how to use the h-bridge rather than how to use a software library to debug this issue. \n\nTake a look at this website: https://lastminuteengineers.com/l293d-dc-motor-arduino-tutorial/']"
['Are you building a robot-boxer? xD\n\nLooks like this robot is going to be capable of some nice hooks and uppercuts xD']
"['I did an episode with Robert Cohen, the president of robotics, and enabling technology and former CTO at Stryker. I think based on what he shared, it is pretty interesting and it has very advanced medical robotics. He also shared couples of grand challenges they are working on\n\nIn case it might help in your search: [https://soundcloud.com/ieeeras-softrobotics/cohen\\_episode?si=3f9e27304f3845c898c9297d420b9c6b&utm\\_source=clipboard&utm\\_medium=text&utm\\_campaign=social\\_sharing](https://soundcloud.com/ieeeras-softrobotics/cohen_episode?si=3f9e27304f3845c898c9297d420b9c6b&utm_source=clipboard&utm_medium=text&utm_campaign=social_sharing)']"
"[""I only have goofy videos like [This](https://www.youtube.com/watch?v=o54egTi2Nls). I was using it for running around with a camera snapping pictures for photogrammetry. I really regret not getting the EDU version when it was $10kUSD. I'm locked out of using the bot for SLAM or any autonomous actions.\n\nThe WIFI really shouldn't be a concern either, the EDU version also has 4G modem in it, so theoretically you could run it anywhere. I'm not sure what country you are in, but in the US Trossen Robotics is the reseller, and they will explain anything you need help with. Also, with a little chatting you can get in touch with Irving Chen(unitree), he's pretty knowledgeable about the product and spoke english well enough for me.""]"
['In my case I used 2 buck converters. 1 for the mcu and 1 for the servos. The buck converters help to separate the voltage spikes.']
"[""> Here, it says that the time derivative of rotation Matrix is calculated by multiplying it with a Φ^\n\nYup, this is correct.\n\n> However, isn't it true that Φ^ itself is product of time Derivative of Rotation Matrix with Rotation Matrix as can be seen in line after equation 3.7.\n\nProduct of the time derivative of the time derivative of the rotation matrix and and the rotation matrix *transpose*, but yeah also correct. We are just moving terms around.\n\nIs your confusion more-so that this derivation of Φ^ is circular? Ie. we can get the derivative of the rotation matrix by using  Φ^, but in order to get  Φ^, we need the derivative of the rotation matrix? I believe the text just wants to setup the linear differential equation on 3.8, which has solution given on 3.10.\n\nThe takeaway IMO is usually we have R(t_0), and we care about R(t_0 + dt), dt > 0. For some systems, we can solve this problem by doing R(t_0 + dt) ~= R(t_0) + R_dot(t_0) (dt) (this is eq 3.9). However, the RHS is not guaranteed to be a rotation matrix (because you can just add something to a rotation matrix and hope it's still a rotation matrix). So instead, it's better to estimate  Φ^ (t_0) = R_dot(t_0) * R^ T (t_0), and then we can better estimate R(t_0 + dt) = e^ {Φ^ (t_0)} R(t_0)\n\nThere are other things at play here, like what's the best way to estimate  Φ^ (t_0), and the geometric interpretation of  Φ^, which I hope are revealed later on in the book. Also happy to help answer questions!"", 'Perhaps this will help\n\nhttps://robotacademy.net.au/lesson/derivative-of-a-rotation-matrix/', ""thanks for clarifying that! I read a lot of material in last 2 days, but I think it has just fogged up everything. Could really use some help to sort it out. \n\nI have a bunch of questions:\n\n1) How can the rotation matrix i.e SO3 be represented as 3D Sphere? Rotation matrix (3x3) has 9 parameters, so I imagine plotting it would need 9 Dimensional space?\n\n2) I am more generally confused with the significance of derivative of rotation matrix? What does it denote? And how do we use it in optimization?\n\n3) Is it the case, that the tangent space is derived usually for the simpler case of Identity / origin (which makes it lie algebra) and assumed that similar process can be followed to derive tangent space for other locations? \n\n4) Is it true that 'Φ' represents the rotation vector in axis angle representation? \n\n&#x200B;\n\nReally appreciate your help!"", 'This video helped me kinda visualize what R\\_dot(t) = Φ \\* R\\_T.   \nThanks for sharing.']"
['IMO that’s honestly true for all areas of knowledge. As something grows in complexity it is only natural to build more abstraction (even in theoretical matters) so that we can work with more knowing less (as there’s just so much to know).']
"['It’s hard to say if I’m honest, I have printed most of the parts multiple times before it is usable so. The files arnt currently published, but it is my plan to do so. All the code, CAD (.step & stl) BOM etc will be written up so that people who are intrested can make one themselves.  I am considering making a few of them once finished which could be sold as a kit for people without a printer. \n\nI’ll keep posting updates and will have a look to see how much filament it would theoretically take to print all the parts from scratch.']"
"['There is nothing wrong with using IMUs if you know what you are doing i.e. be wary that they will experience global rotations differently due to being on lever arms with respect to your centre of rotation.\n\nI am not quite sure what your joint looks like if you have a picture that would help.  The reason i am asking is to understand the space you have for sensors around the joint.\n\nThe first thing that popped into my head is using orthogonal encoders like in old ball mice to track the relative motion of the joint.  You could probably achieve a similar effect with a camera and orientation markers.  If you do a quick homing routine at start up then you will have good knowledge of the joints orientation.\n\nWhilst i was typing that i thought of a better solution.  You can embed magnets in the joint and use a hall effect sensor to determine the orientation of the magnets within the joint. I like this better because it does not need a homing routine.', ""6axis imus have yaw drift, and i thought about using a 9 axis imu with a magnetometer but have since read they're not so reliable in buildings or when other wise near ferromagnetic materials. The machine i plan to use them is going to be made of steel so i don't think they'd work well for my particular use.\n\nThe magnet on the end of the bolt with a hall sensor might give me rotation about the bolt axis (with a magnetic field perpendicular to the bolt axis) but cant tell me the other two directions. Rotation in the other two axis i also imagine would affect the measurements of the bolt axis since the magnet and sensor are now skewed and at different relative positions.""]"
"['Hey u/xmasbad, instead of having the push rod linkage attach to a fixed point on the the underside of the bicep, make that point sit on a bearing instead. It would change the kinematics but would fix the self intersection problem. Please let me know if I didn’t explain that well or you have questions, hope that helps!']"
"[""Sry It's kind of off topic but curious if someone could help me sorce a large scale tracked chassis? I'm really wanting to build a remote control brush mower like the ones advertised on aliexpress,I've found some smaller versions but nothing big enough for what I'm needing...any help would be very much appreciated""]"
"['Do you have to correct for drift with your spatial partition? Or is the VIO stable enough that it can close loops consistently?', ""I've only seen drift from using IMUs, and that's because they're trying to determine position from acceleration data. \n\nSo you have to sum the data over time to get velocity, and then sum that over time to get position. Errors add up over time and cause drift. I.e. the position drifts over time. \n\nSurely there would be other sensors or systems involved to know the reference frame of the camera is moving though; so Imu might be used to know the car is translating and rotating etc and GPS to provide the absolute reference frame. \n\nAlso, I'm just guessing. I've never done sensor fusion or vision, I just work in the field and I am interested.""]"
"[""Lidar is a lot less noisy sensor than radar is, so it is almost always chosen over radar for localization and SLAM applications. Noisy data can completely ruin state estimations and maps. It's the job of the robot to transform sensor data into Cartesian data, so if you apply the transforms that bring you from sensor space to Cartesian space the noise may be amplified or may give you information that does not make any physical sense which will cause lots of problems when trying to localize and when trying to register your latest reading (match up the map you just created with your previous map). Long story short noise is bad. These people came up with a robust and efficient way to filter the radar data that improves the performance in terms of accuracy over other methods. It still doesn't look like it's superior to lidar, but it's a step in the right direction. I think lidar tends to be more expensive than radar (I could be wrong) at least for a good one, which is one reason this is meaningful. I think this is also generalizable, so it could be used on other sensors and in a range of environments."", 'Wasn\'t it Einstein that said if you can\'t explain something simple you don\'t understand the subject enough😅\nBut yeah this is probably pretty hardcore😅 might have to ask the author for a ""CFEAR for dummies""😂']"
"[""That's a genuine smile. Don't see many of those nowadays.\n\nGreat work."", 'The hardware part? Nowhere, I just learned Solidworks in class and went from there. The software part? Online, mostly, with some help from my professors when needed']"
"[""Your SBEC can do what you described but can your battery do so?\n\n6V@20A = 120W\n\nCan your battery supply this sustained?\n\nNot saying the servos will draw 120W total, but your battery may not be able to source the instantaneous current that can be quite high.\n\n120W means for a 3.7V cell, that cell must be capable of roughly 30A continuous discharge. This is assuming the SBEC is 100% efficient, which it isn't.  It's probably 60 to 70% efficient on the average and 80+ % near peak.\n\nAlso, did you check your gauge size for wires?  Pulling a shit ton of current with some resistance in the wire will create huge drops of voltage."", 'Yeah we’ve tried moving the jumper on the SBEC and even bypassing the SBEC entirely with just the power supply. No luck unfortunately. Thanks for the suggestion though']"
"[""It seems like an obscure book from China. Maybe try using Baidu. I couldn't find anything through normal means. The only thing I was able to find was this site [micromouse](https://micromousechina.com/index/en_curriculum_details/book_desc?level=33&class=4&good=37)  which supposedly has the book online but I don't see anything promising.""]"
"['I think you need to flesh out what you mean by GUI and the details on how it might work a little bit more before you can get a good solution. \n\nAre you expecting the GUI to run on the Pico? If so, your only options for it to be displayed is some sort of small connected screen like [a I2C OLEF](https://www.adafruit.com/product/938). If this is not what you want, then you can connect to the Pico from a computer over serial or Wi-Fi (if it’s a Pico W) and then build your GUI as a desktop app or locally hosted website respectively, that then sends the relevant data to the board which it then responds to. You’ll have to ask similar questions about where user input comes from. Once you decide on this, the way forward will be quite a bit more clear. Hope this helps and feel free to ask questions if needed!\n\n(Also, Thonny is just an Integrated Development Environment (IDE) and not likely to be a limiting factor in what you can or can’t do. Python / micropython will determine what’s possible. You might already know this, just with how the question was worded I just wanted to make sure as I wasn’t certain. Sorry if you did know this already.)', 'I see, then in that case I’ll assume you want to use python, (you can use many other languages like Java, JS with electron, etc.) so in your desktop app, using something like [the pyserial library](https://pyserial.readthedocs.io/en/latest/shortintro.html), you’ll want to open a serial connection with the Pico by specifying the com port and baud rate and then send your info accordingly. On the Pico side of things you basically just wait and respond to serial input using the same settings as the desktop app. [I found this blog about doing basically what you’re looking for (although they might doing this slightly different than the way I described)](https://goldensyrupgames.com/blog/2022-02-04-pico-simple-two-way-serial/) which will probably be helpful.']"
"[""Lol I made the same mistake with my quadrapod. The funny thing is that I could move the legs individually, but when I tried to run multiple legs at once, it would trigger an over current protector on the battery and just restart the bot. Anyway, SG90s consume \\~.5A at stall, so ya, you are going to need \\~10Amps. A smallish 2S lipo battery will be able to deliver that, get a buck converter to drop it to 6v though.\n\nA nice [drone lipo](https://www.amazon.com/Zeee-1500mAh-Quadcopter-Helicopter-Airplane/dp/B07TV4KBKV/ref=sr_1_5?keywords=2s+lipo+battery+1500mah&qid=1680536957&sprefix=2s+lipo+battery+15%2Caps%2C90&sr=8-5) at \\~1500mAh ought to do what you want, but please do be careful with them and definitely get a balance charger. The 60C on this battery means that it can output a peak of 60C \\* 1.5Ah = 90A. The C rating is weird (the unit is 1/hour), but it essentially means how many times you could discharge the battery fully in an hour without the battery over heating: this is essentially the battery's current capacity. A 60C lipo can discharge 60 times in an hour, if that lipo is 1.5Ah, that means it can discharge 90Ah worth of energy safely in the time span of 1 hour, AKA a max current of 90Amps."", 'Maybe you can use a buck converter, so it’s possible to use any battery with a bigger voltage than the output that you choose, that’s my [hexapod](https://www.reddit.com/r/arduino/comments/129l916/lil_bro_is_finally_standing_without_any_help/?utm_source=share&utm_medium=ios_app&utm_name=ioscss&utm_content=2&utm_term=1), and I’m using a buck converter for power source, even with bigger servos than yours it consumes a max of 5A', ""Thanks bro, I really apreciate your help.\n\nOne question (i'm kinda new to this stuff) a battery with 1500mah 60C means that the output is always 1500mah, but it takes 60 times to dischard the battery, or the output is always 90A? I already seached a bit but can't find the exact awnser.\n\nAll the 18 servos take \\~9A and I don´t want to buy a battery risking it wont be enough."", "">Most single batteries in this range are enormous and heavy.\n\nThat just isn't true. A tiny 1S 60C lipo w/ >200mAh capacity can sustain 50W. [These 14 gram drone lipos](https://www.amazon.com/650mAh-Battery-PowerWhoop-Connector-Inductrix/dp/B07Q2LHKFT/ref=sr_1_1_sspa?crid=1ZNVANPMWNGR7&keywords=small+lipo+battery&qid=1680537975&sprefix=small+lipo+battery%2Caps%2C89&sr=8-1-spons&psc=1&spLa=ZW5jcnlwdGVkUXVhbGlmaWVyPUE5OVJSNVFBNjVHUFAmZW5jcnlwdGVkSWQ9QTA5NDUxNTczQ1dTQzNEWE44WUNEJmVuY3J5cHRlZEFkSWQ9QTAyMDg4OTIzREZHUEdWSjRDNUJRJndpZGdldE5hbWU9c3BfYXRmJmFjdGlvbj1jbGlja1JlZGlyZWN0JmRvTm90TG9nQ2xpY2s9dHJ1ZQ==) can output 50W at like 1/4 their max discharge rate."", 'Neither. Those values dictate what the battery CAN do, not what it WILL do. The circuit attached to the battery dictates what the battery WILL do (as long as the parameters of the circuit are within the range of what the battery CAN do).\n\n1500mAH is a capacity value, it determines how much energy the battery CAN hold in total.\n\nThe C rating is a max discharge rating, it (in relation to the battery capacity) determines how large of a current a battery CAN output without the battery over heating.']"
"['In Edmonton the answer is a resounding yes. \n\nThe city council would be easily bamboozled by any company which came along and gave a winning presentation with support of some key lobbyists.\n\nAs a precedent, you can just look at the edmonton e-scooter law. Read to the letter, it effectively bans the use of non rental e-scooters. It is not enforced but this is what the law says:\n\nThe province allowed the City of Edmonton an exemption for approved and licensed vendors to operate e-scooters through the active transportation vehicle sharing program. ***Use of privately owned e-scooters on City property is prohibited.***\n\nClearly, the scooter rental people ""helped"" write these laws.\n\nThat all said, I can state with certainty that had these things existed when I was 12 they would have been wrecked at least 10 different ways on a regular basis:\n\n* Rocks\n* Paint on sensors\n* Tipping them over\n* Scrapping for cool parts\n* Figuring out how to mislead them into the ditch or off a cliff\n* Throwing obstacles around them like logs.\n* Tire puncturing\n* Entanglement\n\nThen, if they tried to escalate by having security in my hood:\n\n* Fire\n* Slamming them with battering rams\n* Projectiles from afar such as arrows, BB guns, slingshots, spears.\n\nBasically, home alone vs the robot delivery things.\n\nAbout 20 years after I grew up I bumped into an old neighbour. He told me his grandfather used to leave small cans of gasoline unattended so kids in my neighbourhood would steal them and he could laugh at the stupid things they did with them. An unusual number of kids in my neighbourhood knew not to pour gasoline directly onto a fire.', '67k is the median for all workers in the US, not the average for low paid workers. The bottom end of the pay scale is average a third of that.']"
"[""https://preview.redd.it/qmbictm1gwra1.png?width=1080&format=pjpg&auto=webp&v=enabled&s=2516a232da536a986df9a89b78f0ba019d2c161e\n\nI'm an absolute beginner to robotics, need to work on this project and I have a month to do it. Any help regarding where to begin and resources to learn from will be appreciated.""]"
"[""Use non soldered headers, and force them to be at an angle with the board, with pressure. It can work, but it's super unreliable, difficult, and not suitable for this particular purpose. \n\nI'm afraid you'll have to get one with headers, or borrow a solder iron...""]"
"[""If I were designing this system, I would break it up into two distinct problems. The first being estimating the pose of the object and the second being the path planning of the joints.\n\nFor estimating the state of the object, you will have to detect the object and then estimate some 3D information. If you are always using the same object, then you could easily extract the pose information using a PnP algorithm. While developing the system it may be useful to begin by using fiducial markers like April or aruco tags and eventually upgrade to a more sophisticated scheme. If you do not have any experience with computer vision, this will get you up and running quickly.\n\nFor path planning, your job is just to move the end effector to the estimated position of the object. I would just use inverse kinematics to calculate the final desired joint positions. I don't think you need any RL algorithms for this application. You should be able to find the inverse kinematics for a standard 6DOF arm online pretty easily. You'll probably want some logic that finds the optimal solution because there will probably be many or infinite solutions to as to what the joint angles can be to attain the final end effector pose. This could be something like minimizing joint displacement.\n\nLastly, if you do want to try and implement RL algorithms, I would look at openAI's spinning up documentation. They have good pseudocode for most of the popular RL algorithms. It will be tough to implement anything effective without at least some understanding of the math involved. That documentation and research papers is how I learned to implement RL algorithms. The symbols can be intimidating, but mainly, it's all just gradient descent. You should be able to find some good tutorials on deep Q-learning online but without knowing more about what you actually plan to use the RL for its tough to say if deep Q-learning would be applicable or not. Deep Q-learning requires a discrete action space. If you understand deep qlearning its pretty easy to implement DDPG and from there TD3. Like I said before, you probably don't need any RL for this, but they are fun algorithms to learn so by all means go ahead and try it if thats what you want to do."", ""What kind of objects are you trying to do this for? Will they always be the same object? Like I said, if you could slap an aruco tag on the object then you could call a single opencv function and it would give you an estimate of the pose. You could use different marker id's for different objects. If you can't use markers, but are always using the same object, then it becomes a PnP (perspective n points) problem, which also should have an opencv implementation. If they are always different objects and you can't use fiducial markers then it becomes a bit more complicated with just am rgb camera. You could have the area that the object is placed have a grid or some known pattern printed on and use that to extract the location of the object. That would give you the location of the object on the mat and the perimeter of the object but would not necessarily give you all of the information on the vertical height of the object. If the camera is attached to the arm you could try to view the object from multiple viewpoints and from there use stereo camera system calculations to estimate the pose. This last scenario would probably be tough to implement and would require very good position estimates of the camera to be successful. Also I know there are some researchers working on monocular depth estimation using deep neural nets but that may also be tough. Just trying to give you all the info. I would personally go with some type of fiducial marker to get you up and running before trying one of the other solutions."", ""That's more than enough thank you for your help""]"
"[""Its totally dumb at the moment. I've been trying to find a consistent way to scan complex objects with movements and patterns that expose as many faces from as many angles as possible. It does much better than my hand wavy motions, but it still requires tweaking for each new object shape. \n\nEnd plan is to use intel realsense or something similar to output the paths for the arm to automatically plan movements that sweep the sweet spot of the scanner through all of the faces/crevices."", 'At this point, its kind of a headache. I can typically put an object on there, send the robot to each of 4 different points, spin the turntable 360 degrees, and make sure the scanner is happy with the distances from the object at each waypoint. So maybe 5 minutes of tinkering with it. You can also program the turntable to move how you need it to, instead of just endlessly spinning.\n\n At very low speeds the scanner does an incredible job. VERY low noise compared to me moving it around blindly while looking at the computer screen to make sure im hitting what i need. I can also run this thing for an hour straight and it will for sure get every single point the scanner is capable of scanning.\n\nI stated off just using the arm as a tripod that I could have pose at whatever angle. Its also easy to move it around without having to take your eyes off the scan.\n\n&#x200B;\n\nOn a side note, Arctec is developing their own fully automated robotic arm scanner.. [RoboticScan](https://www.artec3d.com/portable-3d-scanners/robotic-scan)']"
"['It won’t work, because unless OP is using something like an AksIM the noise of the encoder, being multiplied by the reduction, will make motor operation very unreliable.', 'OP is using a magnetic encoder, which typically has 4096 steps / rev. If he were to pair this to a 10 to 1 gear reduction he would end up having only 409 steps per rev of the motor shaft which is way too little for any sort of reliable motor control', 'Yes, if you want velocity control and don’t care about low velocity performance, like in an ebike. If you need precise, low speed control, with anti-cogging, you’re going to have a bad time.']"
"['We know that the diameter of the wheel * pi gives us the circumference of the wheel which is equal to the distance traveled after 360 degrees. So from this we can get (d * pi)/360 = distance traveled over the course of one degree. So all you’d have to do in code is measure the time it takes to go from one degree to the next and you’d get some distance / some unit of time which can then easily be converted into any standard measure of speed like Mph, mps, km/h, etc. Bonus hint: measure your diameter in the target speed units family (if you want miles per hour, measure d in inches, if you km/h measure d in centimeters) since this will make the final conversion math a little bit simpler (not required). Hope this helps!', 'Thank you very much, this did help indeed']"
"['I would guess almost certainly not.  I would be really interested in a breakdown of what responses relied on preprogrammed behavior (probably preprogrammed a number of movement routines - can it do arbitrary shapes or just a square?) and what is entirely relying on the GPT-4 response and (probably the math calculation)', ""Yes it's pretty horrifying. I was fairly sure that you'd thought of those, but not certain. It is shockingly good at creative writing - better than 95% of people including myself I'd say""]"
"['Through the Vin /ground terminal with the help of a DC jack plug', 'Something like this DC plug?\n\n[https://botland.store/wtyki-dc/3507-dc-socket-55x21mm-with-1-m-wire-5904422349295.html](https://botland.store/wtyki-dc/3507-dc-socket-55x21mm-with-1-m-wire-5904422349295.html)\n\nMy issue is simply connecting a power supply to that hat. As you know, that hat has an unusual socket, where you have to put in wires and tighten it with a screw from the top. Standard power supplies don\'t come with such ""wires"". I am new to robotics so I don\'t have experience using such sockets (I don\'t even know how they are called).\n\nSo I was wondering if you have a solution that wouldn\'t need wires and would be more secure.']"
"['So one big thing to keep in mind is that the realistic limit to the amount of current a motor can handle is purely based on thermal properties. To understand how much current you will need you can use the motors torque constant, then compare that number to the esc to make sure it can provide enough current.']"
"['To be fair, it looks like a giant chandelier in general.\n\nHave you ever seen a delta robot?', ""It's for a sorting and QA process.  The delta will pick up an item and place it on a conveyor for a machine vision/ai system to find defects.  The environment will be humid so didn't need the food safe version per se but it helps.""]"
"['Still. If you are skilled in developing 6 dof robots, you are having a job until retirement']"
"['>*I was wondering if anyone knows of a full stack os for robots or any companies looking to make that. I think it would be much more helpful than every company like mine having to build their os from scratch and would decrease downtime.*\n\nI\'m always kind of more skeptical that it would be more successful than struggling through ROS and OS pain. Individual firms\' needs and ideas are often too specialized.\n\nIMO ROS running on a Tier-1-supported OS is supposed to BE this ""full stack OS for robots,"" but we don\'t support open-source efforts well enough financially or with contributions of our core learnings and needs. We hold them close as competitive advantage instead.\n\nThere\'s a lot about keeping up with trends in computation, deployment, good low-latency hardware interfacing, and so on that\'s just about the world finding enough developer hours for what should be nice, shared, secure, and hardened infrastructure on top of which we can build proprietary businesses easily.\n\nI think right now with OS capability issues, GPGPU compute and similar very ""general"" robotics things we\'re kind of in the very early days of things like web content streaming that subjected us old people to RealPlayer. \n\nI think from a manufacturers\' device driver standpoint, the real customers at scale aren\'t using ROS even though everyone, big and small, is using it for SOMETHING. I don\'t know what needs to be done to encourage manufacturers drivers. Are *they* finding it too hard to write and maintain and support the drivers? Probably.\n\n>*it\'s just a pain in the ass to have to build one part of the stack ourselves which is not as robust as the other parts. We end up having a lot of downtime because of this which costs us money and time.*\n\nI think most of the time, this is considered a *desirable feature* from the standpoint of your competitors.\n\nYour individual stack and learnings and process are part of what gives you a competitive edge. Your company failing to get that all right is great from your competitors\' perspectives, because they can move faster than you and build better products.\n\nI think a lot of areas in robotics would advance more quickly and to greater macroeconomic benefit if every single firm dedicated a substantial fraction of their resources to improving the open-source ecosystem.\n\nI think we\'re under-collaborating and over-competing. It\'s too hard and specialized to build robots with the existing tools and it\'s making it hard to make markets where customers start to ""feel"" like robots are a good solution.\n\nIt\'s not unreasonable to do work that helps your competitors in nascent markets, because the growth of adoption and customers\' growing awareness that a robot can do this job will more than absorb the output of lots of small companies.\n\nI think it\'s rare to find startup investors, especially in robotics, that feel that way. Hardware is already sucking down a bunch of the capital, having all the devs spend a couple days a week and infrastructure-focused devs spending all their time giving away your ""secret tricks"" for free to competitors is probably not that attractive.', 'Actually the code that runs on your robots is open source. You’d only pay if you use Viams cloud services for things like data storage, ML training, etc - consumption based like AWS. \nOther differences include an API that remains consistent regardless of the model of component- you swap out one arm or motor or camera and you don’t change your controlling code, only your configuration.  SDKs in various languages so you program your robot in the languages you want. \nHappy to answer more. I do work at Viam and do love building robots with the product.']"
"['I cannot tell anything without seeing the actual pcb layout but it seems like either stepper signals are picking up some power supply noise or the stepper wires are so close that they induce some current on each other.\n\n * Try completely separating the stepper wires to see if it helps.\n * Check the total current capacity of the power supply and see if it matches whatever current setting in the cnc board.\n * Try lowering the maximum current setting on cnc board to check if there is any crosstalk for signaling the stepper drivers.\n * Try even thicker wires as they seem to help. You may be underestimating the amount of current they have to carry.', ""Two suggestions for trouble shooting from a non-expert: \n\nTry to figure out if the noise is coming from the board (likely), the motor, or the wires (unlikely). That could help isolate the issue.\n\nTry to measure the frequency of the noise and see if it's close to an integer multiple of the PWM frequency of the board (assuming it's setting a vintage or current by PWM). If that's the case, maybe you can change the frequency to make it less audible, or consider a different board model.""]"
"['Some of the remaining missing stuff is that adaptable, general-purpose robots are very expensive, and for both software and hardware, adaptation in a complex, unstructured environment is still tough.\n\nA bunch of your examples are each pretty possible with a custom, purpose-built robot, but it\'s not really yet possible to build or effectively program something that can nail a bunch of boards precisely every foot AND dig post holes to a certain depth AND hold beams in place while the concrete sets AND grout the tiles in a bathroom AND mark out some pattern on the floor for framing in a bathroom AND ... AND ... AND\n\nThere\'s also just an agility, dexterity issue for ""carpentry"" and lots of useful home construction. We are making great, rapid progress on all of this, but we\'re not there for dexterous manipulation in small and complex spaces.\n\nI\'ve haven\'t done much home construction, but I\'ve done a lot of construction for big machines, welding stuff from the inside, doing plumbing in tight spaces, running wires in complicated ways, installing belts and pulleys and sensors, doing lots of stuff on ladders. I\'m fat and clumsy, and even I\'ve contorted myself into body positions and done carefully balanced stretching reaches to do work that would absolutely challenge the best dynamic robots out there.\n\nTo make the costs work out, you need to have robots that are useful in many/most situations. It\'s just too complicated, varied, and weird for that to be true yet compared to the amazing things humans can do with their bodies. There\'s a lot of energy and investment going into general-purpose humanoids right now, lots of real and meaningful advances in robotics and AI despite a mountain of breathless hype to go with it, but it\'ll be a long time before many of these advances are really competitive with the agility, planning, perceptual, and cognitive abilities of an average human, even a quite unskilled one.\n\nSafety is a big issue, and I bet liability and insurance will become a bit complex once the tech is there.\n\n\\---\n\nThere\'s a lot going on for special-purpose machines for important big construction jobs. Built Robotics is a good one to look at:\n\n[https://www.therobotreport.com/built-robotics-develops-autonomous-solar-piling-robot/](https://www.therobotreport.com/built-robotics-develops-autonomous-solar-piling-robot/)\n\nBut I think that\'s all operating at big-project capital costs and it\'ll be a long time before things filter down to carpentry/home construction.\n\nEven at smaller scale we\'re still often talking about tech that is most useful for large, clean, commercial construction sites:\n\n[https://www.hilti.com/content/hilti/W1/US/en/business/business/trends/jaibot.html](https://www.hilti.com/content/hilti/W1/US/en/business/business/trends/jaibot.html)\n\nThere\'s less variation, wide open spaces, and so on. We\'re going to see a lot of construction robotics working in environments like that for a long time. They\'re superior to humans because they can precisely localize from some optical or other high-accuracy positioning system (RTK GPS outdoors) and they don\'t need to spend time manipulating measuring devices, they can just ""go to spot and drill"" or mark or whatever.\n\nVery useful, but gets less useful for smaller and more complex job sites.\n\nThe nice thing about these approaches is that they very heavily leverage what robots are actually good at. One of those things is kinematic precision. They are much more accurate at placing their end-effectors precisely compared to a reference point on their bodies, and you can add sensors at will to improve that more and more.\n\n\\---\n\nSuperhuman strength and endurance with human control could be a place you\'ll probably see things happen sooner. Sarcos sells exoskeletons and teleoperation robots that let the human do the cognition and planning but let you lift a couple hundred pounds overhead with one arm.\n\nI could see a lot of value in having one of these for a house building project:\n\n[https://www.sarcos.com/products/guardian-xt/](https://www.sarcos.com/products/guardian-xt/)\n\nYou probably COULD use it very effectively to put things in place and hold them while you affix them. You\'d be the one doing the hard bit to get it there, but it\'ll hold it effortlessly for as long as you like while you do some stuff.\n\nI bet it\'s eye-wateringly expensive. Someday that kind of stuff will easily filter into home carpentry when the prices get low enough, but I feel it\'s less cost-sensitive industries that can use it right now. Aerospace, military. I guess solar is a big one right now:\n\n[https://www.sarcos.com/robotics-applications-and-use-cases/solar/](https://www.sarcos.com/robotics-applications-and-use-cases/solar/)\n\nHardware costs for precision machines just aren\'t dropping that fast to make that kind of tech super accessible, though I imagine when they\'re in more mainstream production you could start to see specialty rental companies where you could hire it for a few days of your project at a reasonable cost, just like you can with the boom lift alone.\n\nSomeday there will be safe and capable enough AI to help do some of that activity on its own. In the near term, closely supervised semi-autonomous can be a good teaming strategy there, to help increase the productivity of the team more by letting the robot do the simpler things and having it wait until the human can help it with the complex bits.']"
"[""You're better off reaching out to other maker clubs who have been through a lot and have a lot of know how and the ins-and-outs, so they will help you out rather than trying to do it from scratch. \n\nStick to your school's culture but also try to associate with a bigger maker culture. \n\n>I am still wondering about what should be the output of the club (A bunch of projects completed by the end of every semester? Participating in competitions?) and how do we get to that point.\r  \n\r\n\nCompetitions and prizes, the easiest way is to take a problem from a company and asking them to fund a competition and give the winners(1st, 2nd and maybe even 3rd) of challenges. This could be anything, AI, Robotics simulations in ROS etc. \n\nReward always motivates students + internship opportunities too.""]"
"[""It's definitely possible, but like u/sugarlava27 said there are plenty of other options. (water ingress, faulty wiring, some mechanical fault increasing friction, ect). Either way I probably wouldn't risk that ESC on another 200$ thruster.""]"
"[""Last summer I was animating a stand at RoboCup 2022, which was held in Bangkok; since our company wanted to show sawyer, I decided to have him do a shared activity for NAO - kick a ball back and forth.\n\nSo Sawyer uses his video to find the ball, shows it to NAO, puts it in front of NAO, then NAO kicks it, and Sawyer picks it up again. If Sawyer *doesn't* find the ball (because is was kicked too far), NAO asks someone in the public to put it back into a reachable spot.\n\nI did the NAO half, and the engineers from Rethink Robotics did the Sawyer half, and the end result worked pretty well (after a bit of testing and tweaking on the booth, because of course those things never work on the first try), and was able to run in a fairly stable loop for more than an hour - the main issue I had was that eventually NAO would kind of slide out of positions, and either miss the ball or fall over because he was too close to Sawyer, which happened a couple times.\n\n(I have other videos, I might post a couple bloopers of when it went wrong)""]"
"[""I can't see why that wouldn't work. If you don't need to winch more than say 30lb, or whatever the capacity of the reel is. I'm sure it's been done at some point. I can see a use case for automated fishing reels for physically challenged individuals.""]"
"[""Hey man, \nthings you said really made my heart warm. I see you also share the same passion for robotics. I'm also completing masters in mechatronics, and I did this mainly to sum up the theory I learned at uni. Electronics and coding is also for me something new and took me most of the time for this project. I hope that I inspired you a bit for you project. Good luck and keep us updated with your progress.""]"
"['AFAIK no, in my experience ABB was unpleasant to do something closer to real time. I think you get RWS for free and you can either poll it or subscribe to changes in variables, but the whole RWS was done as a ""cherry on top"", ""nice to have"": it\'s slow, unreliable (for real time) and the first thing to get lag if there is high CPU usage on robot.\n\nBetter suited for you would be EGM, which gives you something like 200 or 500 Hz updates, but I believe you have to pay for it.\n\nOther thing you can think about is connecting some external e.g. CAN device, that (AFAIK) can access all the data on the robot and then connect it to the ROS. But added complexity and not sure it will work.']"
"['This, which looks super cool is the incredible awesome gorgeous TREE and the forest behind it❣️ Really, magic tree, fairy green nature, you is soooo happy man 💚💚💚 If you know in what gray concrete dump I ""live"" 😢', 'I put some screws in them to help with traction - but yes, the rubber on them is not great for grass etc', 'I live on a rural lot with acres - but the area I am looking to cover is equal to a large suburban lot, probably half an acre or so.  I am using an USB wifi antenna, which helps with range to my house - but something better would be preferable.  Is this why you are asking?']"
"['Absolutely. I don’t trust people to handle my food anymore.', ""The way you ask this makes it seem like you're an AI working on a design and you're going to do sentiment analysis on the comment section\n\nIt looks reasonable and helpful to me in the video. Surely grocery store workers feel differently when every target has 40 of these and at any given time, 3 have something weird going on with their wheels, 5 have been knocked over and keep bumping into shelves to recover, and 1 just sits in the corner because no one can remember what was going on and maybe in a year they'll take a look.""]"
"[""You're better off learning about Kalman Filter, EKF and then try to come up with a solution.\n\nFor monocular camera, the thing I see here is feature extraction and then using said features as landmarks and when you move your camera your imu registers by which yaw pitch roll and displacement it has moved and you use that as error correct in the EKF.\n\nIn case no one posts a monocular slam code, here's how I would go.\n1. Extract features from camera \n2. Using intrinsic + extrinsic camera parameters, calculate the xyz in real world.\n3. Using the imu when you detect motion to xyz, you calculate the position which is moved and also rotation and calculate the distances to the nearest features around the feature points and if they are in frame or not. \n4. Not in frame? Record position variables of last time that point was seen in frame. \n5. Come back in frame again? Calculate the error of your camera's parameters wrt the feature now seen in frame because the coordinates have now changed.\n\nThis is my attempt to put it in layman terms."", ""ORBSLAM 3 is the most popular library at the moment if you're looking to use something that's a fairly complete setup.\n\nIf you're wanting to learn how all this stuff works I highly recommend this open source book: https://github.com/gaoxiang12/slambook-en""]"
"['Looks like a fairly standard design. You will eventually find yourself limited by the low cost hobby servos you are using. One easy improvement would be to use something to increase friction. I enjoy these feet from mcmaster: https://www.mcmaster.com/rubber-feet/slip-on-feet-5/', ""Don't use servos with that sort of form factor. If you want to go cheap, buy a brushed dc motor with an encoder and close the loop your self. Do the calculations on necessary speed and torque, but don't expect it to be super capable and backdrivable. If you want backdrivable you need to go with a bldc. The design used in ODRI is good hardware, but the electronics can be a pain https://github.com/open-dynamic-robot-initiative/open_robot_actuator_hardware""]"
"[""Question: I'm currently in school trying to decide between CS and EE. If I want to be the one to program a robot to act like this and also be apart of the build, which field is best for me? Or can I do both?\n\nI want to build humanoid robots that have the capacity to understand and, hopefully one day, have feelings. Is this more on the CS ? Thanks""]"
"['[Source](https://www.science.org/doi/10.1126/scirobotics.add7385)\n\n> Abstract\n\n> Robotic technologies have shown the capability to interact with living organisms and even to form integrated mixed societies composed of living and artificial agents. Biocompatible robots, incorporating sensing and actuation capable of generating and responding to relevant stimuli, can be a tool to study collective behaviors previously unattainable with traditional techniques. To investigate collective behaviors of the western honeybee (Apis mellifera), we designed a robotic system capable of observing and modulating the bee cluster using an array of thermal sensors and actuators. We initially integrated the system into a beehive populated with about 4000 bees for several months. The robotic system was able to observe the colony by continuously collecting spatiotemporal thermal profiles of the winter cluster. Furthermore, we found that our robotic device reliably modulated the superorganism’s response to dynamic thermal stimulation, influencing its spatiotemporal reorganization. In addition, after identifying the thermal collapse of a colony, we used the robotic system in a “life-support” mode via its thermal actuators. Ultimately, we demonstrated a robotic device capable of autonomous closed-loop interaction with a cluster comprising thousands of individual bees. Such biohybrid societies open the door to investigation of collective behaviors that necessitate observing and interacting with the animals within a complete social context, as well as for potential applications in augmenting the survivability of these pollinators crucial to our ecosystems and our food supply.']"
"['LLMs are the most powerful AI. They can act as universal translators for any language, including computation. If you train an LLM to understand a robotics programming language such as how to move its arms, use its cameras etc. Then it would be able to use it.\n\nIf you train an LLM to read the images it sees and utilize its cameras in the same way teslas do it can both understand how to move around, and make decisions that tesla cars cannot do. Like this: ""I was asked by Bob to give a plant to Bob, I must first find the plant by searching around the area (it moves around like a normal robot would do and scans the plant), I have found the plant I will now give it to Bob"". Basically, unlike narrow AI like tesla cars autopilot which can navigate really well, if you give it such a prompt it wouldn\'t really know what to do. But this LLM is capable of utilizing multiple tools and understanding its goal as well as adapting to it, that it can successfully be used to do MANY tasks. Without needing to be programmed.\n\nBasically, like a human controlling the robot, but it is fully automated.']"
"[""Plenty on the controls side too. I genuinely don't think they're underrated."", 'They never will. Disney is extremely closed and this is mostly just a commercial. Try looking into Robo One and RoboCup. They have big groups of people that can help. Instructables has many tutorials that can really help too.']"
"[""Like where though? If you can't get an all terrain basically RC car through an area how's a crash susceptible flying drone going to help?   \n\n\nI think the one upshot of bring flight into the equation is that it could potentially clear an entire open space faster than a wheeled alternative.""]"
"['Knowledge is always beneficial. Whether this specific course of study will help you find a job depends on what the robotics market is like in your area. This class would probably be a great resume item for a robotics field service tech, if those jobs exist in your area. Find out what local manufacturing companies and robotics companies you have, check their website\'s careers page, and see how the course descriptions line up. You could also reach out to those companies to ask about qualifications. If they say ""We need people with these skills"", then you go out and get those skills, they may remember talking to you and be impressed with your initiative.', ""You're trying to life hack a difficult problem.\n\nBut many of the companies I've worked for require a degree. I'm not saying this is the wrong or incorrect route. But I'd make sure you have one.\n\nIf not, I'd seriously consider CS, ME, or EE and learning as much as you can about the other two during your studies.\n\nFurther, being willing to relocate opens doors. Also, I'd apply like crazy, it's a numbers game too. Don't sell yourself short. Many people will think they are under qualified. Always let them decide if you're qualified, don't decide yourself before hand. Last, keep in mind, they may not have time to wait for a unicorn. They may take someone with less experience in certain situations, you never know. \n\nLast, $20 should be very doable. I have 8 YOE in robotics and earn ~$84 an hour in a HCOL area on a mobile robotics team. I say it not to brag, but help you not sell yourself short. Don't chase the money though, chase the skills; cause they will open doors to experience... Which will open doors for the money... Skills, practice, money. In that order, and there's rarely a shortcut.""]"
"[""Some people can be accepting, some are not. It depends on the robots functions, and whether people will lose jobs/be watched. Some people hold onto the prejudice based on past films, and the ol 'dey took our jerbs' mentality, or the 'uncanny valley', \nThe robot has to be presented in a way that is non-threatening, helpful, and non-disruptive. Hard to do for those stuck in their ways.\nI am hopeful that it would not be the case.""]"
"['Hello All! I have absolutely 0 electronics knowledge I come from a trades back ground. I’m looking for some help from the experts. Back story info: I have a device which needs some components and a controller. I have 8 servos which must be in position a from 7am to 7pm and position B 7pm-7am. The servos are functioning as tiny door openers. They must move approximately 90 degrees and move approximately .5 pounds subject to change pending in my design. My question to you good people is how to accomplish this task I don’t have the slightest clue about controllers servos timers or their correlating power supplies.', 'Hi, I’m looking to build a bionic/robotic hand but all the kits online look incredibly expensive and I’m not sure if they’re trustworthy. Does anyone know any resources (eg websites/videos/blogs/etc) that could help?', ""Hello, I am an italian student and I have to create a robot with some other students. We need a good servo/stepper DC motor with high voltage that we can use for the arm, but we can't find anything to buy online... Can you help me find a good motor to buy online? I don't care about the price, just help me find something good please... Thank you very much for the help<3""]"
['Pico as MCU is capable of this task. As mentioned below your challenge will be power management. Good luck. 👍']
"[""In two minds about this kind of thing. On one hand its amazing what is possible. \n\nOn the other this seems to be wholly for replacing humans in a human build environment, while with very little modification to the setup you could use far simpler and cheaper solutions that suited automation, and even create solutions that were design for robot and human handling (because to be honest, this build environment also sucks for humans, we just don't have to worry about wear and tear for them because there is no capital costs and running costs for replacement units are often less than supporting outdated units)"", 'Its about transition and adaptability. \n\nThe current work environment is build for humans and while a future one may be built solely for robots, while we transition between the two it makes more sense to adapt the robots to the existing infrastructure than make custom factories (except for some cases such as specialised factories with basic robotics we have seen for decades now). Doing it this way also also helps if your business wants to change what it produces. The more general and less specialised the machines are the more flexible a business can be.\n\nIt is also helpful for humans to be able to access the robots in case of maintenance or if humans need to take over from a robot for a specific task temporarily due to an unexpected error. If one stage on the production line stops, the whole thing grinds to a halt while the robot is replaced or repaired and its just might be easier for a human to step in for a few hours.', 'The reason there is such a demand for automation right now is the warehouses and factories can\'t find people to work.  I have been doing automation consulting for 6 years now and I have talked to over facilities.  The number one reason factories want to automate is the lack of resources.  Now some may be saying ""If you pay them a living wage you will find people"".  This is not true.  I have factories that are paying $26/hr in the middle of nowhere and they can\'t find people because the work is hard.  People have different expectations of work these days.  \n\nThis unit will cost about $200k out the door.  If you are talking about a three-shift operation and employees are being paid $30/HR(including all benefits taxes, etc), that is 60k a year a person or 180k for three shifts.  You are looking at a little over a year of payback for three positions that are difficult to fill, especially the second and third shifts.', 'The sales person said this machine was designed with fewer capabilities than atlas, but designed to be easy to implement, much longer battery life, and to be mass produced for actual use in industry.', ""I sincerely doubt that you can simply move that robot to another area of the facility or even another function. What happens when shape, size and space between boxes and storage system change? Hardware and software configuration of the robot will need to be changed, you'll need an expert to do that. Expert will cost you and may not be available when you need him."", 'No doubt...what you getting paid to promote/defend? Less than 30 bux?', 'I mean I have missed some interesting stuff, e.g. this show, promat, and I had never heard of this company. I’ve been recuperating from a half dozen surgeries over the past few years just basically trying to heal and I’ve missed a lot of technological advances. This appears to be a significantly capable product that will change some industries if they are able to produce a product that is cost effective and not a maintenance nightmare. I wonder what else I missed not attending PROMAT.', "">I sincerely doubt that you can simply move that robot to another area of the facility or even another function.\n\nThe point of Agility Robotics solution is, that you indeed can do this and you don't need an expert. The robot has actually enough sensors and autonomy that it can find it can navigate around any obstacle. They have shown it to be capable of finding it's way trough the Pacific Crest Trail."", ""Actually, nothing in this case, just adding my knowledge into the mix.  Of the last 7 years, I worked 6 of them for a not-for-profit company helping manufacturers survive and thrive.  Sometimes it was changing the process, and sometimes it added technology, but in those 6 years not once did my help cause employed people to lose jobs.  More often than not resources had to be added to support the technology.  I will say people were shifted by what was suggested, but in most cases, it was jobs no one wanted to do to something easier or required more skill.  A perfect example was people at the end of a conveyor stacking 30 to 50-lb boxes on pallets all day.  As soon as a new automated solution was put in place, 1)people with interest were promoted to work with the technology, and 2)the people doing the hard work were given easier tasks.  In automation the initial focus is usually on dirty, dangerous, dull, demanding tasks that people don't want to do where the highest turnover is.  \n\nNow, why am I giving advice?  Because I have spent 30+ years working with automation, designing, selling, implementing, and teaching.  I take my experience and knowledge and help manufacturers who don't know any better navigate what is out there and make sure they have the pieces in place to be successful.  More often than not that starts with the right people."", 'Well to be fair somebody has to start it. I doubt that this is the final iteration of the model, thus they will add more features.\n\nThis robot will work very well on bad floor conditions probably too compared to wheel based robots.\n\nIf we stopped developing stuff because the first iterations will not immediately outperform different technologies, there would be less progress in robotics.\n\nAdditionally due to the more flexible reach with arms, it probably can pick up different kinds of payloads compared to a mobile platform. But this is just a rough guess.']"
['thank you! im interested in developing a gripper/toolend for it as a passion project\n\nknowing the weight I need to be working with will help']
"[""I don't know about how universities can fill this void without having Professors being more aware of the market needs and adapting their courses to that.\n\nStill, there are many online courses on C++ and overall robotics topics that are decent enough for you to try something in your own. Try looking for some repos in GitHub to contribute to as well! It will help build your CV.\n\nFor PLCs though, I think that is more expensive to learn by yourself, because of software licenses and equipment costs. I hope someone proves me wrong though :)"", ""Do you know about Robot Arms? Do you think the controller for Robot Arm is same at the PLC? This company, [Mujin](https://mujin-corp.com/mujin-controller/)(from Japan) is definitely not the standard, but it seems like they are selling this controller separately? Idk I would have to contact them to know about this. I also don't know about the standards Kuka, ABB, and other Robot Arm companies follow.\n\nPLC is ~~not~~ hard(it's deceptive, it can look easy, but it's not), please look at Codesys. The real pain in the ass is the debugging whatever janky code or logic you'll write. I'm in Germany in Master, and I've got PLC programming in Uni, but honestly it's very hard to learn everything in 1 semester, but I saw this course and I thought it's a good place to begin [https://learn.realpars.com/collections/PLC-programming](https://learn.realpars.com/collections/PLC-programming)\n\nSLAM is not an easy algorithm either, you can learn an entire semester and only learn the basics, again deceptively looks easy, but it's not.\n\nPerception is a very new field, don't be surprised if it's bleeding edge, many don't know what they are doing. Even the top AI experts burn out trying to solve it, c.f. Andrej Karpathy leaving Tesla and the entire AI codebase hit rock bottom as he was the only one coding the perception/AI stack according to Musk.\n\nC++, I think it's more to do with how good of a code you produce rather than if you know syntax, I don't think it takes much to know syntax but to produce good code needs knowing algorithms, and extensive experience in the industry.\n\nMy suggestion as someone who is struggling to graduate the Robotics program. Take 1 path and stick to it, don't give a fuck about recession, you are gonna get fired anyway, if you are mediocre in all, you will be the 1st to be fired, if you are expert in 1, you might get fired but at least you will be the 1st to be hired by the competitor if you apply for jobs again."", 'I think you’re relatively correctly in terms of industry vs academia, though good universities do teach C++, SLAM/localization, and learning for perception. I’d also add computer vision in that category. You may have to seek out these classes, and the description doesn’t always match. These are super hot topics in robotics that have been around for a while. \n\nBut honestly, students ought to be looking at job descriptions and ensuring they have the necessary skills and qualifications to get a job when they graduate. It will take years and years to get deep knowledge in these areas, sure, but you just need to know enough to get your foot in the door. I bet your college offers classes in:\n-  cpp\n- machine learning \n- computer vision\n- (possibly) SLAM, touched on in part of a course like optimal control & estimation, motion planning,  etc.', ""For GitHub, try to define which area of robotics you want to work with (navigation, localization, computer vision, etc), then focus your search there and try to find a package that is easy to test (e.g., can do it in simulation), that you like, and that is active (you can look for the help wanted/good first issue labels). Find something small and do it, and that will motivate you to do it again while putting you in contact with other people.\n\nI believe PLCs are more recession-proof, they are present in a lot of the robust systems that we have today and I don't see it changing soon. But that's a complete different line than if you follow the ROS path, for example. ROS has great support and has its adoption in companies growing, especially in startups or companies with new autonomous products. Which one you want to follow is up to you though."", ""Not really. A lot of people want to incorporate robotics in their business but are skeptical and don't want to invest in buying or maintaining the equipment. Giving them the option to try it out on a subscription addresses their concerns and mitigates the risk to them and with RaaS being fairly new, you have a little command of the prices. Really all you would have to do is worry about building a team that could handle the workload. And getting approved for funding. \n\nBusiness ownership isn't desirable for everyone though and that's totally ok. I would check with Boeing or Jelly belly if I was back in Cali. Jelly belly has a very impressive factory and it's mostly automated. I'm sure they need somebody to tend to the equipment and find more productive solutions. Aviation has been working on incorporating more automation. Last I heard they were working to set up pilotless flights for freight. You might want to see if they are looking for engineers. Boeing always has a highly competitive compensation package and great benefits. I had an uncle who worked for them for 30 years and him and his family were doing alright.\n\nThere are a few options to explore and a master's gives you an edge. Which region are you job hunting in? The opportunities differ north to south. Each region has different needs."", ""If I'm reading right and you have a masters, it is a viable option. If you work up a comprehensive business plan, you would be a shoe-in for funding. I'm heading that way with an associate's but will have to boot-strap it because I'm blind and don't know where to get funding in my area. \n\nI assumed you knew what I meant by RaaS. Robotics as a service is no joke. Companies are hesitant to make the investment to automate. They just don't know where to start and the equipment cost and maintenance is often too high for them to want to take the leap. \n\nIn addition, you can ensure mitigation of job loss if you focus on collaborative and assistive robotics. The demand is there but the service hasn't really picked up stream yet. Mostly because entrepreneurs haven't gone that way with it. I will be offering my services to small businesses primarily because they are the ones in my area that need the service the most. \n\nThe general focus in the trends right now are in I-Iot. That's consistent for people wanting to start a business or land a job. If you are wanting a job in industrial automation, you will want to learn more about PLCs and Industrial IoT. Python is also good to know.""]"
"['I\'d love to see tele-presence robots more widely adopted, but I think existing remote collaboration solutions are superior to the robotic solutions. So far the physical/robotic presence has been an obstacle rather than a benefit.\n\nLet me explain:\n\n\\- camera control\n\nthis has been solved in the META portal device, by automatically zooming in and focusing the image on the person who is talking, so you feel you\'re there, even if you\'re remote. This has partially been solved by most office meeting-room kits by allowing on-site people to set the pan/tilt/zoom (albeit control is given to the on-site, rather than to the remote)\n\n\\- mobility\n\nthis problem is not solved AT ALL in the robot side. There isn\'t a single tele-presence robot that can open doors or climb stairs or even walk outdoors. They\'re confined to a single floor most usually to a single space within that floor (e.g. the kitchen) and even in that space, they\'re confined to just those areas where WiFi signal is strong (perfect wifi in every square meter of every floor of every building is simply never going to happen).\n\n\\- interaction\n\nthis problem is solved really really well by real-time chat tools. Slack has a video call button so you can actually ring their office computer. Any instant messaging platform allows you to ask people if they have a minute to talk, etc. If you were sitting in the same space, you could look at the person and recognize what activity they were doing, and make a decision whether it\'s worth interrupting them or not. In a remote robot, you usually can\'t tell who is busy, and you certainly cannot interrupt anyone. No waving, no tapping on the shoulders, no calling from a distance...\n\n\\- attention\n\nwith an in-person meeting, you can tell for sure whether the person is giving you their full attention, whether they are understanding you, and most importantly you can get non-verbal communication (more than you get with just video calls). The robot does not solve this problem. in fact, so far no remote collaboration solution solves this problem. it is only human to talk and interact much more with the people inside the meeting room, than to stop and listen to the video call speakers. The robot would not help here, in a 3-way or 4-way conversations in a shared space, the robot presence will most likely be dealt with quickly ""are we done? can we close the call? What else is there to talk about?"" there are no spontaneous ""my kids did something funny"" interactions.\n\n\\- eye-level\n\nThe robot loses. Any video call setup (laptop, meeting room, webcam...) will allow the remote to see a clear shot of the face on the other side. All that you see when you control a mobile robot are people\'s legs and feet.\n\n\\- privacy concerns\n\nThe robot loses. REEEEEALLY bad. On a people level, the idea that the remote camera can spring up and look at you suddenly without warning is unsettling. Which is not the same as a real co-worker entering the kitchen, because that real co-worker is being looked at just the same way they look at you. You\'re equal in the scenario, while with the tele-presence robot, you may or may not see who is controlling the robot and what are they doing. And you will worry whether you\'re being recorded.\n\n\\- company concerns\n\nThe office will fight the robot.\n- does the software comply with privacy laws?\n- does the software vendor access our recordings?\n- will this robot ever see confidential business information?\n- we cannot meet the network requirements of this robot\n- we\'d love to install the robot but it would violate GDPR\n- we\'d love to install the robot but our IT security team advised against any IOT device whatsoever, and this is an IOT device therefore an information security risk\n\nThe best current solution to ""feel"" in a shared space for now are VR solutions and regular video calls. And the best current solution to the problem of ""missing out"" on office interactions is to schedule periodic travel to those office spaces.\n... Until we can all drive a powerful boston dynamics humanoid in the office from the comfort of our homes, and every office will be fully mixed between in-person and remote ... some day.', 'I appreciate your opinion, and I disagree as I expected. The key phrase here is now ""I would not want."" I stated that this is highly person dependent. For me, I can\'t imagine just opening up a video chat every single time I want to talk to my coworkers except for when we have scheduled meetings about certain projects, etc. In fact, if I did do that like in my previous job, I would probably never talk to someone who wasn\'t a part of my immediate team. We have our AR team and our artists for example, and if I only ever talked to them when it related to our VR project, I would probably rarely talk to them. Just yesterday, after I finished work, I ended up sitting back and discussing what the growth in AI capabilities meant for us programmers and the artists. I got a lot out of that discussion and learned about my coworkers concerns. It wasn\'t in front of the computers, and there is no way we would have ""planned"" a zoom call or whatever. For me, I love the work culture, and my coworkers are actually excited about the prospect. We\'re a bunch of weirdos. Whatever. What you may not like doesn\'t necessarily speak for everyone. I am just saying there is a case, even if it\'s for a few, to be made and I intend to put it to the test for myself.\n\nYou said so yourself that some people struggle to get a voice call correct, so this makes it even easier. The people that are in the office literally just interact with it like any other person. They don\'t need a camera. They don\'t need a phone or computer. Impromptu human experience. If you\'re referring to the remote user, if you watched the video, you\'d see this is why I\'m talking about it now instead of 10 years ago. With improved latency from high speed internet as well as AI that can actively recognize people and follow them, turn to them, without my input, it acts as an assist for my own controls, along with its own sensors that can help prevent it from crashing into things or falling. And as for leaving people to be interacting with some \'hardware,\' what do you call video conferencing or any type of communication via a device that isn\'t in person? Talking to a phone is just talking to a piece of metal in that case.\n\nIf you have not tried it yourself, my guess is as good as yours, but I\'m going to test it and find out for myself if it can be more than a gimmick, at least for my particular case.', 'I have addressed the points that you brought up, but you have not addressed the points that I made or the questions I asked. I will restate them more clearly.\n\n1. I have stated this is *a* case to be made for telepresence robots, which I admitted may be very few, especially at the moment. You responded by stating *you* personally would rather voice/video call, implying that your own personal preference is evidence that *everyone* or that *most other* people would feel the same, a generalization that neither of us could back up since most people in work space do have experience these days with voice and video calls but do not have experience talking to a telepresence robot. I responded that *my* personal desires are not like yours as evidence that not everyone feels the same way you would (because I am one person who does not feel the same way), which I admit I cannot generalize to other people either though. I main a point to give a few examples of what I could do with this robot over voice/video calls.\n2. You made the claim that many people struggle with getting video/audio calls right (which can certainly happen in some cases, especially for beginners); therefore, using a telepresence robot would be more complicated. In the case of the robot I will be trying, it is actually quite easy to just open up the app, and its camera feed is the first thing you see, and just tapping it allows you to full screen it, etc. I can\'t claim that it\'s simpler as I\'ve not tried it personally yet, but I disagree that it\'s necessarily more complicated. It\'s certainly even easier for anyone on the other side as they literally don\'t have to do anything to interact with it.\n3. You mentioned that internet could be bad, have hiccups in the signal, etc., which is totally valid, and which is also a shared problem with video/audio calls as they also use the internet to communicate. However, this robot has much greater autonomy that helps relegate issues with latency or less reliable connections (which if you have poor connection completely, I\'m not sure how you would be able to work in such an office or even use audio/video calls either without just using a phone instead) by utilizing V-slam world mapping, tracking people and following them, avoiding crashes on its own, and even being able to charge itself autonomously. In other words, it may mitigate the issues of less reliable connections even better because it doesn\'t suddenly stop working if the connection is having trouble.\n4. You essentially commented that it\'s more selfish to be using such a device and unfair to the people interacting with the robot due to them just talking to \'hardware.\' I disagreed by saying that logic may as well be applied to any case of using a device to communicate with someone instead of talking to them in person. In other words, it\'s no more selfish to talk to someone via a \'brick\' in their hand than it is to talk to someone via a little robot.\n5. You mentioned the issue of people being on video and recorded. Keep in mind, the camera, if used, is very visible and can even be turned off manually by them by being pressed down for privacy mode, and in addition, it is an open office that anyone can walk in on. It is being \'streamed\' not \'recorded,\' and though it does give me the option to make recordings, they are stored on an SD card rather than in a cloud somewhere. On top of that, my coworkers have given me an enthusiastic okay on that even when I explained that, so consent is important. I suppose a case can be made for those concerns still though.\n\n&#x200B;\n\nI hope you will address the above points. For your new points.7) ""The person operating the robot, will be the same user that struggles to start a video call."" This is essentially the same as point 2). I would like to add that there is no way to verify that point though as it is hypothetical. Will they? In my case, I do not struggle with the prior, and I doubt I will struggle with the latter. If my father who struggles with making a video call were to use this robot and not struggle as much, then that would make your hypothetical false. But, my example is also a hypothetical, so it is a moot point.\n\n8) You make the point about the possibility that people will be more hesitant to speak their real feelings because the communication is not being done in person and could potentially be recorded. Again, does that not apply to video/audio calls as well? I admit in others\' cases that could be a potential problem if someone has malicious intent, but in my case, my coworkers and I are already aware of that possibility as I mentioned, and they accept it. In our case, that is not really a worry as the whole reason I\'m doing this is because I love working there. I feel you would have greater worries in other companies that monitor everything you do on your work devices, period. I highly doubt for my particular use case, which is specifically what I am testing, that our conversations will suddenly change. It may if I was a stranger, but I\'m not.\n\n9) You mention that a robot is bound to where its Wifi is and that it cannot go with the coworkers to outside events. That is true. In my case, however, our office is literally just a fun place to be that we sometimes have parties (super bowl, Christmas, etc.), and we hold weekly events in the office related to the work we\'ve done, etc. We don\'t go out to the pub or whatever (which is fine in companies that do). This is highly dependent on work place culture, etc., and I don\'t intend to use this thing all day (partially due to the major time difference) anyway. Its role isn\'t to just replace me in all locations, etc., if that makes sense.\n\n10) You ask me to ""put the hat on"" for a moment, but you have not addressed my other points or attempted to do so yourself. I understand your skepticism and have admitted areas I feel are weaker, but if you ask me to do so, it\'s got to be two-way. For your point about the robot in the meeting, I have stated the use of this robot would be for impromptu meetings or conversations among other things. For that case, people would just have a regular video or audio conference. What stops a boss from doing the exact scenario you just described (at home by their swimming pool) in a conference call if he/she really wanted to do that?\n\n11) You mention an issue of recognition with multiple robots. My use case only mentions using *a* robot, me using it. I\'m not sure if a multiple robot scenario is even likely. If recognition is an issue, what in the world is stopping someone from adding any kind of decorum or using a different robot (in this case, the robot can change its colors, etc.) like clothes? If you had twins working in an office together, how do people recognize them? Usually by their voice, the way they talk, or their style of clothing, etc.\n\n12) Your whole point about advantages of using a telepresence robot over video/voice calls. You mention that with video/voice calls, you can send messages, links, files, etc., which is something that talking to a telepresence robot can\'t do, but I think that reveals a misunderstanding in the whole role of a telepresence robot. It isn\'t supposed to replace those things. It is a different use case, which I have been explaining this whole time. Telepresence isn\'t a telephone. It is by definition about sending a presence. I have mentioned several use cases above already where I personally would not/could not use video/voice calls.\n\n>telepresence - the use of virtual reality technology, especially for remote control of machinery or for apparent participation in distant events.\n\na sensation of being elsewhere, created by the use of virtual reality technology.\n\n13) You state that it took a lot of time and a major need that appeared for people to see the advantages of video/voice conferencing and accept it, but you also say that there are obvious advantages to using that. They couldn\'t have been so obvious during that period if people didn\'t accept and adopt it, so I feel that contradicts what you said. Therefore, you cannot use the same argument to say that telepresence robots have no advantages based on people not accepting and using it right now (because like video/audio conferencing, someday in the future, there may arrive even more valid use cases and be acknowledged more).  \n\n\n14) ""I cannot see one real world advantage."" Which is the whole point of this post. I have a theory it does, and now technology has gotten to a point where I can test it for myself. Whether you personally cannot see a real world advantage is a completely different matter compared to not knowing if there is an advantage or not. I do not know for certain myself, hence the point of testing it for myself for *my* personal use case. I will be able to tell more surely if there is potential or if it\'s a waste of time and money at the moment. You\'re not having to pay for anything, so you\'ve got nothing to lose unless you just *want* it to have no purpose.\n\nI apologize if I got heated with my points. I actually appreciate you bringing these points up as it\'s actually helping me consider the areas I may not have before. I think the main thing I learn from this discussion so far is that voice/audio calls are definitely not meant to be replaced by telepresence, only that it serves a different purpose that has not been fully realized before (hence why if it works, it was just difficult to see beyond a hypothetical before).', 'I don\'t think you got heated with your points, but you are not reading my points correctly. \n\n1) - I have been through this pretty well exact scenario many times before, it\'s just \'another new\' technology. Having seen the slow acceptance of Internet / video calls / ANY new technology (many years within prestigious universities). Its my PERSONAL opinion and my professional opinion as someone who has been developing and implementing technology since the mid 1990\'s. I have worked for many different organisations all in senior technology / management roles getting real world humans to accept new technology and trust me from the voice of experience very few people outside of the field that works in telepresence will want telepresence. I have been doing remote work since the 2000\'s and managing remote staff much of that time as well. \n\n2) MANY corporate / government people do struggle to use Excel, send an email, start a video call. Do a teleconference with a government / corporate NOT in IT and its just plain obvious. These people still need to want to interact, and be able to operate the robot - it\'s not going to be mainly IT people (who can already remote work) - using these things. \n\n7) extra: This point is not theoretical it is real word, many humans struggle to use technology. \n\n&#x200B;\n\n&#x200B;\n\n3) Internet can be bad, technology needs to be able to handle that scenario, a telepresence robot will still suffer bad connection as do video calls. I can see a still picture of your face - when the Internet goes down - doesn\'t help. \n\n4) - I never said selfish. If I am on a phone call with you we are both on hardware, have you tried to do a conference call - when everyone is in one meeting room and you are on a video call - it never works well, the telepresence robot will be exactly the same problems.\n\n5) The audio / video does not necessarily go to SD card, it goes to where the developers have set it up to go. Streaming and recording are effectively the same thing. You have said you work for an AR / VR company - of course the people you work will be enthusiastic about it. Ring 10 of your mates who do not work in IT, get them to read your and my answers - and see of those 10 - how many want to interact with a telepresence robot professionally. \n\n8) Yes tele presence suffer the same negative here as video calls.\n\nFor the casual meetings you want to have in the hall with people - you are a stranger to them, they are not going to be as open / forward with you as with people who have already met you. \n\n9) Much of the \'real bonding\' at work happens outside of work, \n\n10) How have I not put your hat on, I understand exactly where you are coming from, what you want to do. I have worked for remote clients and had remote staff for a very long time, so am very experienced at this from both the technology side and the human side. I think I have answered all your points. \n\n11) Corporates / governments love desk sharing - you don\'t think that if this ever does happen, that this morning you are robot 15, this afternoon you are robot 48. If a company does this - they are not going to do it only for one person, they will try it for many as it will have different advantages / disadvantages in different roles. \n\n12) I understand the use case of a telepresence robot. Those advantages I was talking about where in relation to video calls (Skype / teams etc., ) over a normal phone call. Even with all those advantages it took COVID to finally make it get market adoption, after 15 years. \n\n13) Do you deal with humans much ? Humans are hopeless at learning / understanding new technology. My point is valid. \n\n""They couldn\'t have been so obvious during that period if people didn\'t accept and adopt it, so I feel that contradicts what you said."" Go and try and implement a technology project in a corporate or government environment and see the real level of IT skills of the average person. \n\n14) If you can\'t convince me and I am all for new technology, you are going to have no hope getting a sales manager / average NOT IT senior manager to use it / accept it / pay for it. \n\nIf you want to test it - go for it, I am just saying that outside a few very specific industries, I can not see this technology getting large market acceptance.']"
"['Great work buddy 👍\nBtw can you tell me how u had done that??\nNeed some help ..', ""Yes definitely a lot of interest out there on the theory and build. For me personally, I want to know more about the WHAT and WHY a robotic arm. \n\nDon't get me wrong, the James Burton build style videos out there are cool, but I hate to see a one off build for the sake of entertainment and then stashing it in a backroom for the rest of its life. I want to see what and how robotic arms can make or save money, and how they can automate manual labour along with a cost benefit analysis.  Would be even cooler to explain if a DIY solution is possible for existing business owners and what the differences are with commercial grade arms.  I think this would be a very good opportunity to create unique content they could potentially help spearhead your online presence. \n\nKeep us posted.""]"
"['""scara arm"" is the 2 joint pendulum design you are talking about. Search the web there is information about building them and ik is fairly simple.']"
"['This is helpful, thanks!']"
"['Congratulations, looks impressive as I said before you have a great talent and I wish you a great success.', 'Mechanics (torque), dynamics (of weight, mass, movement), electronics (motors for the required torque, PWM control for said motors, where to find the best and cheapest PWM drivers, power consumption/management, communications, drivers to communicate with PC, programming of how to behave/Blindspots/curves, etc etc).', 'I really appreciate the work you gave put in as I am working in something similar as part of my graduate thesis.  It is also a 6DOF manipulator, but it need to have a load bearing capacity of at least 1.5 kg. Currently I am in the designing phase, i.e., lots of CAD modelling.', 'I asked another bot to ask reddit mods to do that, and he said only mods can pin their own comments. So can we just like his comment instead?']"
"['So you can attach the en pins to the motor and use the pwm pins attached to an Arduino pwm capable output to control the speed of the motors. By analog writing to the enable pin a value between 0-255, you control the speed between no speed to full speed, respectively.']"
"['If you can’t solve it, you shouldn’t be on the team.  But if you really want to be a cheater that bad.  Use chat gpt', ""That's a dick answer. I'm absolutely horrible at math and need a calculator for everything. It's never stopped me from being successful at building robots, having a career in computer science, or doing any of the things I was told I'd never be able to do without advanced math skills. You don't need to be able to solve that equation to build a rover or be on a robotics team. And using gpt to get the answer isn't cheating if the end goal of the problem being solved is achieved."", ""😂lol good to know I am not the only one that suck at math and still want to pursue robotics. I agree solving the equations doesn't help in building the robot but atleast you should know the concept like someone mentioned rocker bogie mechanism."", ""I've already studied about Rocker-Bogie Mechanism and all about past NASA rovers . I've even solved the phi(max) part of the problem .\nI've partially figured out the expression for y , I'm just asking for some help on that . \nAlso this was the only question I wasn't able to solve for the app .""]"
"[""Pneumatics. Soft robotics still heavily uses pneumatics. Pneumatic actuators are inherently inefficient and not very responsive. Using them on mobile robots in the real world is questionable as the inefficiency severely limits autonomy. \n\nThen there's the question of why to use soft robotics at all. Most animals aren't entirely soft. The preventing injury to humans argument becomes obsolete if robots become smarter. If robots become smarter then we may not need soft grippers. Grippers that aren't soft may be more capable."", 'Generalization towards design regarding actuation and sensing. Perhaps even branching into semi-soft robots. \n\nSince the mid 2000\'s, the number of different soft robotic designs has skyrocketed, all quite different in design. Many applications of robotics focus either on ""locomotion"" or ""manipulation"", yet there is little concenses on what makes a ""good"" soft robotic design for such applications. Poor design leaves room for parasitic (joint) motions in soft robots, that inherently complicate sensing, modeling and control. \n\nI do believe entirely soft robots form a nice academic niche, but ultimately these robots should pursue a broader spectrum of mechanical compliance accompanied by good design principles if they want to achieve similar dexterity and performance akin to nature. \n\nAlso, I believe the Soft Robotics Toolkit is a good platform for converging on designs that work (e.g. the PneuNet), but the site hasn\'t been updated since 2018...', ""> Most animals aren't entirely soft. \n\nI'm not sure I'm going off of the same premises as you. Most animals *are* soft, unless you have some different definition of soft than I do.""]"
"[""Oof, that is a REALLY long article. I hope I will find the time to read it entirely.\n\nIMO, the important frontier isn't retirement homes. At that point the demands on any robot is insanely high because the residents are often struggling with even the most basic things.\n\nRobotics needs to enter elderly people's **homes** in order to help with basic chores they can't do anymore. Take out the trash, clean the windows, that type of thing. Essentially anything that will allow them to stay at home longer."", 'That makes sense. I wonder if the reason companies and ministries in Japan focused on robots for nursing homes is because those places, like hospitals, have a lot of frequent routine tasks to do in a relatively unchanging and predictable environment. Ie, an easier challenge for a robot than someone\'s home. \n\nHome is where people are the most inclined to express their individuality and insist that things be ""my way,"" and not standardized. That seems like the toughest possible environment for a robot, compared to a factory, hospital, office, or wherever else.']"
"['>*Could be used, only the magnetic force, just needing energy when changing the state of the actuators, or also add the electromagnetic force, directing a constant current to the electromagnets.*\n\nThis is similar to how some latching relays work:\n\n[https://en.wikipedia.org/wiki/Relay#Latching\\_relay](https://en.wikipedia.org/wiki/Relay#Latching_relay)\n\nI think what you\'re going to find in the context of robotics and ""muscles"" is that your electromagnets are going to need to be very large and heavy to pull together over any distance and any load you\'d be interested in (in particular, getting the electromagnets\' force at large gap to be similar to a safe working holding load of the permanent magnets).\n\nUltimately, you\'ve got a direct-drive electromagnetic motor with a little smidge of help from the permanent magnets when they\'re far apart. The strength of your muscle will be almost the same as your two electromagnets alone, so you can start by figuring out how much force you can ""pull"" between two electromagnets at maximum extension.\n\nYou also need them to be strong enough to ""push"" hard enough when they\'re close together to separate your permanent magnets, which you can also figure out.\n\nThe latching aspect would be nice, but you need your electromagnets to be pretty much big enough to do these jobs by themselves, so you can start figuring it out by working just with electromagnets.\n\n>*So far I have developed the basic part of this idea, have thought more things, but first would need to experiment and check if the actuators work. For now, I\'m just presenting it, what do you think?*\n\nI\'d absolutely start with research, calculations, and simulations to get an idea of how big your electromagnets need to be.\n\nYou can start winding and doing experiments if you like to do things that way, but you\'ll be able to iterate a lot more on the idea and geometry if you can calculate.\n\nWhen the electromagnets are far apart compared to their size, you can use the equation for force between magnetic dipoles, but they WON\'T be far apart compared to their size in this application, so a numerical simulation might be worthwhile.\n\nI think [FEMM](https://www.femm.info/wiki/HomePage) can handle this problem:\n\nHere\'s an axisymmetric speaker simulation that shares some characteristics of the problem you\'re interested in, in the sense that it has a current-carrying coil and a permanent magnet in it:\n\n[https://www.femm.info/wiki/Woofer](https://www.femm.info/wiki/Woofer)\n\nSection 3.1 discusses force computations\n\nHere\'s another one with some force calculations on an axisymmetric geometry, this time for a solenoid with a tapered iron plunger:\n\n[https://www.femm.info/wiki/RotersExample](https://www.femm.info/wiki/RotersExample)']"
"['The pph is the massive problem with most I have seen. The fastest version I have seen, most people would hate because it just dumps a wall at a time into a dustpan essentially. That and irregs like you said.', 'Nice to see there’s progress on it, I can imagine just having it for large packages will be helpful']"
['thank you for the help!!']
['I need a robot that can punch stickers out!! Please help!! I can send you a video of what we currently do by hand and need a robot like this']
['I think a great first step before trying to continue would be to try and learn a bit about breadboards. There are tons of great videos by people all over YouTube. Just type in “how to use a breadboard” and even a short 5 minute video I think will really help nudge you where you need to be']
"['I’m creating my first project and it’s a robot arm. I want to add a sensor or multiple sensors to detect if it’s about to hit something. I’m using an arduino nano and servo motors. I have the servo motors and sensor working, but my issue is stopping the servo motor before it’s going to hit something. For example, if I’m turning from 0 degrees to 90 degrees on a single servo motor, but something is at 70 degrees, I want the servo motor to stop at 65 degrees and wait for another command (I haven’t thought about what’s next, I just want it to detect that it’s going to hit something, and stop before it hits it). My thoughts right now is to break down the command to turn the servo motor into smaller commands (like turn 0-10, 10-20, 20-30, …) and I can stop the command inside the inner loop. \n\nAnything helps!', ""Hello, i am potentially going into a master's program this year (BS in EE) and it will be paid for by my company. Currently I'm working as a manufacturing engineer but ultimately I want to get into the robotics space. Manufacturing has a big focus on automation and i see this as a plus in choosing a master's program because it is related to what I want but my options at the nearby university are limited. With that in mind I'm looking at a [signal processing master ](https://www.uwb.edu/stem/graduate/msee/research/signal-processing) or a [computer engineering master](https://www.uwb.edu/stem/graduate/msee/research/computer-engineering). I'm leaning signal processing but I don't know if that's the right choice given my goals. any advice?"", ""I have been learning more about control and robotic kinematics but am wondering if there are any courses or roadmaps to best work towards applying machine learning to a robotics system?  \n\n\nAlso if anyone has any book recommendations for getting a better understanding for  \n\n\n* Linear Algebra (Need to get a stronger understanding for PID)\n* Controls\n* Electrical Engineering\n\n&#x200B;\n\nI'm familiar with the basics but it has been some time since so any recommendations that can help me get back on track would be great!"", ""I am currently working on a re-design for the robotic arm for my University Rover Challenge team, and need a bit of guidance. \n\nThis arm has the following requirements:\n\n* Must have an overall reach of 3 feet\n* Must not weigh over 20kg\n* must be able to pick up and move a 15kg load\n* Needs to have 6 dof in order to allow us to pick up and turn screwdrivers, ammo crates, and the like\n\nI understand a lot of the mechanical design aspects, but am struggling in regards to how to search for, select, and accommodate motors. I have created a basic calculator that tells me the maximum amount of torque needed at each joint, but the numbers are significantly higher than what any solution can provide.   \n\n\nIs there a good place to start looking? Do you all have any recommendations of motors that I should use?   \n\n\nThanks in advance for your help. If you want more details, I'll be happy to provide them."", ""Former urc mech team lead here. I'd suggest lowering your payload requirements, and your requirements in general where possible - finding a base joint that can handle that much weight is no joke. Designing a 6dof arm at all with 15kg is a lot - starting from scratch, my team went through 3 designs to get to an arm originally aiming for those requirements with a 5kg payload and we still only got it down to 17kg before reaching diminishing returns.\n\nWe opted for linear actuators for the first couple joints since they were relatively cheap and strong, plus we had a really hard time finding gearboxes/motor+gearbox combos that weren't incredibly heavy while still having close to enough torque. Some teams have had success with self designed cycloidal gearboxes, and IMPULS got working 3d printes strain wave gearboxes on theirs, but if you go that route be ready for lots of design time/testing. \n\nLooking at SAR videos is a great resource to see what works well for other teams, so don't be afraid to look at those a lot. Good luck on your design!""]"
"['This is a Fakespot Reviews Analysis bot. Fakespot detects fake reviews, fake products and unreliable sellers using AI.\n\nHere is the analysis for the Amazon product reviews:\n\n>**Name**: Flysky FS-i6X 10CH 2.4GHz AFHDS RC Transmitter w/ FS-iA6B Receiver \n\n>**Company**: Flysky\n\n>**Amazon Product Rating**: 4.6 \n\n>**Fakespot Reviews Grade**: D\n\n>**Adjusted Fakespot Rating**: 2.4\n\n>**Analysis Performed at**: 03-10-2023 \n\n[Link to Fakespot Analysis](https://fakespot.com/product/flysky-fs-i6x-10ch-2-4ghz-afhds-rc-transmitter-w-fs-ia6b-receiver) | [Check out the Fakespot Chrome Extension!](https://chrome.google.com/webstore/detail/fakespot-analyze-fake-ama/nakplnnackehceedgkgkokbgbmfghain)\n\n*Fakespot analyzes the reviews authenticity and not the product quality using AI. We look for real reviews that mention product issues such as counterfeits, defects, and bad return policies that fake reviews try to hide from consumers.*\n\n*We give an A-F letter for trustworthiness of reviews. A = very trustworthy reviews, F = highly untrustworthy reviews. We also provide seller ratings to warn you if the seller can be trusted or not.*']"
"[""But wasn't the problem last time that they couldnt figure out where to reliable land? How does this not have the exact same problem with a wire added in to make it harder?"", 'The technology is there.  Unfortunately we’re making more obstacles for drones now than ever before.  The laws that govern this through the FAA are changing almost constantly.  The stuff drone pilots had to study and pass 6 months ago is largely no longer relevant.  \n\nAnother thing a lot of people fail to understand, as one poster commented below about pulling them down, these are registered aircraft.  You take down a drone, it’s the same as taking down a large jet.   Even Sen. Charles Scott of Wyoming last month said people should be allowed to shoot down drones with a shotgun.  Ignoring the fact that that is highly illegal, could you imagine what would happen if people started drone hunting?  What would happen when they rupture those LiPo batteries and an explosive burning fireball starts hurling toward the ground?  \n\nGenerally speaking, as of right now, drones are limited to a max flight height of 400’ above ground level and line of sight must be maintained between the operator and the drone.  They also have to abide by all of the same airspace clearances and approvals that manned aircraft do.  Finally, by September of this year, all drones over 250grams will have to be registered and transmit their location in real time.\n\nEdited to add: I’m speaking from a United States perspective in regard to the laws and rules mentioned above.', ""He specifically said at the beginning that they weren't paying him to make the video, he just liked what they were doing...\n\nIs a guy with 23 million subscribers really going to risk his reputation for that?"", 'Like the above commenter said, the difference is regulation. The federal aviation administration (FAA) governs ALL airspace in the United States. They have been very conservative in allowing truly useful operating modes such as beyond visual line of sight. Meanwhile, politicians say stupid things everyday to impress their constituents so I would disregard what the senator from Wyoming (literally the least populous state and one of the least relevant states when it comes to drones) says. On the other hand, road regulations are made mostly at the state and local level, which is why certain cities such as San Francisco and Phoenix have greenlit autonomous driving companies to operate on public roads.', ""He's advertising a technology that he thinks could help save the world from being destroyed by pollution...\n\nSo suspicious. Clearly an asshole."", ""Drone deliveries are an already established technology, and have been for years. There are a dozen companies in this space. Many with similarly quiet drones, and cable based delivery systems.\n\nBut this wasn't an overview of the technology and the companies operating in this space, this was a spotlight on this specific company\n\nThe blood delivery story was cool, and if it stopped there it would have been fine. But he showed CGI renders of a product a company hasn't finished developing, and making promises on behalf of the company on what the hypothetical product could do. And then didn't disclose that CGI was used, or that zipline themselves said their product won't be ready for its first read flight until 2024.""]"
"[""I just pulled up the cad. The robot is open source so there is a good amount of documentation. The leg design is the same as most quadruped robots use 3 revolute joints. While the pupper does have a 4 bar linkage for the knee, I'm fairly certain that the link lengths mean its just a parallelogram. This leg design is simple enough that your unlikely to find a research paper covering it. Here is the code where they do the kinematics: https://github.com/stanfordroboticsclub/StanfordQuadruped/blob/master/pupper/Kinematics.py""]"
"['What he said 👆', 'I was looking and found some (not automated) used for baking and pastry. They used hand levers to dispense a given amount. With access to a 3d printer and an electronic solenoid I think it would be easy to design one. The screw idea would work similarly as both are inclined/declines and the screw could be designed to release a specific portion for each rotation.\n\nBoth ideas could use a fairly large hopper to hold sugar. Just make sure the solenoid/screw releases the smallest increment of sugar you need and larger increments can be whole multiples.']"
"['As other comment said, it may be not really what you are looking for, but anyway I would suggest taking difference in angle. Probably the best way is to get rotation/quaternion vector of target and actual orientation and calculate angle between those two. But you can also get RPY or other representation and sum up those errors.']"
"[""it's weird that info isn't on their datasheets.  Worth asking the manufacturer or distributor. \n\nScrewing with the power won't help.\n\nJust, checking here, but there was a point where the signal was stepping faster but the motor couldn't keep up? If that's the case, ramping up might help overcome the inertia to get it moving.""]"
"['Replace “medical aid” with “guided munition” and this would probably get an extra billion in DARPA funding.', ""Well your doing gymnastics now too. Uk delivery by bike makes sense if you are familiar with their suburbs and zoning. The US well it's single zoning suburbs that are spread thin. As in low population density. I'm from Denver and the specific suburb I last lived there in was off Broadway but far south of municipal Denver. I'm actually laughing at the idea of a bicycle delivery there. Large hills but ok you could do a. Hybrid electric for those. But the distances and zoning mean that you probably do 1-2 orders per trip that's encompassing 3-4 miles one one (look up suburban food deserts). So, bikes solves this by? The infrastructure is the problem. Because in your mind it's bike couriers with loads of orders all within a square mile but in a US suburb it would not be enough to justify the costs and effort. It practically doesn't for the services now lol. The US overall just doesn't have dense enough housing to make this work. We'd be better off nationally banning single zoning housing and let the bakers, cuisine, etc move into neighborhoods. But again it doesn't change the physical layout of suburbs, spread out, isolated, and unfriendly to pedestrian traffic (including bicycles largely - if you disagree try riding through a suburb with all the stop signs, etc). Basically there's no transportation system you can propose thars going to make it economically viable to do these deliveries unless your a big ole company that outsources costs to contracted labor. Because it's not a winning game. I live in Asia and oh man, high density housing means I can get anything delivered by someone on an ebike. But I couldn't imagine that in a spread out suburb because it wouldn't be profitable.\n\n\nTo be honest I'm hoping the US does start to shift to higher density housing and people can actually have bike couriers that can make a living etc. It would solve so many more problems than just this though lol."", ""I'm an embedded software engineer at Zipline. I lol'ed this morning when I heard that line, and my wife just looked at me funny. I think it's fair to say that it's equivalent performance to military grade equipment, though. Overall I thought this video was really awesome."", 'imagine when u/xyfoh realizes that countries other than america have similar road systems that rely on cars', "">It's a clever technology but it's yet again incredible mind gymnastics of the US to believe they can't solve their current problems with car culture by using existing transportation systems.\n\nNo, this is what you said. And that is what he responded to, not some magical point, that you didn't articulate, but somehow you implied, to undermine his response.\n\nChanging your narrative to support an argument is bullshit and you are a fucking coward for doing it."", ""There's a project called AgOpenGPS that the original developer is a farmer not far from where I live, I got started with it very early on and have been helping here and there with it.  I think I'm on my third iteration of it now on a couple of tractors.  But it's being used across the world now and gives access to this sort of technology to areas without the income to afford commercial GPS.\n\nIt's a pretty good setup, I prefer it to the Trimble unit we have that cost almost $20k.  It will do all the turns at the ends of the row if you set up the boundaries correctly, and it pulls into the nav line much nicer than Trimble, without a bunch of bumping and oversteer.  Brian uses a method called pure pursuit that seems to make it work much better but it's a bit of a journey to calibrate well for a new tractor.\n\nhttps://discourse.agopengps.com/""]"
"[""Are the cards in some sort of protective cover or are you going to allow the robot to touch the cards?  You may have to create a 'shuffler' that can handle sleeved cards.\n\nIf you consider the problem as a binary problem, you are just doing 2 piles (i.e. chosen vs unchosen) based on some rule or criteria, sounds fairly easy enough.  A raspberry pi with a camera, opencv, and some data set for 'matching' the cards is a good start to id the cards.\n\nNow for the physical part, you'd need to create something like a shuffler. You could stack the cards in a tray that keeps the top most card visible and slideable (just like a playing-card shuffler) and then based on the output from opencv (is it chosen/unchosen) shuffle it right or left into piles.  Let's say chosen cards go left, so you dump them all in a pile.  You could even track the quantity and order of the final cards in that pile.\n\nRinse and repeat for each subsequent sorting rule on the remaining cards."", ""I do have an interest, but I have to be honest, I have so many half finished projects at the moment, I think it would behoove me to just concentrate on the parts that I need to and buy what I don't""]"
"['Actually, once, I\'ve ask my automation professor (he\'s specialised in control theory and modern control) if it\'s possible to define the PID parameters with functions rather than a constant to have a better respond, so it can respond to different conditions, where this functions is defined by the system states, the conversion progressed and he even pointed out that how in modern control, the observer ""the sensing element"" not only can be used for the standard feedback loop, but also the feedback is used to change different parameters to respond to the different environments of said system. In a way, each mathematical element can be a subsystem, and the changes of the environment ""the plan function"" could be addressed from the controller, as if the controller\'s transfer function is actually the result of summing different subsystem, where the plant acts as if it is an unchanged transfer function, resulting in the feedback not only changing the system respond, but the base system itself. So I don\'t think this is new, but maybe they have done it better?\nP.S : I\'m a big control theory enthusiast\nEdit: I\'m just overlooking the click baity stuff about insects and crap if it\'s not obvious']"
"['Thank you!  ""coincident axes and joint origins at a single point"" is helpful language for describing this, much appreciated', ""I think a spherical wrist actually can roll as well [https://imgur.com/a/NrQshPE](https://imgur.com/a/NrQshPE) But that comparison is helpful, that's a better way of putting it, thank you!\\\\"", 'Correct.  The order of operations in the given image is roll, tilt, roll.  An unconstrained ball joint can, for example, pan then roll, or tilt then pan.  how would you lock down the ball to get only the predictable motion desired in a robot arm?']"
['face raiders wishes it was this']
"[""I looked it over.  It is a novel spider, but it appears to be a single motor driving a number of gears/legs, so they won't move independently.  I'm afraid with that configuration, there won't be much control you can take over the robot (other than maybe remotely turning on/off).  Even switching its gait would be challenging because it is probably a mechanical switch. \n\nIdeally, if you find something that is multi-articulated (i.e. an arm, robot, spider) that uses multiple motors to control each aspect, that makes a better candidate for hacking.""]"
"['Definitely follow what the other guy said about buying already made belts.', ""didn't say it was huge, said I could not find one in the size I wanted :-)""]"
"['I\'m gonna need more evidence other than ""trust your definition"" of what ""Pre-production demonstration"" means.  \n  \nAnd I never said they don\'t have working prototypes.']"
"[""Your new design is fine, if you dont want to pretension the bearings, what you could do, if precision is not important. You cant pretension the bearings, without having something between the inner rings (X-configuration) or outer rings (O-configuration). Generally you can use setscrews on low load applications if you use several (equally spaced on the ring to be tensioned) but its not a good way. You should introduce the pretension with a ridgit part on the complete outer (or inner) ring. I would use something like this (https://imgur.com/6a3hWEF). Make sure that the cylindrical mounting surfaces are concentric by using pins or hexagonal standoffs like this ([https://www.ebay.de/itm/234503018801?var=534093410520](https://www.ebay.de/itm/234503018801?var=534093410520)). If never used the slew rings from igus, so i dont want to judge their sutability for this application. Generally igus bushings can be fairly precise if integrated properly. I cant tell for sure what the 'preload' in the thumbnail means but i think its just tighter overall for less play (and more friction)."", 'I drew it in fusion360. I dont know. Might be that some use some weird axial/radial-configuration. But when you go to the link you posted, the first few said Schrägkugellager Whitch means angular contact ball bearing.', 'I drew it in fusion360. I dont know. Might be that some use some weird axial/radial-configuration. But when you go to the link you posted, the first few said Schrägkugellager Whitch means angular contact ball bearing.', 'What do you want to build? You said its goind to be an scara arm but whats your endeffector and what do you want to do with it? How long do you want to make the two arm sections? Because NEMA 14 motors have very limited torque. NEMA 17 are not that tiny but still very limited. And microstepping really is not the solution to limited resolution. So unless your planning to sort M&Ms really slowly and inprecisely, I would guess you need a reduction stage. If you dont want to spend money, 3D print a gear stage. The first image doesnt pretension the bearings. If you dont need the precision, thats fine but you also cant print the middle part without supports. Why do you prefer the second? Its the same concept as the first, but without pretension or motor.', 'I dont know what you mean with bracket, but the gap is for ensuring, that the ring ist fixed securely and cant slip up or down under load.']"
"[""Since you said it's a MARS rover - are you going to use mars gravity or earth gravity. \n\nThe torque required will vary on surface - concrete 'v' mud etc.,"", 'Perfect, thank you so much for your help']"
"['Does this help:\n\nhttps://math.stackexchange.com/questions/461547/whats-the-equation-of-helix-surface', 'Hi Thank you very much for your detailed response, I really appreciate and it helps a lot. \n\nThe lead screw can actually work and it might the engineering representation of this toy as well. However, the angular velocity as well as the linear velocity of a lead screw is very less whereas in this toy they are high which eventually generate the enough angular momentum for the rotor in the toy to fly. Do you know anything about this? How can I achieve greater velocities with a lead screw?   \n\n\nThanks again!', '>*How can I achieve greater velocities with a lead screw?*\n\nThe angular and linear velocities are simply related by the lead of the screw (distance traveled per revolution of the nut) so you really just need to push faster (and/or rotate faster)\n\n(Be careful: the ""lead"" is the same as the ""pitch"" for single-start screws like normal hardware screws, but it is common for lead screws to have several ""starts,"" i.e. maybe they have 2, 4, 6, or 8 helical threads that spiral around the core, not just one)\n\n>*However, the angular velocity as well as the linear velocity of a lead screw is very less*\n\nThat\'s really just because you can push the ""nut"" along fast in the helicopter toy which makes it spin fast.\n\nThere are a couple of reasons why you don\'t see high rotational and linear speeds on lead screws you\'ve encountered.\n\n\\- They\'re often used to turn rotary motion into long-distance linear motion. You have to make sure you don\'t excite a whirling instability of a long screw by rotating too fast, so this limits the rotational speed even if you have zero load. \n\n\\- Your toy is a toy. It\'s not designed to carry large loads for a long time. Lead screw designs are often moving against significant load and designed for long, reliable industrial lifetimes. You\'ll find that if you built a machine to constantly cycle your helicopter toy at the peak force and torque you achieve at takeoff, it probably wouldn\'t last a million cycles. At the very least you\'ll probably start to see some wear at the contact patches over many launches. But in the toy application, the mechanism only needs to last for the expected number of flights before a kid steps on it in the yard and snaps it in half 😅\n\nIf you pick a long-lead (high-helix) lead screw and push the nut fast, it will spin fast, according to the kinematics prescribed by the lead (one rotation every lead length)\n\n>*whereas in this toy they are high which eventually generate the enough angular momentum for the rotor in the toy to fly*\n\nYou have to keep in mind that everything in the toy is very lightweight so you can push VERY hard as a human against a very lightweight, small system. \n\nThe reason it spins fast is because you can push it fast. The twisted axis is just a type of lead screw, and it rotates what, 1 revolution per centimeter, 1.5 revolutions per centimeter? I would classify your helicopter toy as a 2-start lead screw with something like a 1cm lead (it also happens to have zero minor diameter so it\'s all threads and no cylinder, because it doesn\'t have to be very strong)\n\nIf you choose a similar-pitch lead screw you should get very similar behavior, but if your rotational load is heavier (and in particular has a higher moment of inertia) than that helicopter toy you will of course need to push **much, much harder** to get it to spin a similar rate, just because the rotational kinetic energy you need to add is so much higher, plus the force due to frictional losses will be elevated.\n\nCheck out \n\n[https://en.wikipedia.org/wiki/Screw\\_(simple\\_machine)#Torque\\_form](https://en.wikipedia.org/wiki/Screw_(simple_machine)#Torque_form) \n\n[https://en.wikipedia.org/wiki/Screw\\_(simple\\_machine)#Actual\\_mechanical\\_advantage\\_and\\_efficiency](https://en.wikipedia.org/wiki/Screw_(simple_machine)#Actual_mechanical_advantage_and_efficiency) \n\nfor details.\n\nScrews in general are FREQUENTLY frictionally self-locking, and all hardware-store screws for fastening are explicitly designed to be self-locking because otherwise they\'d be completely useless. So obviously, you can\'t push the nut and make it spin. Maybe you can with a light push, some oil, and a little vibration, but barely.\n\nIf you\'ve never held one of these backdriveable high-helix long-lead lead screws in your hands, you might be skeptical that you can push the nut fast and spin it fast, but it\'s absolutely feasible. It\'s just unfamiliar because most screws are designed intentionally so that you can\'t push the nut at all no matter how hard you push.\n\nBy the way, even if you don\'t go with a ball nut for the nut, you\'ll probably want a low-friction thrust bearing where you do the pushing. The helicopter toy has one of those too, but it\'s just light-duty slippery plastic on plastic.']"
"[""In a way, I'm a bit leery of this.  Is the robot capable of stopping when it hits a rock or a sewer or some other underground anomaly, or is it just going to mindlessly pound the pile into the ground?""]"
"['For example, robotics in Switzerland are skyrocketing in the Watch Industry. \n\nBecause of the lack of skilled labor. Some companies have begun to build uses to replace humans. This concerns ungrateful tasks for the moment.', ""It's important to remember that a lot of these tech companies going through massive layoffs underwent equally massive growth during the pandemic. A lot of this is just a reality check for them that the growth they experienced during that time was basically a façade.  \n\n\nAs far as robotics goes, it depends on the business itself. Roomba is basically the only successful retail robot product. Anything going for pie-in-the-sky ideas to try and make us like the Jetsons is going to be a ways off. Things like drone package delivery, food delivery, in-home assistants etc. Where robots are doing just fine is in manufacturing and the industrial sector in general, where high initial buy-in costs aren't as prohibitive, skilled labor is getting harder to come by, and there's money to be made from a machine that can do the same motions over and over."", 'Pretty good actually.  Our suppliers are running near capacity.', ""From a US employee perspective my impression is it's good or even improved only for companies who are revenue generating or have a clear path towards revenue generation. Others are doing bad and have died or on path to.\n\nThe robotics product I was part of on didn't work out even though we had people in the 100's working on it because it was not making any money and all of us were laid off.\nThe industry is trending towards cutting fluff and experiments of all sizes and focusing short term on things that seem to work. This situation has made it super competitive for job applicants.""]"
"[""I agree with sentiment here, leg shaft strength probably isn't your big concern, but to help leg strength and honestly the overall performance of your bot, make the body section as light as possible. It will minimize all your forces to move thus all your reaction forces, it will reduce your part scale and cost. Just keep it in mind directionally.""]"
"['Do some force calculations to help you tease out what type of torque you need and at what speed to identify what motor you need.', 'Additional information is probably needed. Not by me because I’m not knowledgeable about motors enough for the answer but I’m good at thinking out questions.\n\nWhen you say swim, to what capacity? \nIn a calm water pool or pond vs in a lake vs against the current of a busy river vs the rolling waves at the beach?\n\nYou mentioned boat-like or duck legs which implies “swimming” at the surface. What sort of speed are looking for it to achieve?\n\nWhat sort of power source is available to the robot?\n\nAre you hoping to achieve single motor propulsion steered by a servo or a left and right drive system?']"
"['[Here is a December 2020 show-and-tell](https://slideslive.at/38946802/boston-dynamics?debug_slideslive_player=yes&ref=recommended-presentation-38946802&locale=en) by Marc Raibert, in which he presents the guts of Atlas. The battery is 1.4 kW\\*h, and the hydraulic pump unit is capable of 5 kW.\n\nA few hundred watts goes to power the controller, the rest goes to the large hydraulic pump motor and a few motors of the joints that are not hydraulic. Assuming 50% efficiency, heat dissipation is from about half a kilowatt to nearly three kilowatts, depending on how the robot is used.\n\nA short athletic performance which drains the battery in 15 minutes will get the air from the cooling fans noticeably warm. Just standing still for an hour probably not so much.', 'Having met him. I 100% believe the 1 star review. I’m pretty sure the latest reviews are damage control and they’re from all over the world. Which is very shady for a 30 person UK based company. \n\nI agree with you entirely, we need to do better. The best employers in the UK for engineers are the large companies. At least they hold themselves accountable to some degree.', 'Engineered arts as a company has so much potential, and you can tell he is the limiting factor there. It’s very clear, even from the outside that he rules with an iron fist over there. Explains the little growth as a company in almost 20 years! I’m not surprised he said that to you about having a PhD. It aligns perfectly with his character.', 'Controlling a robot like atlas requires fairly intimate knowledge of its workings. Withholding this data from users would hurt adoption and make it harder to develop with them.']"
"['The problem is that it\'s a cult. There already are humanoid robots, and there have been capable humanoid robots for twenty years. If an experienced roboticist who already had a humanoid robot went on stage and said ""I\'d like a hundred million dollars to better develop this robot and to implement it in business"" they would be booed off stage. Someone with a personality cult though, can go on stage, say that they don\'t have a robot but they want a hundred million dollars, and people throw money at them. Effectively that\'s what the guy did, he went on stage, he did not have a robot, he said he had a robot. People then sent him, by buying stock, hundreds of millions of dollars. Then he hired people to build a robot, and they will keep going that way. It\'s a personality cult that allows it and it\'s a personality cult that keeps it going.\n\nEven worse, because most people aren\'t super familiar with the state of robotics, when the guy claims that he invented humanoid robots, somehow a bunch of people seem to believe it. Almost worse still you have people like Lex Fridman who get guests on their show and make them talk about how great their personality cult leader is, that fools listeners into thinking there\'s legitimacy behind it.', ""TIme will tell if I'm right but I think it's not that hard of a problem. If you have the capital to finance it and a rough idea of the steps then it can be done, and again, in such a way where it would be hard to screw up. Lately people just aren't organised in their capital so not enough people are going for it. Or, put the other way, a lot of people actually are going for it and they are making huge progress, there already are humanoid robots, but those people who are going for it don't have a billion dollars to just throw at their project. As they get funding to implement what they want to implement, they dillute their power over their humanoid robot project to the point where they can't build it effectively. Hence the people going for it aren't given the adequate funding. The ones who can do it, for whatever reason, aren't. Also I'm individualising these people and I shouldn't be, in reality it's the collective work of a lot of people, but I'm phrasing it this way for the sake of conversation.\n\nSo for example, for $200 (I'm making up numbers) million with no strings attached, there are a lot of people who can make very competent humanoid robots and bring about huge change in business. Those people though, if they tried, would have to spend half of their time talking to investors, dilluting their ability to work on the project. They would only get $20 million instead of $200 million, severely capping their ability to build it. They would also lose significant share and therefore voting power over the project, interfering with their ability to direct it. On top of that, they would have to sign obligations to pursue business goals quickly, and that would limit their ability to make a good robot for making a good robot's sake, and in the long term that would compromise the potential of the robot.\n\nPutting that stuff aside, I think it's a far easier task than people give it credit for.""]"
['BRO I HAVE BECOME A FAN INSTANTLY. Keep this going I see a very profitable future. Mans got a YouTube channel with coding and robots. Stay determined and consistent.']
"['This is a Fakespot Reviews Analysis bot. Fakespot detects fake reviews, fake products and unreliable sellers using AI.\n\nHere is the analysis for the Amazon product reviews:\n\n>**Name**: OBSBOT Tiny AI-Powered PTZ Webcam, Full HD 1080p Video Conferencing, Recording and Streaming - Black \n\n>**Company**: Visit the OBSBOT Store\n\n>**Amazon Product Rating**: 4.4 \n\n>**Fakespot Reviews Grade**: B\n\n>**Adjusted Fakespot Rating**: 4.4\n\n>**Analysis Performed at**: 03-05-2023 \n\n[Link to Fakespot Analysis](https://fakespot.com/product/obsbot-tiny-ai-powered-ptz-webcam-full-hd-1080p-video-conferencing-recording-and-streaming-black) | [Check out the Fakespot Chrome Extension!](https://chrome.google.com/webstore/detail/fakespot-analyze-fake-ama/nakplnnackehceedgkgkokbgbmfghain)\n\n*Fakespot analyzes the reviews authenticity and not the product quality using AI. We look for real reviews that mention product issues such as counterfeits, defects, and bad return policies that fake reviews try to hide from consumers.*\n\n*We give an A-F letter for trustworthiness of reviews. A = very trustworthy reviews, F = highly untrustworthy reviews. We also provide seller ratings to warn you if the seller can be trusted or not.*']"
"[""Thanks, this was super helpful! I looked at the SMARS and we're going to try that first!  This was also a good excuse to buy that 3D printer too I've been thinking about too..."", 'That’s awesome! I’m glad that I was able to help and I’m sure you all will have a blast for years to come!']"
"[""Thank you! And yes, you are exactly on point, that is part of what I am doing. But there's nothing mysterious here, I just wrote a regular Android app (phone not rooted), that communicates with a servo controller via a serial port over the usb, and accessing the phone's sensors are all well documented on Androids website. Hope it helps. I totally agree with you that using phones as an embedded system has a ton of benefits, specially for hobby projects like this one."", 'Nice nice! As I am more of a bookworm, do you have any suggestions of some books on this stuff? Sort of like Embedded + Android dev. If not, then any other links are also appreciated :)\n\nI will surely take a look into Android app dev and the Android documentation, as you mentioned.']"
"['Litigation due to injury caused directly or indirectly by action (or inaction) of automated systems.\n\nSupply chain issues. Especially for electronics components.\n\nDirective compliance (CE, FCC, UKCA, UL ..etc) and associated legal requirements for distribution\n\nFinding skilled engineering staff\n\nThen the usual business issues of marketing, sales, profit... Etc']"
"['Ehh I wanted a way for it to move on less grippy material… the solution I found so far is to add small  Velcro pieces on the lower side, it somewhat helps with traction :D \n\nAlso having moved the components (raspberry, breadboard for 293 chip and battery) on the robot helped with additional grip because it puts more downward pressure…\n\nI’m aware that wheels would make for a much easier, more functioning moving robot but I liked the idea of the snake like movement ahah\n\nhttps://imgur.com/gallery/0kRFsc3']"
['Took a long time to get them to this point. Lots of manual reading and begging Yaskawa for help.']
"['I would say either attach an extra set of tie rods/ bracing overtop of the servo to stabilize it farther up to have more weight centered with how tall it is. \n\nAlso was going to say, do you have a 3d printer?? If so, I would print a breakaway product and form it into a spine to restrict the ""bobbing"" lol.\n\n&#x200B;\n\nHope this helps!! Otherwise, it looks awesome even wobbly- it adds a certain effect alright!!', 'Some thick viscous lubricant withing the bearings should help', 'Have the creature continuously loop Donnie Darko in video screen with audio.   That will ""help"" stability.\n\nBut seriously, some simple springy material to support.  Judicious use of styrofoam pool noodles?', 'But to give a serious answer, you need to rig up some counterweights to help stabilize it. Eg a linkage to your drive for an axis that connects to a heavy weight on an arm that pulls toward upright about as much as the top pulls down.', 'That is a very clever idea. My first thought was that the servos and the mechanics are too weak. But the spine would help relieve that weight of the overhang at the extreme positions. Chapeau!', 'Linear actuators on a spine like system (or even this maybe) may help', 'Yeah I honestly have no idea what you’re referring to.']"
"['Thank you this is very helpful. I purchased physical axis limiters for axis 1,2,3 so I can be a bit more sure on its limited range of motion.\n\nThis is very helpful to understand, thank you for taking the time to write it out.']"
"['I’m working on some animatronics that require actuation via Bowden cable. I figured I’d try to save some money and buy raw 1.5x1.9mm ID/OD PTFE tube and 1.2mm OD stainless steel braided cable instead of buying Gold-N-Rod. Seems like I made a bit of a mistake, since I’m going to need to secure the outside ends of the Bowden tube lines, and PTFE is notoriously hard to glue to. Do you guys have any ideas on how I can salvage this situation and secure the ends of the tubes?', 'What data structures and algorithms should I prioritize learning to crack interviews for Robotics Software Engineer role? I have work experience, have designed custom systems with ROS. What I have never done is interviewed for a job, and since there is very little written about interviews for robotics, I want to understand from others what can I expect and what should I prioritize preparing.\r  \n\r  \nI also have mechanical and electronics experience while building previous robots. Do these help when interviewing for software roles?\r  \n\r  \nLastly, on average how much experience do people in Robotics Software Engineer roles have?', '\n\nI have the following problem: We want to estimate the doil dumped into a truck by an excavator. To do this, we would like to develop an algorithm which estimates the heightmap of soil dumped into a dumping bed.\n\n \n\nWe have 5 independent variables, like the degree of the dumping arm, the velocity with which the soil is dumped into the dumping bed, the position of dumping, the soil volume in the bucket etc.\n\n \n\nAlso, there is a LIDAR sensor on top of the cabin of an excavator, which is not perfect however, we call this the observed data. Also, to generate the ground truth data, we measured the real heightmap, with a lidar sensor over the dumping bed of the truck.  The Goal is that we find a good approximation of the heightmap values just based on the observed data from the Lidar sensor on top of the excavator and the 5 variables. We recorded groundtruth data just to evaluate the performance we get for this regression task.\n\n \n\nWe recorded 14 experiments (excavator dumps soil from a pile of soil into the dumping region until all pile was loaded) with 10-15 time points in each. So we have 140-210 data points.\n\n \n\nFor the modeling, I think about modeling it as a Kalman Filter. I have a machine learning/data analytics background, so at first I thought one could somehow treat this as a supervised problem, i.e. learn the relationship of the variables and the observed variables to the groundtruth data G. But If understood correctly, in Kalman Filtering I would use the observed data and I would use my recorded independent variables as part of a state update function, in a form like:\n\n \n\nO(t+1) = O(t) +w1 * y1(t+1)  + w2  * y2(t+1) + w3 * y3 (t+1).\n\n \n\nI.e., the observed heightmap values here are a function of these variables y1-y5.', 'I am a robotics software engineer with 4 years experience (2 in masters degree). Most robotics interviews will ask you to implement actual robotics adjacent algorithms (such as 3D spatial geometry or multi threading) so data structures and algorithms are not the focus. That said you will need to have a very solid foundation in DSA. Also a masters degree is looked at favorably since it means you have actually built a few robots. I see a lot of applicants with a bunch of unrelated web projects and I filter them out. We need people with hardware experience.', 'A good starting point is to be very comfortable with the following topics:\n\n1. Rigid 3D transforms and spatial geometry like homogenous transforms and quaternions\n2. C++/Python but any runtime code is likely C++\n3. Concurrency in both C++ and Python\n4. Linux usage \n5. Point cloud processing\n6. Linear algebra and Calculus \n\nAlso it’s worth noting that unlike preparation for a FAANG interview where you can LC for a while and then get in, it would be really helpful for you to actually build a couple robotics systems (which it seems like you have!). As I mentioned earlier I see a lot of applicants who have never actually built a robot and made it work with hardware (which is by far where most time is spent during development). DSA is foundational in robotics software but it’s really the specialized skills you need to master. \n\nThat said there are a few companies I’ve interviewed at that do take the more LC style approach such as Waymo and Cruise but the problems are often LC hard and related to robotics.', 'Yes ideally you could implement a transform tree like tf2 does. ROS is rarely used in industry.']"
"[""This was my first robotics project and my first time using a Raspberry Pi. It was extremely fun to work on and I will definitely take on more robotics projects in the future.\n\nThe idea for this project came about when I was talking to some friends who were discussing the problem of excrement particles flying out of a toilet when it's flushed without the user shutting the lid. However, shutting the lid requires the user to touch the toilet, which is not sanitary. This project's goal was to create a completely hands-free toilet that closes the lid before flushing. \n\nAs an added bonus, the toilet can also be controlled from a smartphone (closing/opening the lid and flushing). This was just supposed to be a gimmick. Not shown in the video.\n\nI could not have completed this project without the help of the moderators of the Adafruit forums (specifically adafruit\\_support\\_bill) and the moderators of the Pololu forums (specifically PatrickM and BrandonM). Much respect for those who helped. I was shocked at their willingness to explain anything I had a question about."", ""I'll be moving fairly soon, so I might make some improvements when I install it in my new bathroom.""]"
"[""His opinion doesn't matter, humans are going to build whatever robots they want anyway. For doing dishes, for killing, for sex, for farming. Ethics has been out the window for a while. Whole schools of philosophers trained to think about why we should or shouldn't do something stand powerless in the face of the masses who are going to do whatever they want anyway, be it ethical or not. Its like Asimovs robot laws. They mean nothing because nobody is programming robots like that."", 'Somewhat unfair quote. In those days computers filled entire rooms.', ""He's scared of humanoid robots and seems not to be able to be honest about that.""]"
"[""This demo (i.e. the choice of motions) actually brings Tony full circle to his 1st version of stuntronics before it was called stuntronics, a bittersweet footnote to its backstory (NDA's, ugh). The more interesting detail is not the roll/getup, that's old hat, common in the humanoid world: it's the turn in place at the end that's new tech (and noticed there was assistance to keep it balanced, so it's not there yet).\n\nIt's great he and Morgan are still working on the tech & concepts that solve the typical scenarios performance robots will encounter from daily use.""]"
['For such a long article there are almost zero specifics. Every paragraph is just “many” “consider” “could” and a few broadly generalized statements. Did ChatGPT write this? This won’t actually help anyone choose a specific gripper for a specific application.']
['Thank you very much!  Let me know if I can help clarify anything along your read :)']
"[""I'm working on something similar with raspberry pi, this will be helpful.""]"
"['Does BD publish performance specs related to power consumption of each sub system?\n\nI\'d imagine locomotion burns up a solid 80+ percent of charge in a given ""standard"" situation right?', 'I am not sure if I understand your question, could you please elaborate. Spot robot could run for long hours using shore cable connected to it while the battery inside the robot. I dont think BD published any specs since I am in contact with them. I noticed that if operate Spot for long hours, the mechanical performance is not efficient sometimes, I did not find any spec or tests regarding the number of the cycles that the robot can operate.\n\nYou can find here the details in this link: [https://support.bostondynamics.com/s/article/Robot-specifications#Power](https://support.bostondynamics.com/s/article/Robot-specifications#Power).\n\nPlease note there are different version of the battery, the one I was referring to is the enterprise battery, also working with Spot could be pretty painful because of the extreme fan noise.']"
"['Geartrain performance, motor performance, encoder performance, linkage stiffness, bearing stiffness and accuracy, control loop performance to name a few', ""Labour costs a lot of money. You see some big open source projects that perform as well as commercial ones, or even better if there is no commercial alternative. But they can have hundreds or even thousands of people working on them. Of those people, enough of them either have to be professionals, or competent enough to contribute in a way that can meet standards.\n\nLast I checked machinists in my area were charging 100 dollars an hour ballpark, engineers in the same range, and software developers are pretty high as well. Part of this is also machines/equipment, and resources have a cost too. In theory, if you made something at material cost, it might be possible to do it close or closer to hobby prices, but even if you have a community willing to work on the project, they need access to those tools or the tool costs increase the cost as well.\n\nTo have enough people to make a project work, you need something to motivate them. For companies they can just pay people. But for a hobby community usually theres something to take out of the project itself. Open sourced software works well because most people have the tools (computer), and software can basically be free of physical resource costs. 3D printers took off as they became more accessible. But a lot of people that love to mess with them now, wouldnt or didnt get down in the trenches and do the boring comunal work back when it was just early prototypes with more work and less payoff. You may have a lot of people who want a high precision robot arm, but dont see the benefit in commiting themselves to the cause. You could have a bunch of people work together remotely on a prototype. But if they arent the one who owns it, or if it doesnt match what they want it for/to do, theyre more likely to set out on their own to make something. Even though they'll accomplish less than they could in a group. Lack of confidence plays a big part too. many people might not waste their time trying because not many other people have done it yet so it doesn't look very feasible. Again to the 3D printer example, they needed initial trail blazers. The more people succeeded, the more others had interest and expectations they could succeed too. \n\nI want to close this out by saying you could technically make this happen IMO. With a clear goal, good organization, and a dedicated group who have or are willing to gain the skills and tools, it's possible to break through the first most difficult milestone. But it would take someone or multiple someones who are very dedicated to spearheading the group by keeping it organized and on track. That's a difficult task, and requires someone who is credible enough to keep group confidence so they don't fizzle out or splinter off on their own and abandon the project. In fact the whole initial group might have to be passionate or dedicated to the same level. But people have lives, and get distracted, so we might not see it for a while.\n\nBonus: capitalism perspective, there's not enough of a market for it rn because of available alternatives."", 'Yak is absolutely correct here. I’ll try to expand starting from the controller out to the mechanics. \n\nThe controller for precision motion control needs to be quite high performance, offering closed loop system bandwidth at several thousand Hz. This allows for it to compensate for high frequency vibrations in the robot movement. This would typically be achieved with a purpose designed FPGA and has performance far superior to any hobby microprocessor. The motors are also commanded with S-curve motion or high order blends to minimize the jerk term which causes mechanical resonance to be excited. I’ve never seen a hobby microcontroller doing path planning with higher order profiles. Not that it couldn’t be done but there is a performance limit to that hardware. \n\nNext up is the motors. I’ve seen hobby robots using either RC servos or steppers. I’ll touch on steppers first. They are inherently controlled open loop meaning that the actual motion of the robot is a guess. Secondly they move in discrete steps so regardless of the degree of microstepping, the will always induce mechanical vibrations. They also have a fairly limited positioning resolution compared to the industrial alternatives. RC hobby servos are even worse. They are technically closed loop motors, but they have very poor feedback (usually only a potentiometer) and can only move to 256 positions. Their path following performance is even worse. I blame hobby RC servos for 80% of the problems you see with home brew robots. \n\nCompare those motors to industrial AC servo motors with digital motor control. These motors are fast, powerful, and extremely precise. A decent servo today will come with feedback devices that produce well over a million counts per revolution. Feedback response along with some other parameters like motor inertia and drive closed loop bandwidth determine the position and velocity control bandwidths. There is no hobby motor that even comes close in performance to these motors and the command a price accordingly. A high end 400W motor (not including drive or cabling) can run around $1500. These will be found on just about every robot made in the last 25 years. \n\nThen there are gearboxes. Robots typically use either harmonic drive gearboxes or cyclodial gearboxes. Both of these are very expensive but also top of the line with regards to low backlash, high torsional stiffness, precision of motion, and compact size. Even a small harmonic drive for a desktop size robot could be $1000-2000 per joint. These gearboxes are also typically paired with a crossed roller bearing for supporting the moment loads at the joint. These bearings can be several hundred dollars per joint as well. There really is not a good replacement for these precision mechanical components that’s affordable to the hobbyist. \n\nAnd finally there is the accuracy of the mechanical linkage against the target dimensions defined in the robot kinematics. Any errors (ESPECIALLY on the first links) will compound to positioning errors at the end of the tool. This is a big issue even for industrial robots and often requires an intensive calibration to make the robot kinematic model match the actual hardware. \n\nIn total many factors come together to permit industrial robots to move with the precision that they do. And through mass manufacturing, the robot vendors have driven cost about as low as it can be for these precision machines.', 'Robot vision is the answer.  People are capable of great precision with vision alone.', 'That’s my hobby:) \n\nI have 2 industrial robots. The closest thing I’ve found to an industrial “open” robot controller is robotic control through an Allen Bradley PLC. It’s a pain to get a random motor working on their drives, but when you do, you can command the robot kinematics through the PLC with arbitrary commands. \n\nI paid less than $500 each for my robots and over a year of tinkering with them to get them running.', ""I don't think compute performance plays into it at all. A modern MCU is more than capable of controlling a robotic arm at khz update rates.\n\nSoftware yes. Even the hobby 3D printer community, which is huge and cares a lot about precision and accuracy, doesn't have the path planning done right so far.\n\nActuators yes. The 1900s called, they want their actuators back. 256 positions is almost certainly not true for most servos though.\n\nGearboxes definitely."", 'Compute is definitely a factor, Odrives which run 2 servo motors with bare minimum control loops and zero motion planning are already approaching the limit of their microcontrollers. I think they use STM32 F4’s, which are not at all low end chips. When you need to run 6 motors at even faster loop speeds and compensation for different loads and inertia it really adds up, especially once inverse kinematics and motion planning come into play. All the commercial industrial robots use FPGAs or maybe even ASICs for the motor and motion control. (Note it’s not necessarily processing, but it’s the real-time control of everything that needs to have extremely consistent timing)', 'I used to work @ one of the top R&D labs for a robotic surgery company, and compute absolutely affected overall system performance.  We designed haptic robots with 16kHz control loop rates to maximize performance, and on various tests we ran down to 2kHz and there is a significant difference.  Compute absolutely affects performance.', 'Not a great example. Odrive doesn\'t ""run"" a servo motor, it IS a servo motor. It has to do all of the FOC compute to update the magnetic field in the motor windings at 10s to 100s of khz. This task is completely independent and you can 100% offload/parallelize it.\n\nGiven that ODrive is (IIRC) sensored FOC and therefore doesn\'t have to estimate the rotor angle from electrical quantities using a kalman filter, I doubt they\'re running into any compute limitations unless they\'re just really inefficient. They\'d definitely be low on pins, timers and ADCs, running 2 3 phase inverters, though.\n\nIf I were building a robot arm with ODrives, I would have multiple ODrives connected to either an MCU or desktop computer or both depending on compute requirements and timing requirements.\n\nRealistically, what is behind in the hobbyist community is probably the software and mechanical aspects.\n\nI would expect that eventually, robot arms will follow in the footsteps of drones - a majority of commercial drones run open software developed by hobbyists these days, so a DIY drone is pretty much equally capable in terms of software.', ""the motors on the katana are just dc motors with documented encoders strapped to them. so this should be rather straightforward :)\n\n&#x200B;\n\nROS is a middleware that in the first place provides a communication platform to push around messages. on top of that, it also provides a ton of packages to do various robot-related tasks. \n\ni've used ROS a bunch for a project at work, where the idea was to do path planning on a laptop and then just push trajectories on the robot. this worked very well. \n\nhowever, (AFAIK) ROS doesn't really do any of the real-time related stuff per se. it's up to you to provide with an OS and the relevant software to take care of this. \n\nthe learning isn't that steep if you can get away with using what's already there. but if you really need to dig into the entire stack, it becomes rather difficult. you can do a lot with relatively simple python scripts, but for performance, you'll have to get into the C++ end of things. \n\nthat being said, UR and MiR run their robots with ROS as far as i know."", 'Yeah Odrives just handle the current, velocity, and position control. It’s not exactly a lightweight task, but not crazy. The standard is obviously having separate drives for each motor and a motion controller. I have a 6 axis robot that runs off of Odrives and LinuxCNC. The software is terrible, it does the inverse kinematics but there is no handling for singularities or any jerk limiting. I think good motion planning software could help a huge amount, even robots with subpar mechanics.']"
"[""Pi Pico is a microcontroller. Much depends on your programming language of choice. Here's a comparison;\n\n[https://all3dp.com/2/raspberry-pi-pico-vs-arduino/](https://all3dp.com/2/raspberry-pi-pico-vs-arduino/)\n\nYou can, for the Raspberry Pi 4, get a RTOS that makes it fully deterministic and still have the advantage of a full OS. That said, the resources available for Arduino as a gcode interpreter are vast and may be the best starting point. As mentioned the ESP32 offers a great alternative as well being a very well supported controller and is compatible with the Arduino programming IDE.\n\nIn the end, you're unlikely to run into speed issues with any of these. More likely you will see the physical limits of inertia and acceleration first.\n\nThe drivers you wish to use will depend on the motors you choose. The mass you intend to move and required acceleration, max speed will determine that.""]"
"[""Don't overlook the brushed option. Cheaper / easier to control, and depending on the torque you need, the performance might be similar.\n\nEdit: Particularly in the case where you only need torque in one direction, you could be talking about 5$ in components vs 150$ for an o-drive.""]"
